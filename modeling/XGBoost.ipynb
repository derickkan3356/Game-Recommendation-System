{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633684ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score  # Assuming NDCG is your evaluation metric\n",
    "from sklearn.preprocessing import LabelEncoder # If you have categorical target variables\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583f3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path_local = '../assets/combined/train_ready.pkl'\n",
    "test_file_path_local = '../assets/combined/test_ready.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c411c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_file_path_local = '../assets/combined/train_raw.pkl'\n",
    "raw_test_file_path_local = '../assets/combined/test_raw.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9b38e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully!\n",
      "Training data shape: (2643279, 50)\n",
      "\n",
      "First few rows of training data (as DataFrame):\n",
      "              user_id  app_id  relevance_score user_country_code  \\\n",
      "0  76561198073669602    4000         0.641805           Missing   \n",
      "1  76561198073669602    2590         0.000000           Missing   \n",
      "2  76561198073669602   11200         0.734365           Missing   \n",
      "3  76561198073669602      20         0.000000           Missing   \n",
      "4  76561198073669602      50         0.000000           Missing   \n",
      "\n",
      "   user_has_coordinates  user_latitude  user_longitude  \\\n",
      "0                 False            NaN             NaN   \n",
      "1                 False            NaN             NaN   \n",
      "2                 False            NaN             NaN   \n",
      "3                 False            NaN             NaN   \n",
      "4                 False            NaN             NaN   \n",
      "\n",
      "   user_account_age_months                  game_name  game_tba  ...  \\\n",
      "0               149.106555                Garry's Mod     False  ...   \n",
      "1               149.106555                Alpha Prime     False  ...   \n",
      "2               149.106555     Shadowgrounds Survivor     False  ...   \n",
      "3               149.106555      Team Fortress Classic     False  ...   \n",
      "4               149.106555  Half-Life: Opposing Force     False  ...   \n",
      "\n",
      "   game_avg_playtime_forever  game_avg_playtime_last_2weeks  \\\n",
      "0                       9448                            500   \n",
      "1                         20                              0   \n",
      "2                        136                              0   \n",
      "3                        105                              0   \n",
      "4                        390                              0   \n",
      "\n",
      "   game_median_playtime_forever  game_median_last_2weeks  game_current_price  \\\n",
      "0                          1115                      111               599.0   \n",
      "1                            24                        0               499.0   \n",
      "2                           164                        0               999.0   \n",
      "3                            11                        0               499.0   \n",
      "4                           142                        0               499.0   \n",
      "\n",
      "   game_initial_price  game_current_discount game_concurrent_user  \\\n",
      "0               999.0                   40.0                22008   \n",
      "1               499.0                    0.0                    1   \n",
      "2               999.0                    0.0                    1   \n",
      "3               499.0                    0.0                   74   \n",
      "4               499.0                    0.0                  107   \n",
      "\n",
      "  game_estimate_owners_lower game_estimate_owners_upper  \n",
      "0                   20000000                   50000000  \n",
      "1                     200000                     500000  \n",
      "2                     200000                     500000  \n",
      "3                    5000000                   10000000  \n",
      "4                    2000000                    5000000  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "\n",
      "Testing data loaded successfully!\n",
      "Testing data shape: (694638, 50)\n",
      "\n",
      "First few rows of testing data (as DataFrame):\n",
      "                 user_id  app_id  relevance_score user_country_code  \\\n",
      "2693  76561197960304100      10         0.698825                CL   \n",
      "2694  76561197960304100      20         0.000000                CL   \n",
      "2695  76561197960304100      30         0.000000                CL   \n",
      "2696  76561197960304100      40         0.000000                CL   \n",
      "2697  76561197960304100      50         0.000000                CL   \n",
      "\n",
      "      user_has_coordinates  user_latitude  user_longitude  \\\n",
      "2693                  True     -35.675147      -71.542969   \n",
      "2694                  True     -35.675147      -71.542969   \n",
      "2695                  True     -35.675147      -71.542969   \n",
      "2696                  True     -35.675147      -71.542969   \n",
      "2697                  True     -35.675147      -71.542969   \n",
      "\n",
      "      user_account_age_months                  game_name  game_tba  ...  \\\n",
      "2693               258.218823             Counter-Strike     False  ...   \n",
      "2694               258.218823      Team Fortress Classic     False  ...   \n",
      "2695               258.218823              Day of Defeat     False  ...   \n",
      "2696               258.218823         Deathmatch Classic     False  ...   \n",
      "2697               258.218823  Half-Life: Opposing Force     False  ...   \n",
      "\n",
      "      game_avg_playtime_forever  game_avg_playtime_last_2weeks  \\\n",
      "2693                       9855                            204   \n",
      "2694                        105                              0   \n",
      "2695                        181                              0   \n",
      "2696                        146                              0   \n",
      "2697                        390                              0   \n",
      "\n",
      "      game_median_playtime_forever  game_median_last_2weeks  \\\n",
      "2693                           151                       33   \n",
      "2694                            11                        0   \n",
      "2695                            15                        0   \n",
      "2696                            10                        0   \n",
      "2697                           142                        0   \n",
      "\n",
      "      game_current_price  game_initial_price  game_current_discount  \\\n",
      "2693               999.0               999.0                    0.0   \n",
      "2694               499.0               499.0                    0.0   \n",
      "2695               499.0               499.0                    0.0   \n",
      "2696               499.0               499.0                    0.0   \n",
      "2697               499.0               499.0                    0.0   \n",
      "\n",
      "     game_concurrent_user game_estimate_owners_lower  \\\n",
      "2693                13421                   10000000   \n",
      "2694                   74                    5000000   \n",
      "2695                  105                    5000000   \n",
      "2696                    3                     100000   \n",
      "2697                  107                    2000000   \n",
      "\n",
      "     game_estimate_owners_upper  \n",
      "2693                   20000000  \n",
      "2694                   10000000  \n",
      "2695                   10000000  \n",
      "2696                     200000  \n",
      "2697                    5000000  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train_raw = joblib.load(raw_train_file_path_local)\n",
    "df_test_raw = joblib.load(raw_test_file_path_local)\n",
    "print(\"Training data loaded successfully!\")\n",
    "print(\"Training data shape:\", df_train_raw.shape)\n",
    "print(\"\\nFirst few rows of training data (as DataFrame):\\n\", df_train_raw.head())  # Print the first 5 rows of the DataFrame\n",
    "print(\"\\nTesting data loaded successfully!\")\n",
    "print(\"Testing data shape:\", df_test_raw.shape)\n",
    "print(\"\\nFirst few rows of testing data (as DataFrame):\\n\", df_test_raw.head())  # Print the first 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22190c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'app_id', 'relevance_score', 'user_country_code',\n",
       "       'user_has_coordinates', 'user_latitude', 'user_longitude',\n",
       "       'user_account_age_months', 'game_name', 'game_tba',\n",
       "       'game_RAWG_weighted_avg_rating', 'game_RAWG_ratings_count',\n",
       "       'game_RAWG_reviews_with_text_count', 'game_RAWG_bookmark_count',\n",
       "       'game_metacritic_rating', 'game_RAWG_system_suggest_count',\n",
       "       'game_RAWG_reviews_count', 'game_genres', 'game_tags',\n",
       "       'game_esrb_rating', 'game_released_year', 'game_released_month',\n",
       "       'game_released_day', 'game_RAWG_rating_5_percent',\n",
       "       'game_RAWG_rating_4_percent', 'game_RAWG_rating_3_percent',\n",
       "       'game_RAWG_rating_1_percent', 'game_RAWG_bookmark_type_yet_count',\n",
       "       'game_RAWG_bookmark_type_owned_count',\n",
       "       'game_RAWG_bookmark_type_beaten_count',\n",
       "       'game_RAWG_bookmark_type_toplay_count',\n",
       "       'game_RAWG_bookmark_type_dropped_count',\n",
       "       'game_RAWG_bookmark_type_playing_count', 'game_available_platform',\n",
       "       'game_available_parent_platforms', 'game_developer', 'game_publisher',\n",
       "       'game_positive_review_count', 'game_negative_review_count',\n",
       "       'game_avg_user_score', 'game_avg_playtime_forever',\n",
       "       'game_avg_playtime_last_2weeks', 'game_median_playtime_forever',\n",
       "       'game_median_last_2weeks', 'game_current_price', 'game_initial_price',\n",
       "       'game_current_discount', 'game_concurrent_user',\n",
       "       'game_estimate_owners_lower', 'game_estimate_owners_upper'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "830b345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully!\n",
      "Training data shape: (2643279, 130)\n",
      "\n",
      "First few rows of training data (as DataFrame):\n",
      "              user_id  app_id  relevance_score user_country_code  \\\n",
      "0  76561198073669602    4000         0.641805           Missing   \n",
      "1  76561198073669602    2590         0.000000           Missing   \n",
      "2  76561198073669602   11200         0.734365           Missing   \n",
      "3  76561198073669602      20         0.000000           Missing   \n",
      "4  76561198073669602      50         0.000000           Missing   \n",
      "\n",
      "   user_has_coordinates  user_latitude  user_longitude  \\\n",
      "0                 False       0.013426        0.127397   \n",
      "1                 False       0.013426        0.127397   \n",
      "2                 False       0.013426        0.127397   \n",
      "3                 False       0.013426        0.127397   \n",
      "4                 False       0.013426        0.127397   \n",
      "\n",
      "   user_account_age_months                  game_name  game_tba  ...  \\\n",
      "0                -0.931663                Garry's Mod     False  ...   \n",
      "1                -0.931663                Alpha Prime     False  ...   \n",
      "2                -0.931663     Shadowgrounds Survivor     False  ...   \n",
      "3                -0.931663      Team Fortress Classic     False  ...   \n",
      "4                -0.931663  Half-Life: Opposing Force     False  ...   \n",
      "\n",
      "   user_preference_game_platforms_Neo Geo  \\\n",
      "0                               -0.911519   \n",
      "1                               -0.911519   \n",
      "2                               -0.911519   \n",
      "3                               -0.911519   \n",
      "4                               -0.911519   \n",
      "\n",
      "   user_preference_game_platforms_Nintendo  \\\n",
      "0                                 1.743753   \n",
      "1                                 1.743753   \n",
      "2                                 1.743753   \n",
      "3                                 1.743753   \n",
      "4                                 1.743753   \n",
      "\n",
      "   user_preference_game_platforms_PlayStation  \\\n",
      "0                                    1.076329   \n",
      "1                                    1.076329   \n",
      "2                                    1.076329   \n",
      "3                                    1.076329   \n",
      "4                                    1.076329   \n",
      "\n",
      "   user_preference_game_platforms_SEGA  user_preference_game_platforms_Web  \\\n",
      "0                            -0.409947                           -0.197966   \n",
      "1                            -0.409947                           -0.197966   \n",
      "2                            -0.409947                           -0.197966   \n",
      "3                            -0.409947                           -0.197966   \n",
      "4                            -0.409947                           -0.197966   \n",
      "\n",
      "   user_preference_game_platforms_Xbox  user_preference_game_platforms_iOS  \\\n",
      "0                             0.978062                            0.585206   \n",
      "1                             0.978062                            0.585206   \n",
      "2                             0.978062                            0.585206   \n",
      "3                             0.978062                            0.585206   \n",
      "4                             0.978062                            0.585206   \n",
      "\n",
      "  game_released_year_since_1984.0                                  user_emb  \\\n",
      "0                       -1.802417  [1.8855448961257935, 0.7624592781066895]   \n",
      "1                       -1.569513  [1.8855448961257935, 0.7624592781066895]   \n",
      "2                       -1.437791  [1.8855448961257935, 0.7624592781066895]   \n",
      "3                       -2.225046  [1.8855448961257935, 0.7624592781066895]   \n",
      "4                       -2.225046  [1.8855448961257935, 0.7624592781066895]   \n",
      "\n",
      "                                      game_emb  \n",
      "0    [0.6941275000572205, -0.6239486336708069]  \n",
      "1  [0.03067554160952568, 0.005427324678748846]  \n",
      "2  [0.12914691865444183, -0.07241964340209961]  \n",
      "3   [0.3241513967514038, -0.26820915937423706]  \n",
      "4    [0.3962540030479431, -0.3395841419696808]  \n",
      "\n",
      "[5 rows x 130 columns]\n",
      "\n",
      "Testing data loaded successfully!\n",
      "Testing data shape: (694120, 130)\n",
      "\n",
      "First few rows of testing data (as DataFrame):\n",
      "              user_id  app_id  relevance_score user_country_code  \\\n",
      "0  76561197960304100      10         0.698825                CL   \n",
      "1  76561197960304100      20         0.000000                CL   \n",
      "2  76561197960304100      30         0.000000                CL   \n",
      "3  76561197960304100      40         0.000000                CL   \n",
      "4  76561197960304100      50         0.000000                CL   \n",
      "\n",
      "   user_has_coordinates  user_latitude  user_longitude  \\\n",
      "0                  True      -2.666991       -1.134554   \n",
      "1                  True      -2.666991       -1.134554   \n",
      "2                  True      -2.666991       -1.134554   \n",
      "3                  True      -2.666991       -1.134554   \n",
      "4                  True      -2.666991       -1.134554   \n",
      "\n",
      "   user_account_age_months                  game_name  game_tba  ...  \\\n",
      "0                 1.964785             Counter-Strike     False  ...   \n",
      "1                 1.964785      Team Fortress Classic     False  ...   \n",
      "2                 1.964785              Day of Defeat     False  ...   \n",
      "3                 1.964785         Deathmatch Classic     False  ...   \n",
      "4                 1.964785  Half-Life: Opposing Force     False  ...   \n",
      "\n",
      "   user_preference_game_platforms_Neo Geo  \\\n",
      "0                               -0.911519   \n",
      "1                               -0.911519   \n",
      "2                               -0.911519   \n",
      "3                               -0.911519   \n",
      "4                               -0.911519   \n",
      "\n",
      "   user_preference_game_platforms_Nintendo  \\\n",
      "0                                -0.933219   \n",
      "1                                -0.933219   \n",
      "2                                -0.933219   \n",
      "3                                -0.933219   \n",
      "4                                -0.933219   \n",
      "\n",
      "   user_preference_game_platforms_PlayStation  \\\n",
      "0                                   -0.372465   \n",
      "1                                   -0.372465   \n",
      "2                                   -0.372465   \n",
      "3                                   -0.372465   \n",
      "4                                   -0.372465   \n",
      "\n",
      "   user_preference_game_platforms_SEGA  user_preference_game_platforms_Web  \\\n",
      "0                             1.893516                           -0.065732   \n",
      "1                             1.893516                           -0.065732   \n",
      "2                             1.893516                           -0.065732   \n",
      "3                             1.893516                           -0.065732   \n",
      "4                             1.893516                           -0.065732   \n",
      "\n",
      "   user_preference_game_platforms_Xbox  user_preference_game_platforms_iOS  \\\n",
      "0                            -0.225288                           -1.451573   \n",
      "1                            -0.225288                           -1.451573   \n",
      "2                            -0.225288                           -1.451573   \n",
      "3                            -0.225288                           -1.451573   \n",
      "4                            -0.225288                           -1.451573   \n",
      "\n",
      "  game_released_year_since_1984.0                                   user_emb  \\\n",
      "0                       -2.157159  [0.7054241895675659, 0.23045143485069275]   \n",
      "1                       -2.225046  [0.7054241895675659, 0.23045143485069275]   \n",
      "2                       -1.904388  [0.7054241895675659, 0.23045143485069275]   \n",
      "3                       -2.081358  [0.7054241895675659, 0.23045143485069275]   \n",
      "4                       -2.225046  [0.7054241895675659, 0.23045143485069275]   \n",
      "\n",
      "                                      game_emb  \n",
      "0  [0.48835909366607666, -0.42478129267692566]  \n",
      "1   [0.3241513967514038, -0.26820915937423706]  \n",
      "2  [0.20189513266086578, -0.15428879857063293]  \n",
      "3   [0.18785971403121948, -0.1463390737771988]  \n",
      "4    [0.3962540030479431, -0.3395841419696808]  \n",
      "\n",
      "[5 rows x 130 columns]\n",
      "Index(['user_id', 'app_id', 'relevance_score', 'user_country_code',\n",
      "       'user_has_coordinates', 'user_latitude', 'user_longitude',\n",
      "       'user_account_age_months', 'game_name', 'game_tba',\n",
      "       ...\n",
      "       'user_preference_game_platforms_Neo Geo',\n",
      "       'user_preference_game_platforms_Nintendo',\n",
      "       'user_preference_game_platforms_PlayStation',\n",
      "       'user_preference_game_platforms_SEGA',\n",
      "       'user_preference_game_platforms_Web',\n",
      "       'user_preference_game_platforms_Xbox',\n",
      "       'user_preference_game_platforms_iOS', 'game_released_year_since_1984.0',\n",
      "       'user_emb', 'game_emb'],\n",
      "      dtype='object', length=130)\n"
     ]
    }
   ],
   "source": [
    "df_train_ready = joblib.load(train_file_path_local)\n",
    "df_test_ready = joblib.load(test_file_path_local)\n",
    "print(\"Training data loaded successfully!\")\n",
    "print(\"Training data shape:\", df_train_ready.shape)\n",
    "print(\"\\nFirst few rows of training data (as DataFrame):\\n\", df_train_ready.head())  # Print the first 5 rows of the DataFrame\n",
    "print(\"\\nTesting data loaded successfully!\")\n",
    "print(\"Testing data shape:\", df_test_ready.shape)\n",
    "print(\"\\nFirst few rows of testing data (as DataFrame):\\n\", df_test_ready.head())  # Print the first 5 rows of the DataFrame\n",
    "print(df_train_ready.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f2a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sys\n",
    "# import io # To capture info output if needed\n",
    "\n",
    "# def examine_dataframe(df, df_name=\"DataFrame\"):\n",
    "#     \"\"\"\n",
    "#     Prints comprehensive information about a pandas DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): The DataFrame to examine.\n",
    "#         df_name (str): The name of the DataFrame for printing headers.\n",
    "#     \"\"\"\n",
    "#     print(\"=\" * 70)\n",
    "#     print(f\"Examining: {df_name}\")\n",
    "#     print(\"=\" * 70)\n",
    "\n",
    "#     # --- Basic Checks ---\n",
    "#     if df is None:\n",
    "#         print(\"[INFO] DataFrame object is None.\")\n",
    "#         print(\"=\" * 70 + \"\\n\")\n",
    "#         return\n",
    "#     if not isinstance(df, pd.DataFrame):\n",
    "#         print(f\"[ERROR] Object '{df_name}' is not a pandas DataFrame (Type: {type(df)}). Cannot examine.\")\n",
    "#         print(\"=\" * 70 + \"\\n\")\n",
    "#         return\n",
    "#     if df.empty:\n",
    "#         print(\"[INFO] DataFrame is empty.\")\n",
    "#         print(\"=\" * 70 + \"\\n\")\n",
    "#         return\n",
    "\n",
    "#     # --- Examination Steps ---\n",
    "#     try:\n",
    "#         # 1. Shape\n",
    "#         print(\"\\n--- Shape ---\")\n",
    "#         print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "#         # 2. Info (Data Types, Non-Null Counts, Memory Usage)\n",
    "#         print(\"\\n--- Info ---\")\n",
    "#         # Capture info output to prevent it from truncating in some environments\n",
    "#         buffer = io.StringIO()\n",
    "#         df.info(verbose=True, show_counts=True, buf=buffer)\n",
    "#         info_str = buffer.getvalue()\n",
    "#         print(info_str)\n",
    "\n",
    "#         # 3. Head (First 5 Rows) - Display more columns temporarily\n",
    "#         print(\"\\n--- Head (First 5 Rows) ---\")\n",
    "#         with pd.option_context('display.max_rows', 5, 'display.max_columns', None, 'display.width', 1000):\n",
    "#             print(df.head())\n",
    "\n",
    "#         # 4. Tail (Last 5 Rows) - Useful for comparison\n",
    "#         print(\"\\n--- Tail (Last 5 Rows) ---\")\n",
    "#         with pd.option_context('display.max_rows', 5, 'display.max_columns', None, 'display.width', 1000):\n",
    "#             print(df.tail())\n",
    "\n",
    "#         # 5. Describe (Statistical Summary - including categorical/object)\n",
    "#         print(\"\\n--- Describe (Statistics) ---\")\n",
    "#         # include='all' provides stats for object/category columns too\n",
    "#         described_df = df.describe(include='all').transpose()\n",
    "#         with pd.option_context('display.max_rows', described_df.shape[0], 'display.max_columns', described_df.shape[1], 'display.width', 1000):\n",
    "#              print(described_df)\n",
    "\n",
    "#         # 6. Value Counts for Object/Category Columns (Sample)\n",
    "#         print(\"\\n--- Value Counts (Sample for Low-Cardinality Object/Category Columns) ---\")\n",
    "#         MAX_UNIQUE_FOR_VALUE_COUNTS = 50 # Only show full counts for columns below this\n",
    "#         MAX_COLS_TO_SHOW_VC = 10       # Limit how many columns we run value_counts on\n",
    "#         cols_to_check = df.select_dtypes(include=['object', 'category']).columns\n",
    "#         checked_count = 0\n",
    "\n",
    "#         if not cols_to_check.empty:\n",
    "#             print(f\"[INFO] Checking first {min(len(cols_to_check), MAX_COLS_TO_SHOW_VC)} object/category columns for value counts...\")\n",
    "#             for col in cols_to_check:\n",
    "#                 if checked_count >= MAX_COLS_TO_SHOW_VC:\n",
    "#                     print(f\"\\n[INFO] Reached limit ({MAX_COLS_TO_SHOW_VC}) for showing value counts.\")\n",
    "#                     break\n",
    "#                 print(f\"\\n--- Value Counts: '{col}' ---\")\n",
    "#                 try:\n",
    "#                     # Handle potential presence of lists/unhashable types gracefully\n",
    "#                     if any(isinstance(i, (list, dict, set)) for i in df[col].head(100).dropna()):\n",
    "#                          print(\"[INFO] Column seems to contain unhashable types (e.g., lists). Skipping detailed value counts.\")\n",
    "#                          # Optionally show type distribution if lists are present\n",
    "#                          print(\"Type distribution (sample):\")\n",
    "#                          print(df[col].apply(type).value_counts())\n",
    "#                     else:\n",
    "#                         unique_count = df[col].nunique()\n",
    "#                         print(f\"Unique values: {unique_count}\")\n",
    "\n",
    "#                         if unique_count == 0:\n",
    "#                              print(\"No non-null values found.\")\n",
    "#                         elif unique_count < MAX_UNIQUE_FOR_VALUE_COUNTS:\n",
    "#                             print(df[col].value_counts(dropna=False)) # Include NaNs in count\n",
    "#                         else:\n",
    "#                             # Show top 5 most frequent for high cardinality\n",
    "#                             print(f\"(Top 5 values for high cardinality column):\")\n",
    "#                             print(df[col].value_counts(dropna=False).head(5))\n",
    "#                     checked_count += 1\n",
    "#                 except Exception as e_vc:\n",
    "#                     print(f\"[ERROR] Could not get value counts for '{col}': {e_vc}\")\n",
    "#         else:\n",
    "#             print(\"[INFO] No object or category columns found.\")\n",
    "\n",
    "#     except Exception as e_main:\n",
    "#          print(f\"\\n[ERROR] An error occurred during examination of {df_name}: {e_main}\")\n",
    "#          import traceback\n",
    "#          print(traceback.format_exc())\n",
    "\n",
    "#     finally:\n",
    "#         print(\"\\n\" + \"=\" * 70)\n",
    "#         print(f\"Finished Examining: {df_name}\")\n",
    "#         print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# # --- Main Execution ---\n",
    "\n",
    "# print(\"*\"*30 + \" Examining df_train_raw \" + \"*\"*30)\n",
    "# # Check if the variable exists in the global namespace\n",
    "# if 'df_train_raw' in locals() or 'df_train_raw' in globals():\n",
    "#     examine_dataframe(df_train_raw, \"df_train_raw (Before Feature Engineering)\")\n",
    "# else:\n",
    "#     print(\"[WARN] DataFrame 'df_train_raw' not found in the current environment.\")\n",
    "\n",
    "# print(\"\\n\" + \"*\"*30 + \" Examining df_train_ready \" + \"*\"*30)\n",
    "# # Check if the variable exists in the global namespace\n",
    "# if 'df_train_ready' in locals() or 'df_train_ready' in globals():\n",
    "#     examine_dataframe(df_train_ready, \"df_train_ready (After Feature Engineering)\")\n",
    "# else:\n",
    "#     print(\"[WARN] DataFrame 'df_train_ready' not found in the current environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4ebaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.643279e+06\n",
      "mean     2.774212e-01\n",
      "std      3.482629e-01\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      6.021035e-01\n",
      "max      9.999999e-01\n",
      "Name: relevance_score, dtype: float64\n",
      "Axes(0.125,0.11;0.775x0.77)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_train_raw['relevance_score'].describe())\n",
    "print(df_train_raw['relevance_score'].hist(bins=50)) # Visualize the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add68555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c24bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting preprocessing pipeline (Borrowing Embeddings from df_train_ready)...\n",
      "----------------------------------------------------------------------\n",
      "[INFO] Creating copy of df_train_raw...\n",
      "[INFO] Copy created.\n",
      "[INFO] Separating target variable 'relevance_score'...\n",
      "[SUCCESS] Separated 'relevance_score'.\n",
      "[INFO] Dropping initial set of unused/redundant columns (keeping merge keys)...\n",
      "[INFO] Columns remaining after initial drop: 23\n",
      "\n",
      "[PHASE 0] Borrowing & Merging Embeddings from df_train_ready...\n",
      "  Extracting embedding columns from df_train_ready...\n",
      "  Extracted 2595694 unique user/app embedding rows.\n",
      "    Determined embedding dimension: 2\n",
      "    Using fill value for missing embeddings: [0.0, 0.0]\n",
      "  Merging embeddings onto X_train...\n",
      "  [SUCCESS] Embeddings borrowed and merged.\n",
      "[PHASE 0] Completed.\n",
      "\n",
      "[PHASE 1] Flattening Embeddings (if available)...\n",
      "  [INFO] Processing column: user_emb...\n",
      "  [SUCCESS] Flattened 'user_emb' into ['user_emb_0', 'user_emb_1'].\n",
      "  [INFO] Processing column: game_emb...\n",
      "  [SUCCESS] Flattened 'game_emb' into ['game_emb_0', 'game_emb_1'].\n",
      "[PHASE 1] Completed.\n",
      "\n",
      "[PHASE 2] Processing Game Tags (Top N)...\n",
      "  Calculating tag frequencies for Top 500...\n",
      "  Found 2501 unique tags. Keeping top 500.\n",
      "  Applying Binarizer for Top 500 tags...\n",
      "  [SUCCESS] Processed 'game_tags'. Added 500 boolean features.\n",
      "[PHASE 2] Completed.\n",
      "\n",
      "[PHASE 3] Processing Game Genres (Binarize)...\n",
      "  Applying Binarizer for 'game_genres'...\n",
      "  [SUCCESS] Processed 'game_genres'. Added 19 boolean features.\n",
      "[PHASE 3] Completed.\n",
      "\n",
      "[PHASE 4] Processing Platforms (Binarize)...\n",
      "  Applying Binarizer for 'game_available_platform'...\n",
      "  [SUCCESS] Processed 'game_available_platform'. Added 47 boolean features.\n",
      "[PHASE 4] Completed.\n",
      "\n",
      "[PHASE 5] Extracting Strings & Processing Dev/Publisher (Top N + Category)...\n",
      "  [INFO] Extracting string from 'game_developer'...\n",
      "  [SUCCESS] Extracted strings for 'game_developer'.\n",
      "  [INFO] Extracting string from 'game_publisher'...\n",
      "  [SUCCESS] Extracted strings for 'game_publisher'.\n",
      "  [INFO] Applying Top 150 / Other to 'game_developer'...\n",
      "  [SUCCESS] Applied Top 150 / Other to 'game_developer'. Now has 151 unique values.\n",
      "  [INFO] Applying Top 150 / Other to 'game_publisher'...\n",
      "  [SUCCESS] Applied Top 150 / Other to 'game_publisher'. Now has 151 unique values.\n",
      "  [INFO] Converting 'game_developer' to category dtype...\n",
      "  [SUCCESS] Converted 'game_developer' to category.\n",
      "  [INFO] Converting 'game_publisher' to category dtype...\n",
      "  [SUCCESS] Converted 'game_publisher' to category.\n",
      "[PHASE 5] Completed.\n",
      "\n",
      "[PHASE 6] Processing Other Categoricals (Category)...\n",
      "  [INFO] Processing 'user_country_code'...\n",
      "  [SUCCESS] Converted 'user_country_code' to category.\n",
      "  [INFO] Processing 'game_esrb_rating'...\n",
      "  [SUCCESS] Converted 'game_esrb_rating' to category.\n",
      "[PHASE 6] Completed.\n",
      "\n",
      "[PHASE 7] Processing Numerical Features (Imputation)...\n",
      "  [INFO] Imputing selected numerical columns...\n",
      "    Imputed NaNs in: ['game_current_price', 'game_initial_price']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/vvs7t0hs4j95wv7lbj2095940000gn/T/ipykernel_8502/1595243090.py:399: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n",
      "/var/folders/f1/vvs7t0hs4j95wv7lbj2095940000gn/T/ipykernel_8502/1595243090.py:399: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PHASE 7] Completed.\n",
      "\n",
      "[PHASE 8] Processing Date Feature...\n",
      "  [INFO] Processing 'game_released_year'...\n",
      "    Imputed NaNs in 'game_released_year' with median (2015).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/vvs7t0hs4j95wv7lbj2095940000gn/T/ipykernel_8502/1595243090.py:423: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[date_col].fillna(median_year, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [SUCCESS] Created 'game_released_year_since_1984' and dropped original.\n",
      "[PHASE 8] Completed.\n",
      "\n",
      "[PHASE 9] Final Check & Info...\n",
      "  [INFO] Checking final columns and types...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2643279 entries, 0 to 2643278\n",
      "Data columns (total 588 columns):\n",
      " #    Column                                 Non-Null Count    Dtype   \n",
      "---   ------                                 --------------    -----   \n",
      " 0    user_country_code                      2643279 non-null  category\n",
      " 1    user_account_age_months                2643279 non-null  float64 \n",
      " 2    game_RAWG_weighted_avg_rating          2643279 non-null  float64 \n",
      " 3    game_RAWG_ratings_count                2643279 non-null  float64 \n",
      " 4    game_RAWG_bookmark_count               2643279 non-null  float64 \n",
      " 5    game_esrb_rating                       2643279 non-null  category\n",
      " 6    game_developer                         2643279 non-null  category\n",
      " 7    game_publisher                         2643279 non-null  category\n",
      " 8    game_positive_review_count             2643279 non-null  float64 \n",
      " 9    game_negative_review_count             2643279 non-null  float64 \n",
      " 10   game_avg_playtime_forever              2643279 non-null  float64 \n",
      " 11   game_median_playtime_forever           2643279 non-null  float64 \n",
      " 12   game_current_price                     2643279 non-null  float64 \n",
      " 13   game_initial_price                     2643279 non-null  float64 \n",
      " 14   game_concurrent_user                   2643279 non-null  float64 \n",
      " 15   game_estimate_owners_lower             2643279 non-null  float64 \n",
      " 16   game_estimate_owners_upper             2643279 non-null  float64 \n",
      " 17   user_emb_0                             2643279 non-null  float64 \n",
      " 18   user_emb_1                             2643279 non-null  float64 \n",
      " 19   game_emb_0                             2643279 non-null  float64 \n",
      " 20   game_emb_1                             2643279 non-null  float64 \n",
      " 21   tag_Singleplayer                       2643279 non-null  bool    \n",
      " 22   tag_Steam Achievements                 2643279 non-null  bool    \n",
      " 23   tag_Multiplayer                        2643279 non-null  bool    \n",
      " 24   tag_steam-trading-cards                2643279 non-null  bool    \n",
      " 25   tag_Steam Cloud                        2643279 non-null  bool    \n",
      " 26   tag_Full controller support            2643279 non-null  bool    \n",
      " 27   tag_Atmospheric                        2643279 non-null  bool    \n",
      " 28   tag_RPG                                2643279 non-null  bool    \n",
      " 29   tag_Co-op                              2643279 non-null  bool    \n",
      " 30   tag_Great Soundtrack                   2643279 non-null  bool    \n",
      " 31   tag_2D                                 2643279 non-null  bool    \n",
      " 32   tag_cooperative                        2643279 non-null  bool    \n",
      " 33   tag_Partial Controller Support         2643279 non-null  bool    \n",
      " 34   tag_First-Person                       2643279 non-null  bool    \n",
      " 35   tag_Story Rich                         2643279 non-null  bool    \n",
      " 36   tag_Open World                         2643279 non-null  bool    \n",
      " 37   tag_Horror                             2643279 non-null  bool    \n",
      " 38   tag_Sci-fi                             2643279 non-null  bool    \n",
      " 39   tag_FPS                                2643279 non-null  bool    \n",
      " 40   tag_Steam Leaderboards                 2643279 non-null  bool    \n",
      " 41   tag_Online Co-Op                       2643279 non-null  bool    \n",
      " 42   tag_Funny                              2643279 non-null  bool    \n",
      " 43   tag_Third Person                       2643279 non-null  bool    \n",
      " 44   tag_Difficult                          2643279 non-null  bool    \n",
      " 45   tag_Fantasy                            2643279 non-null  bool    \n",
      " 46   tag_Free to Play                       2643279 non-null  bool    \n",
      " 47   tag_Gore                               2643279 non-null  bool    \n",
      " 48   tag_Classic                            2643279 non-null  bool    \n",
      " 49   tag_Female Protagonist                 2643279 non-null  bool    \n",
      " 50   tag_Survival                           2643279 non-null  bool    \n",
      " 51   tag_Comedy                             2643279 non-null  bool    \n",
      " 52   tag_Sandbox                            2643279 non-null  bool    \n",
      " 53   tag_Online multiplayer                 2643279 non-null  bool    \n",
      " 54   tag_Early Access                       2643279 non-null  bool    \n",
      " 55   tag_Split Screen                       2643279 non-null  bool    \n",
      " 56   tag_Pixel Graphics                     2643279 non-null  bool    \n",
      " 57   tag_Exploration                        2643279 non-null  bool    \n",
      " 58   tag_stats                              2643279 non-null  bool    \n",
      " 59   tag_Violent                            2643279 non-null  bool    \n",
      " 60   tag_Local Co-Op                        2643279 non-null  bool    \n",
      " 61   tag_Retro                              2643279 non-null  bool    \n",
      " 62   tag_Local Multiplayer                  2643279 non-null  bool    \n",
      " 63   tag_Tactical                           2643279 non-null  bool    \n",
      " 64   tag_Anime                              2643279 non-null  bool    \n",
      " 65   tag_Cross-Platform Multiplayer         2643279 non-null  bool    \n",
      " 66   tag_Point & Click                      2643279 non-null  bool    \n",
      " 67   tag_Steam Workshop                     2643279 non-null  bool    \n",
      " 68   tag_Includes level editor              2643279 non-null  bool    \n",
      " 69   tag_Controller                         2643279 non-null  bool    \n",
      " 70   tag_Space                              2643279 non-null  bool    \n",
      " 71   tag_PvP                                2643279 non-null  bool    \n",
      " 72   tag_Stealth                            2643279 non-null  bool    \n",
      " 73   tag_Action RPG                         2643279 non-null  bool    \n",
      " 74   tag_Zombies                            2643279 non-null  bool    \n",
      " 75   tag_In-App Purchases                   2643279 non-null  bool    \n",
      " 76   tag_Turn-Based                         2643279 non-null  bool    \n",
      " 77   tag_Third-Person Shooter               2643279 non-null  bool    \n",
      " 78   tag_Family Friendly                    2643279 non-null  bool    \n",
      " 79   tag_Dark                               2643279 non-null  bool    \n",
      " 80   tag_Cute                               2643279 non-null  bool    \n",
      " 81   tag_Action-Adventure                   2643279 non-null  bool    \n",
      " 82   tag_Nudity                             2643279 non-null  bool    \n",
      " 83   tag_War                                2643279 non-null  bool    \n",
      " 84   tag_VR                                 2643279 non-null  bool    \n",
      " 85   tag_Moddable                           2643279 non-null  bool    \n",
      " 86   tag_Survival Horror                    2643279 non-null  bool    \n",
      " 87   tag_Hack and Slash                     2643279 non-null  bool    \n",
      " 88   tag_Captions available                 2643279 non-null  bool    \n",
      " 89   tag_Short                              2643279 non-null  bool    \n",
      " 90   tag_Mystery                            2643279 non-null  bool    \n",
      " 91   tag_Replay Value                       2643279 non-null  bool    \n",
      " 92   tag_Physics                            2643279 non-null  bool    \n",
      " 93   tag_RTS                                2643279 non-null  bool    \n",
      " 94   tag_Colorful                           2643279 non-null  bool    \n",
      " 95   tag_role-playing                       2643279 non-null  bool    \n",
      " 96   tag_Realistic                          2643279 non-null  bool    \n",
      " 97   tag_3D                                 2643279 non-null  bool    \n",
      " 98   tag_Character Customization            2643279 non-null  bool    \n",
      " 99   tag_Roguelike                          2643279 non-null  bool    \n",
      " 100  tag_Post-apocalyptic                   2643279 non-null  bool    \n",
      " 101  tag_Historical                         2643279 non-null  bool    \n",
      " 102  tag_Team-Based                         2643279 non-null  bool    \n",
      " 103  tag_controller support                 2643279 non-null  bool    \n",
      " 104  tag_Side Scroller                      2643279 non-null  bool    \n",
      " 105  tag_Fast-Paced                         2643279 non-null  bool    \n",
      " 106  tag_Crafting                           2643279 non-null  bool    \n",
      " 107  tag_Turn-Based Strategy                2643279 non-null  bool    \n",
      " 108  tag_Building                           2643279 non-null  bool    \n",
      " 109  tag_Military                           2643279 non-null  bool    \n",
      " 110  tag_mmo                                2643279 non-null  bool    \n",
      " 111  tag_Valve Anti-Cheat enabled           2643279 non-null  bool    \n",
      " 112  tag_Competitive                        2643279 non-null  bool    \n",
      " 113  tag_Top-Down                           2643279 non-null  bool    \n",
      " 114  tag_Shoot 'Em Up                       2643279 non-null  bool    \n",
      " 115  tag_Choices Matter                     2643279 non-null  bool    \n",
      " 116  tag_Isometric                          2643279 non-null  bool    \n",
      " 117  tag_Memes                              2643279 non-null  bool    \n",
      " 118  tag_Medieval                           2643279 non-null  bool    \n",
      " 119  tag_Visual Novel                       2643279 non-null  bool    \n",
      " 120  tag_Mature                             2643279 non-null  bool    \n",
      " 121  tag_Management                         2643279 non-null  bool    \n",
      " 122  tag_Walking Simulator                  2643279 non-null  bool    \n",
      " 123  tag_Aliens                             2643279 non-null  bool    \n",
      " 124  tag_Dark Fantasy                       2643279 non-null  bool    \n",
      " 125  tag_Futuristic                         2643279 non-null  bool    \n",
      " 126  tag_Relaxing                           2643279 non-null  bool    \n",
      " 127  tag_combat                             2643279 non-null  bool    \n",
      " 128  tag_Sexual Content                     2643279 non-null  bool    \n",
      " 129  tag_Cyberpunk                          2643279 non-null  bool    \n",
      " 130  tag_Beat 'em up                        2643279 non-null  bool    \n",
      " 131  tag_Roguelite                          2643279 non-null  bool    \n",
      " 132  tag_Magic                              2643279 non-null  bool    \n",
      " 133  tag_Multiple Endings                   2643279 non-null  bool    \n",
      " 134  tag_World War II                       2643279 non-null  bool    \n",
      " 135  tag_Online PvP                         2643279 non-null  bool    \n",
      " 136  tag_Tower Defense                      2643279 non-null  bool    \n",
      " 137  tag_MMORPG                             2643279 non-null  bool    \n",
      " 138  tag_JRPG                               2643279 non-null  bool    \n",
      " 139  tag_Metroidvania                       2643279 non-null  bool    \n",
      " 140  tag_Base Building                      2643279 non-null  bool    \n",
      " 141  tag_Parkour                            2643279 non-null  bool    \n",
      " 142  tag_Crime                              2643279 non-null  bool    \n",
      " 143  tag_Dungeon Crawler                    2643279 non-null  bool    \n",
      " 144  tag_Bullet Hell                        2643279 non-null  bool    \n",
      " 145  tag_Surreal                            2643279 non-null  bool    \n",
      " 146  tag_1990's                             2643279 non-null  bool    \n",
      " 147  tag_Puzzle-Platformer                  2643279 non-null  bool    \n",
      " 148  tag_Procedural Generation              2643279 non-null  bool    \n",
      " 149  tag_Robots                             2643279 non-null  bool    \n",
      " 150  tag_Cinematic                          2643279 non-null  bool    \n",
      " 151  tag_Music                              2643279 non-null  bool    \n",
      " 152  tag_Stylized                           2643279 non-null  bool    \n",
      " 153  tag_RPG Maker                          2643279 non-null  bool    \n",
      " 154  tag_Detective                          2643279 non-null  bool    \n",
      " 155  tag_RPGMaker                           2643279 non-null  bool    \n",
      " 156  tag_overlay                            2643279 non-null  bool    \n",
      " 157  tag_Remake                             2643279 non-null  bool    \n",
      " 158  tag_Dystopian                          2643279 non-null  bool    \n",
      " 159  tag_Driving                            2643279 non-null  bool    \n",
      " 160  tag_Dark Humor                         2643279 non-null  bool    \n",
      " 161  tag_Steampunk                          2643279 non-null  bool    \n",
      " 162  tag_Cartoony                           2643279 non-null  bool    \n",
      " 163  tag_PvE                                2643279 non-null  bool    \n",
      " 164  tag_3D Platformer                      2643279 non-null  bool    \n",
      " 165  tag_4 Player Local                     2643279 non-null  bool    \n",
      " 166  tag_3D Vision                          2643279 non-null  bool    \n",
      " 167  tag_Linear                             2643279 non-null  bool    \n",
      " 168  tag_Hidden Object                      2643279 non-null  bool    \n",
      " 169  tag_Hand-drawn                         2643279 non-null  bool    \n",
      " 170  tag_Steam Trading Cards                2643279 non-null  bool    \n",
      " 171  tag_Minimalist                         2643279 non-null  bool    \n",
      " 172  tag_Resource Management                2643279 non-null  bool    \n",
      " 173  tag_Economy                            2643279 non-null  bool    \n",
      " 174  tag_Story                              2643279 non-null  bool    \n",
      " 175  tag_Destruction                        2643279 non-null  bool    \n",
      " 176  tag_Card Game                          2643279 non-null  bool    \n",
      " 177  tag_achievements                       2643279 non-null  bool    \n",
      " 178  tag_Turn-Based Tactics                 2643279 non-null  bool    \n",
      " 179  tag_Turn-Based Combat                  2643279 non-null  bool    \n",
      " 180  tag_Perma Death                        2643279 non-null  bool    \n",
      " 181  tag_Loot                               2643279 non-null  bool    \n",
      " 182  tag_Blood                              2643279 non-null  bool    \n",
      " 183  tag_Education                          2643279 non-null  bool    \n",
      " 184  tag_puzzles                            2643279 non-null  bool    \n",
      " 185  tag_Kickstarter                        2643279 non-null  bool    \n",
      " 186  tag_Real-Time with Pause               2643279 non-null  bool    \n",
      " 187  tag_Top-Down Shooter                   2643279 non-null  bool    \n",
      " 188  tag_City Builder                       2643279 non-null  bool    \n",
      " 189  tag_Touch-Friendly                     2643279 non-null  bool    \n",
      " 190  tag_Romance                            2643279 non-null  bool    \n",
      " 191  tag_Grand Strategy                     2643279 non-null  bool    \n",
      " 192  tag_2.5D                               2643279 non-null  bool    \n",
      " 193  tag_4X                                 2643279 non-null  bool    \n",
      " 194  tag_Drama                              2643279 non-null  bool    \n",
      " 195  tag_Commentary available               2643279 non-null  bool    \n",
      " 196  tag_Cult Classic                       2643279 non-null  bool    \n",
      " 197  tag_Twin Stick Shooter                 2643279 non-null  bool    \n",
      " 198  tag_Narration                          2643279 non-null  bool    \n",
      " 199  tag_Level Editor                       2643279 non-null  bool    \n",
      " 200  tag_Demons                             2643279 non-null  bool    \n",
      " 201  tag_Board Game                         2643279 non-null  bool    \n",
      " 202  tag_exclusive                          2643279 non-null  bool    \n",
      " 203  tag_Arena Shooter                      2643279 non-null  bool    \n",
      " 204  tag_Choose Your Own Adventure          2643279 non-null  bool    \n",
      " 205  tag_1980s                              2643279 non-null  bool    \n",
      " 206  tag_Assassin                           2643279 non-null  bool    \n",
      " 207  tag_Dating Sim                         2643279 non-null  bool    \n",
      " 208  tag_Cartoon                            2643279 non-null  bool    \n",
      " 209  tag_Real-Time                          2643279 non-null  bool    \n",
      " 210  tag_Illuminati                         2643279 non-null  bool    \n",
      " 211  tag_Flight                             2643279 non-null  bool    \n",
      " 212  tag_Interactive Fiction                2643279 non-null  bool    \n",
      " 213  tag_Episodic                           2643279 non-null  bool    \n",
      " 214  tag_battle                             2643279 non-null  bool    \n",
      " 215  tag_Alternate History                  2643279 non-null  bool    \n",
      " 216  tag_online                             2643279 non-null  bool    \n",
      " 217  tag_MOBA                               2643279 non-null  bool    \n",
      " 218  tag_Score Attack                       2643279 non-null  bool    \n",
      " 219  tag_2D Fighter                         2643279 non-null  bool    \n",
      " 220  tag_Comic Book                         2643279 non-null  bool    \n",
      " 221  tag_Noir                               2643279 non-null  bool    \n",
      " 222  tag_Lovecraftian                       2643279 non-null  bool    \n",
      " 223  tag_Протагонистка                      2643279 non-null  bool    \n",
      " 224  tag_Supernatural                       2643279 non-null  bool    \n",
      " 225  tag_Dragons                            2643279 non-null  bool    \n",
      " 226  tag_Lore-Rich                          2643279 non-null  bool    \n",
      " 227  tag_Remote Play Together               2643279 non-null  bool    \n",
      " 228  tag_Class-Based                        2643279 non-null  bool    \n",
      " 229  tag_true exclusive                     2643279 non-null  bool    \n",
      " 230  tag_Superhero                          2643279 non-null  bool    \n",
      " 231  tag_Psychological                      2643279 non-null  bool    \n",
      " 232  tag_Mechs                              2643279 non-null  bool    \n",
      " 233  tag_Rhythm                             2643279 non-null  bool    \n",
      " 234  tag_Gothic                             2643279 non-null  bool    \n",
      " 235  tag_Tanks                              2643279 non-null  bool    \n",
      " 236  tag_2D Platformer                      2643279 non-null  bool    \n",
      " 237  tag_Experimental                       2643279 non-null  bool    \n",
      " 238  tag_Soundtrack                         2643279 non-null  bool    \n",
      " 239  tag_Immersive Sim                      2643279 non-null  bool    \n",
      " 240  tag_2D-платформер                      2643279 non-null  bool    \n",
      " 241  tag_CRPG                               2643279 non-null  bool    \n",
      " 242  tag_nature                             2643279 non-null  bool    \n",
      " 243  tag_Includes Source SDK                2643279 non-null  bool    \n",
      " 244  tag_Real Time Tactics                  2643279 non-null  bool    \n",
      " 245  tag_Party-Based RPG                    2643279 non-null  bool    \n",
      " 246  tag_e-sports                           2643279 non-null  bool    \n",
      " 247  tag_LGBTQ+                             2643279 non-null  bool    \n",
      " 248  tag_Ninja                              2643279 non-null  bool    \n",
      " 249  tag_Family Sharing                     2643279 non-null  bool    \n",
      " 250  tag_party                              2643279 non-null  bool    \n",
      " 251  tag_Heist                              2643279 non-null  bool    \n",
      " 252  tag_Trading                            2643279 non-null  bool    \n",
      " 253  tag_America                            2643279 non-null  bool    \n",
      " 254  tag_Quick-Time Events                  2643279 non-null  bool    \n",
      " 255  tag_Swordplay                          2643279 non-null  bool    \n",
      " 256  tag_Abstract                           2643279 non-null  bool    \n",
      " 257  tag_Mythology                          2643279 non-null  bool    \n",
      " 258  tag_Shared/Split Screen Co-op          2643279 non-null  bool    \n",
      " 259  tag_Emotional                          2643279 non-null  bool    \n",
      " 260  tag_Bullet Time                        2643279 non-null  bool    \n",
      " 261  tag_Tactical RPG                       2643279 non-null  bool    \n",
      " 262  tag_Psychedelic                        2643279 non-null  bool    \n",
      " 263  tag_Science                            2643279 non-null  bool    \n",
      " 264  tag_Satire                             2643279 non-null  bool    \n",
      " 265  tag_Time Travel                        2643279 non-null  bool    \n",
      " 266  tag_Strategy RPG                       2643279 non-null  bool    \n",
      " 267  tag_Epic                               2643279 non-null  bool    \n",
      " 268  tag_Space Sim                          2643279 non-null  bool    \n",
      " 269  tag_Other                              2643279 non-null  bool    \n",
      " 270  tag_city                               2643279 non-null  bool    \n",
      " 271  tag_Political                          2643279 non-null  bool    \n",
      " 272  tag_character                          2643279 non-null  bool    \n",
      " 273  tag_Parody                             2643279 non-null  bool    \n",
      " 274  tag_Games Workshop                     2643279 non-null  bool    \n",
      " 275  tag_Thriller                           2643279 non-null  bool    \n",
      " 276  tag_Hex Grid                           2643279 non-null  bool    \n",
      " 277  tag_Voxel                              2643279 non-null  bool    \n",
      " 278  tag_Dinosaurs                          2643279 non-null  bool    \n",
      " 279  tag_Clicker                            2643279 non-null  bool    \n",
      " 280  tag_Pirates                            2643279 non-null  bool    \n",
      " 281  tag_Hacking                            2643279 non-null  bool    \n",
      " 282  tag_Match 3                            2643279 non-null  bool    \n",
      " 283  tag_Cold War                           2643279 non-null  bool    \n",
      " 284  tag_Mod                                2643279 non-null  bool    \n",
      " 285  tag_Character Action Game              2643279 non-null  bool    \n",
      " 286  tag_Investigation                      2643279 non-null  bool    \n",
      " 287  tag_Conspiracy                         2643279 non-null  bool    \n",
      " 288  tag_Inventory Management               2643279 non-null  bool    \n",
      " 289  tag_Warhammer 40K                      2643279 non-null  bool    \n",
      " 290  tag_Masterpiece                        2643279 non-null  bool    \n",
      " 291  tag_3rd-Person Perspective             2643279 non-null  bool    \n",
      " 292  tag_Action Roguelike                   2643279 non-null  bool    \n",
      " 293  tag_Old School                         2643279 non-null  bool    \n",
      " 294  tag_Western                            2643279 non-null  bool    \n",
      " 295  tag_Shared/Split Screen PvP            2643279 non-null  bool    \n",
      " 296  tag_Star Wars                          2643279 non-null  bool    \n",
      " 297  tag_GameMaker                          2643279 non-null  bool    \n",
      " 298  tag_Vampire                            2643279 non-null  bool    \n",
      " 299  tag_Silent Protagonist                 2643279 non-null  bool    \n",
      " 300  tag_friends                            2643279 non-null  bool    \n",
      " 301  tag_Beautiful                          2643279 non-null  bool    \n",
      " 302  tag_Souls-like                         2643279 non-null  bool    \n",
      " 303  tag_Spectacle fighter                  2643279 non-null  bool    \n",
      " 304  tag_cats                               2643279 non-null  bool    \n",
      " 305  tag_Underwater                         2643279 non-null  bool    \n",
      " 306  tag_Based On A Novel                   2643279 non-null  bool    \n",
      " 307  tag_Villain Protagonist                2643279 non-null  bool    \n",
      " 308  tag_Co-op Campaign                     2643279 non-null  bool    \n",
      " 309  tag_vr mod                             2643279 non-null  bool    \n",
      " 310  tag_FMV                                2643279 non-null  bool    \n",
      " 311  tag_Runner                             2643279 non-null  bool    \n",
      " 312  tag_Time Manipulation                  2643279 non-null  bool    \n",
      " 313  tag_Lara Croft                         2643279 non-null  bool    \n",
      " 314  tag_console                            2643279 non-null  bool    \n",
      " 315  tag_Modern                             2643279 non-null  bool    \n",
      " 316  tag_Wargame                            2643279 non-null  bool    \n",
      " 317  tag_Hunting                            2643279 non-null  bool    \n",
      " 318  tag_Trading Card Game                  2643279 non-null  bool    \n",
      " 319  tag_Politics                           2643279 non-null  bool    \n",
      " 320  tag_offline                            2643279 non-null  bool    \n",
      " 321  tag_secrets                            2643279 non-null  bool    \n",
      " 322  tag_TrackIR                            2643279 non-null  bool    \n",
      " 323  tag_weapons                            2643279 non-null  bool    \n",
      " 324  tag_God Game                           2643279 non-null  bool    \n",
      " 325  tag_Mouse only                         2643279 non-null  bool    \n",
      " 326  tag_Dynamic Narration                  2643279 non-null  bool    \n",
      " 327  tag_Diplomacy                          2643279 non-null  bool    \n",
      " 328  tag_Puzzle Platformer                  2643279 non-null  bool    \n",
      " 329  tag_Gun Customization                  2643279 non-null  bool    \n",
      " 330  tag_Naval                              2643279 non-null  bool    \n",
      " 331  tag_Mars                               2643279 non-null  bool    \n",
      " 332  tag_LEGO                               2643279 non-null  bool    \n",
      " 333  tag_Utilities                          2643279 non-null  bool    \n",
      " 334  tag_Design & Illustration              2643279 non-null  bool    \n",
      " 335  tag_first person mod                   2643279 non-null  bool    \n",
      " 336  tag_cloud saves                        2643279 non-null  bool    \n",
      " 337  tag_Sniper                             2643279 non-null  bool    \n",
      " 338  tag_Nonlinear                          2643279 non-null  bool    \n",
      " 339  tag_Monsters                           2643279 non-null  bool    \n",
      " 340  tag_Fishing                            2643279 non-null  bool    \n",
      " 341  tag_Time Attack                        2643279 non-null  bool    \n",
      " 342  tag_Narrative                          2643279 non-null  bool    \n",
      " 343  tag_Text-Based                         2643279 non-null  bool    \n",
      " 344  tag_explore                            2643279 non-null  bool    \n",
      " 345  tag_Batman                             2643279 non-null  bool    \n",
      " 346  tag_NSFW                               2643279 non-null  bool    \n",
      " 347  tag_Capitalism                         2643279 non-null  bool    \n",
      " 348  tag_Logic                              2643279 non-null  bool    \n",
      " 349  tag_Dark Comedy                        2643279 non-null  bool    \n",
      " 350  tag_fight                              2643279 non-null  bool    \n",
      " 351  tag_Conversation                       2643279 non-null  bool    \n",
      " 352  tag_Agriculture                        2643279 non-null  bool    \n",
      " 353  tag_Battle Royale                      2643279 non-null  bool    \n",
      " 354  tag_Martial Arts                       2643279 non-null  bool    \n",
      " 355  tag_Crowdfunded                        2643279 non-null  bool    \n",
      " 356  tag_Постапокалипсис                    2643279 non-null  bool    \n",
      " 357  tag_work                               2643279 non-null  bool    \n",
      " 358  tag_Trains                             2643279 non-null  bool    \n",
      " 359  tag_Animation & Modeling               2643279 non-null  bool    \n",
      " 360  tag_Programming                        2643279 non-null  bool    \n",
      " 361  tag_2D-файтинг                         2643279 non-null  bool    \n",
      " 362  tag_skill                              2643279 non-null  bool    \n",
      " 363  tag_Grid-Based Movement                2643279 non-null  bool    \n",
      " 364  tag_Precision Platformer               2643279 non-null  bool    \n",
      " 365  tag_Remote Play on TV                  2643279 non-null  bool    \n",
      " 366  tag_Game Development                   2643279 non-null  bool    \n",
      " 367  tag_Software                           2643279 non-null  bool    \n",
      " 368  tag_deckbuilding                       2643279 non-null  bool    \n",
      " 369  tag_World War I                        2643279 non-null  bool    \n",
      " 370  tag_Life Sim                           2643279 non-null  bool    \n",
      " 371  tag_looter shooter                     2643279 non-null  bool    \n",
      " 372  tag_Offroad                            2643279 non-null  bool    \n",
      " 373  tag_4 giocatori divano                 2643279 non-null  bool    \n",
      " 374  tag_Automation                         2643279 non-null  bool    \n",
      " 375  tag_fun                                2643279 non-null  bool    \n",
      " 376  tag_collectathon                       2643279 non-null  bool    \n",
      " 377  tag_Time Management                    2643279 non-null  bool    \n",
      " 378  tag_island                             2643279 non-null  bool    \n",
      " 379  tag_death                              2643279 non-null  bool    \n",
      " 380  tag_Football                           2643279 non-null  bool    \n",
      " 381  tag_hero                               2643279 non-null  bool    \n",
      " 382  tag_esports                            2643279 non-null  bool    \n",
      " 383  tag_Романтика                          2643279 non-null  bool    \n",
      " 384  tag_european                           2643279 non-null  bool    \n",
      " 385  tag_future                             2643279 non-null  bool    \n",
      " 386  tag_history                            2643279 non-null  bool    \n",
      " 387  tag_environment                        2643279 non-null  bool    \n",
      " 388  tag_Otome                              2643279 non-null  bool    \n",
      " 389  tag_Steam Turn Notifications           2643279 non-null  bool    \n",
      " 390  tag_Mining                             2643279 non-null  bool    \n",
      " 391  tag_Hero Shooter                       2643279 non-null  bool    \n",
      " 392  tag_challenge                          2643279 non-null  bool    \n",
      " 393  tag_Soccer                             2643279 non-null  bool    \n",
      " 394  tag_journey                            2643279 non-null  bool    \n",
      " 395  tag_leaderboards                       2643279 non-null  bool    \n",
      " 396  tag_Horses                             2643279 non-null  bool    \n",
      " 397  tag_Remote Play on Tablet              2643279 non-null  bool    \n",
      " 398  tag_Rome                               2643279 non-null  bool    \n",
      " 399  tag_Tutorial                           2643279 non-null  bool    \n",
      " 400  tag_build                              2643279 non-null  bool    \n",
      " 401  tag_unique                             2643279 non-null  bool    \n",
      " 402  tag_balance                            2643279 non-null  bool    \n",
      " 403  tag_SteamVR Collectibles               2643279 non-null  bool    \n",
      " 404  tag_race                               2643279 non-null  bool    \n",
      " 405  tag_Sailing                            2643279 non-null  bool    \n",
      " 406  tag_LAN Co-op                          2643279 non-null  bool    \n",
      " 407  tag_Transhumanism                      2643279 non-null  bool    \n",
      " 408  tag_in development                     2643279 non-null  bool    \n",
      " 409  tag_Artificial Intelligence            2643279 non-null  bool    \n",
      " 410  tag_Colony Sim                         2643279 non-null  bool    \n",
      " 411  tag_steam                              2643279 non-null  bool    \n",
      " 412  tag_Benchmark                          2643279 non-null  bool    \n",
      " 413  tag_tabletop                           2643279 non-null  bool    \n",
      " 414  tag_Asynchronous Multiplayer           2643279 non-null  bool    \n",
      " 415  tag_Farming Sim                        2643279 non-null  bool    \n",
      " 416  tag_night                              2643279 non-null  bool    \n",
      " 417  tag_Music-Based Procedural Generation  2643279 non-null  bool    \n",
      " 418  tag_Dungeons & Dragons                 2643279 non-null  bool    \n",
      " 419  tag_Chess                              2643279 non-null  bool    \n",
      " 420  tag_Shadows                            2643279 non-null  bool    \n",
      " 421  tag_art                                2643279 non-null  bool    \n",
      " 422  tag_Gambling                           2643279 non-null  bool    \n",
      " 423  tag_Vehicular Combat                   2643279 non-null  bool    \n",
      " 424  tag_6DOF                               2643279 non-null  bool    \n",
      " 425  tag_planet                             2643279 non-null  bool    \n",
      " 426  tag_humor                              2643279 non-null  bool    \n",
      " 427  tag_Pinball                            2643279 non-null  bool    \n",
      " 428  tag_sound                              2643279 non-null  bool    \n",
      " 429  tag_solitaire                          2643279 non-null  bool    \n",
      " 430  tag_Card Battler                       2643279 non-null  bool    \n",
      " 431  tag_Арена-шутер                        2643279 non-null  bool    \n",
      " 432  tag_animation                          2643279 non-null  bool    \n",
      " 433  tag_Typing                             2643279 non-null  bool    \n",
      " 434  tag_Minigames                          2643279 non-null  bool    \n",
      " 435  tag_guns                               2643279 non-null  bool    \n",
      " 436  tag_3D Fighter                         2643279 non-null  bool    \n",
      " 437  tag_Лутер-шутер                        2643279 non-null  bool    \n",
      " 438  tag_Role Playing Game                  2643279 non-null  bool    \n",
      " 439  tag_destroy                            2643279 non-null  bool    \n",
      " 440  tag_enemy                              2643279 non-null  bool    \n",
      " 441  tag_Golf                               2643279 non-null  bool    \n",
      " 442  tag_escape                             2643279 non-null  bool    \n",
      " 443  tag_gun                                2643279 non-null  bool    \n",
      " 444  tag_Automobile Sim                     2643279 non-null  bool    \n",
      " 445  tag_ship                               2643279 non-null  bool    \n",
      " 446  tag_school                             2643279 non-null  bool    \n",
      " 447  tag_Philisophical                      2643279 non-null  bool    \n",
      " 448  tag_hentai                             2643279 non-null  bool    \n",
      " 449  tag_idler                              2643279 non-null  bool    \n",
      " 450  tag_immersive                          2643279 non-null  bool    \n",
      " 451  tag_click                              2643279 non-null  bool    \n",
      " 452  tag_On-Rails Shooter                   2643279 non-null  bool    \n",
      " 453  tag_Experience                         2643279 non-null  bool    \n",
      " 454  tag_collect                            2643279 non-null  bool    \n",
      " 455  tag_Remote Play on Phone               2643279 non-null  bool    \n",
      " 456  tag_hunt                               2643279 non-null  bool    \n",
      " 457  tag_LAN PvP                            2643279 non-null  bool    \n",
      " 458  tag_collection                         2643279 non-null  bool    \n",
      " 459  tag_police                             2643279 non-null  bool    \n",
      " 460  tag_fire                               2643279 non-null  bool    \n",
      " 461  tag_factory                            2643279 non-null  bool    \n",
      " 462  tag_Web Publishing                     2643279 non-null  bool    \n",
      " 463  tag_Movie                              2643279 non-null  bool    \n",
      " 464  tag_interactive                        2643279 non-null  bool    \n",
      " 465  tag_lifestyle                          2643279 non-null  bool    \n",
      " 466  tag_Werewolves                         2643279 non-null  bool    \n",
      " 467  tag_3D-файтинг                         2643279 non-null  bool    \n",
      " 468  tag_Unity                              2643279 non-null  bool    \n",
      " 469  tag_Cozy                               2643279 non-null  bool    \n",
      " 470  tag_rain                               2643279 non-null  bool    \n",
      " 471  tag_Endless                            2643279 non-null  bool    \n",
      " 472  tag_hell                               2643279 non-null  bool    \n",
      " 473  tag_Solo                               2643279 non-null  bool    \n",
      " 474  tag_alien                              2643279 non-null  bool    \n",
      " 475  tag_boss                               2643279 non-null  bool    \n",
      " 476  tag_transportation                     2643279 non-null  bool    \n",
      " 477  tag_Party Game                         2643279 non-null  bool    \n",
      " 478  tag_Software Training                  2643279 non-null  bool    \n",
      " 479  tag_Traps                              2643279 non-null  bool    \n",
      " 480  tag_Mini Golf                          2643279 non-null  bool    \n",
      " 481  tag_match                              2643279 non-null  bool    \n",
      " 482  tag_fall                               2643279 non-null  bool    \n",
      " 483  tag_Автоматика                         2643279 non-null  bool    \n",
      " 484  tag_philosophical                      2643279 non-null  bool    \n",
      " 485  tag_treasure                           2643279 non-null  bool    \n",
      " 486  tag_16-bit                             2643279 non-null  bool    \n",
      " 487  tag_controversial                      2643279 non-null  bool    \n",
      " 488  tag_elements                           2643279 non-null  bool    \n",
      " 489  tag_Faith                              2643279 non-null  bool    \n",
      " 490  tag_Word Game                          2643279 non-null  bool    \n",
      " 491  tag_love                               2643279 non-null  bool    \n",
      " 492  tag_murder                             2643279 non-null  bool    \n",
      " 493  tag_Auto Battler                       2643279 non-null  bool    \n",
      " 494  tag_dungeon                            2643279 non-null  bool    \n",
      " 495  tag_food                               2643279 non-null  bool    \n",
      " 496  tag_artgame                            2643279 non-null  bool    \n",
      " 497  tag_light                              2643279 non-null  bool    \n",
      " 498  tag_defense                            2643279 non-null  bool    \n",
      " 499  tag_Real time strategy                 2643279 non-null  bool    \n",
      " 500  tag_Dog                                2643279 non-null  bool    \n",
      " 501  tag_evolution                          2643279 non-null  bool    \n",
      " 502  tag_Single player only                 2643279 non-null  bool    \n",
      " 503  tag_mafia                              2643279 non-null  bool    \n",
      " 504  tag_Idle-игра                          2643279 non-null  bool    \n",
      " 505  tag_Bowling                            2643279 non-null  bool    \n",
      " 506  tag_Котики                             2643279 non-null  bool    \n",
      " 507  tag_skins                              2643279 non-null  bool    \n",
      " 508  tag_japan                              2643279 non-null  bool    \n",
      " 509  tag_Classes                            2643279 non-null  bool    \n",
      " 510  tag_fast                               2643279 non-null  bool    \n",
      " 511  tag_Spooky                             2643279 non-null  bool    \n",
      " 512  tag_speed                              2643279 non-null  bool    \n",
      " 513  tag_Unreal Engine                      2643279 non-null  bool    \n",
      " 514  tag_Creature Collector                 2643279 non-null  bool    \n",
      " 515  tag_violence                           2643279 non-null  bool    \n",
      " 516  tag_sword                              2643279 non-null  bool    \n",
      " 517  tag_snow                               2643279 non-null  bool    \n",
      " 518  tag_office                             2643279 non-null  bool    \n",
      " 519  tag_Sokoban                            2643279 non-null  bool    \n",
      " 520  tag_galaxy                             2643279 non-null  bool    \n",
      " 521  genre_Action                           2643279 non-null  bool    \n",
      " 522  genre_Adventure                        2643279 non-null  bool    \n",
      " 523  genre_Arcade                           2643279 non-null  bool    \n",
      " 524  genre_Board Games                      2643279 non-null  bool    \n",
      " 525  genre_Card                             2643279 non-null  bool    \n",
      " 526  genre_Casual                           2643279 non-null  bool    \n",
      " 527  genre_Educational                      2643279 non-null  bool    \n",
      " 528  genre_Family                           2643279 non-null  bool    \n",
      " 529  genre_Fighting                         2643279 non-null  bool    \n",
      " 530  genre_Indie                            2643279 non-null  bool    \n",
      " 531  genre_Massively Multiplayer            2643279 non-null  bool    \n",
      " 532  genre_Platformer                       2643279 non-null  bool    \n",
      " 533  genre_Puzzle                           2643279 non-null  bool    \n",
      " 534  genre_RPG                              2643279 non-null  bool    \n",
      " 535  genre_Racing                           2643279 non-null  bool    \n",
      " 536  genre_Shooter                          2643279 non-null  bool    \n",
      " 537  genre_Simulation                       2643279 non-null  bool    \n",
      " 538  genre_Sports                           2643279 non-null  bool    \n",
      " 539  genre_Strategy                         2643279 non-null  bool    \n",
      " 540  platform_3DO                           2643279 non-null  bool    \n",
      " 541  platform_Android                       2643279 non-null  bool    \n",
      " 542  platform_Apple II                      2643279 non-null  bool    \n",
      " 543  platform_Atari 2600                    2643279 non-null  bool    \n",
      " 544  platform_Atari 5200                    2643279 non-null  bool    \n",
      " 545  platform_Atari 8-bit                   2643279 non-null  bool    \n",
      " 546  platform_Atari Lynx                    2643279 non-null  bool    \n",
      " 547  platform_Atari ST                      2643279 non-null  bool    \n",
      " 548  platform_Classic Macintosh             2643279 non-null  bool    \n",
      " 549  platform_Commodore / Amiga             2643279 non-null  bool    \n",
      " 550  platform_Dreamcast                     2643279 non-null  bool    \n",
      " 551  platform_Game Boy                      2643279 non-null  bool    \n",
      " 552  platform_Game Boy Advance              2643279 non-null  bool    \n",
      " 553  platform_Game Boy Color                2643279 non-null  bool    \n",
      " 554  platform_Game Gear                     2643279 non-null  bool    \n",
      " 555  platform_GameCube                      2643279 non-null  bool    \n",
      " 556  platform_Genesis                       2643279 non-null  bool    \n",
      " 557  platform_Jaguar                        2643279 non-null  bool    \n",
      " 558  platform_Linux                         2643279 non-null  bool    \n",
      " 559  platform_NES                           2643279 non-null  bool    \n",
      " 560  platform_Neo Geo                       2643279 non-null  bool    \n",
      " 561  platform_Nintendo 3DS                  2643279 non-null  bool    \n",
      " 562  platform_Nintendo 64                   2643279 non-null  bool    \n",
      " 563  platform_Nintendo DS                   2643279 non-null  bool    \n",
      " 564  platform_Nintendo DSi                  2643279 non-null  bool    \n",
      " 565  platform_Nintendo Switch               2643279 non-null  bool    \n",
      " 566  platform_PC                            2643279 non-null  bool    \n",
      " 567  platform_PS Vita                       2643279 non-null  bool    \n",
      " 568  platform_PSP                           2643279 non-null  bool    \n",
      " 569  platform_PlayStation                   2643279 non-null  bool    \n",
      " 570  platform_PlayStation 2                 2643279 non-null  bool    \n",
      " 571  platform_PlayStation 3                 2643279 non-null  bool    \n",
      " 572  platform_PlayStation 4                 2643279 non-null  bool    \n",
      " 573  platform_PlayStation 5                 2643279 non-null  bool    \n",
      " 574  platform_SEGA CD                       2643279 non-null  bool    \n",
      " 575  platform_SEGA Master System            2643279 non-null  bool    \n",
      " 576  platform_SEGA Saturn                   2643279 non-null  bool    \n",
      " 577  platform_SNES                          2643279 non-null  bool    \n",
      " 578  platform_Web                           2643279 non-null  bool    \n",
      " 579  platform_Wii                           2643279 non-null  bool    \n",
      " 580  platform_Wii U                         2643279 non-null  bool    \n",
      " 581  platform_Xbox                          2643279 non-null  bool    \n",
      " 582  platform_Xbox 360                      2643279 non-null  bool    \n",
      " 583  platform_Xbox One                      2643279 non-null  bool    \n",
      " 584  platform_Xbox Series S/X               2643279 non-null  bool    \n",
      " 585  platform_iOS                           2643279 non-null  bool    \n",
      " 586  platform_macOS                         2643279 non-null  bool    \n",
      " 587  game_released_year_since_1984          2643279 non-null  float64 \n",
      "dtypes: bool(566), category(4), float64(18)\n",
      "memory usage: 1.8 GB\n",
      "\n",
      "[INFO] All final columns appear to be numeric, boolean, or category dtype.\n",
      "\n",
      "[INFO] Final X_train shape: (2643279, 588)\n",
      "\n",
      "======================================================================\n",
      "[INFO] Leaner preprocessing pipeline finished.\n",
      "[INFO] `X_train` and `y_train` should be ready.\n",
      "[INFO] `fitted_transformers` dictionary contains objects needed for X_test.\n",
      "======================================================================\n",
      "\n",
      "[NEXT STEPS]\n",
      "1. Inspect the final `X_train.info()` and shape. Ensure no unexpected object columns remain.\n",
      "2. Use the `fitted_transformers` dictionary to apply IDENTICAL transformations to `X_test` (starting from `df_test_raw`).\n",
      "   - **Borrow/Merge Embeddings:** Get `user_emb`, `game_emb` for test users/items (e.g., from `df_test_ready` or `df_test`). Merge onto `X_test` based on `user_id`/`app_id`. Fill any missing with `fitted_transformers['embedding_fill_value']`.\n",
      "   - Flatten test embeddings using `fitted_transformers['embedding_dim']`.\n",
      "   - Impute numerical NaNs using `fitted_transformers['numerical_medians'][col_name]`.\n",
      "   - Filter test tags using `fitted_transformers['top_n_tags']`, then use `MultiLabelBinarizer(classes=fitted_transformers['top_n_tags']).fit_transform(...)`.\n",
      "   - Transform test genres using `fitted_transformers['mlb_genres'].transform(...)`.\n",
      "   - Transform test platforms using `fitted_transformers['mlb_platform'].transform(...)`.\n",
      "   - Apply Top N / Other logic for Dev/Pub using `fitted_transformers['top_n_developers']`/`['top_n_publishers']` lists, then convert to category (handle values not seen in train, map to 'Other').\n",
      "   - Convert other categoricals (`user_country_code`, `game_esrb_rating`) to category dtype (handle new values by mapping to 'Missing'/'Other').\n",
      "   - Create date feature using the same REF_YEAR and imputation value if needed.\n",
      "   - **CRITICAL:** Ensure `X_test` has the exact same columns in the same order as the final `X_train`. Use `X_test = X_test.reindex(columns=X_train.columns, fill_value=0)` (or appropriate fill like False for bools) after all transformations.\n",
      "3. Train XGBoost model using `enable_categorical=True`:\n",
      "   import xgboost as xgb\n",
      "   model = xgb.XGBRegressor(objective='reg:squarederror', tree_method='hist', enable_categorical=True, random_state=42)\n",
      "   # model.fit(X_train, y_train)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/vvs7t0hs4j95wv7lbj2095940000gn/T/ipykernel_8502/1595243090.py:446: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  non_supported_types = final_dtypes[~final_dtypes.apply(lambda x: pd.api.types.is_numeric_dtype(x) or pd.api.types.is_categorical_dtype(x) or pd.api.types.is_bool_dtype(x))]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from collections import Counter\n",
    "import traceback\n",
    "import gc # Garbage collection for memory management\n",
    "# No 'ast' needed now if embeddings are already lists in df_train_ready\n",
    "\n",
    "print(\"[INFO] Starting preprocessing pipeline (Borrowing Embeddings from df_train_ready)...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_COLUMN = 'relevance_score'\n",
    "# Embedding columns - These will be borrowed from df_train_ready\n",
    "embedding_cols = ['user_emb', 'game_emb']\n",
    "# Other feature processing config (same as before)\n",
    "game_tags_col = 'game_tags'\n",
    "N_TOP_TAGS = 500\n",
    "game_genres_col = 'game_genres'\n",
    "platform_col = 'game_available_platform'\n",
    "single_item_list_cols = ['game_developer', 'game_publisher']\n",
    "N_TOP_DEV_PUB = 150\n",
    "low_card_categorical_cols = ['user_country_code', 'game_esrb_rating']\n",
    "numerical_cols_to_keep = [\n",
    "    'user_account_age_months', 'game_RAWG_weighted_avg_rating',\n",
    "    'game_RAWG_ratings_count', 'game_RAWG_bookmark_count',\n",
    "    'game_positive_review_count', 'game_negative_review_count',\n",
    "    'game_avg_playtime_forever', 'game_median_playtime_forever',\n",
    "    'game_current_price', 'game_initial_price', 'game_concurrent_user',\n",
    "    'game_estimate_owners_lower', 'game_estimate_owners_upper',\n",
    "]\n",
    "date_col = 'game_released_year'\n",
    "REF_YEAR = 1984\n",
    "\n",
    "# --- Storage for fitted objects (MUST keep this for X_test) ---\n",
    "fitted_transformers = {\n",
    "    'numerical_medians': {},\n",
    "    'embedding_dim': None,\n",
    "    'embedding_fill_value': None,\n",
    "    'top_n_tags': None,\n",
    "    'mlb_genres': None,\n",
    "    'mlb_platform': None,\n",
    "    'top_n_developers': None,\n",
    "    'top_n_publishers': None,\n",
    "    # 'scaler': None\n",
    "}\n",
    "\n",
    "# --- Data Loading Checks ---\n",
    "if 'df_train_raw' not in locals() or not isinstance(df_train_raw, pd.DataFrame):\n",
    "    print(f\"[ERROR] DataFrame 'df_train_raw' not found or not a DataFrame. Please load data.\")\n",
    "    df_train_raw = pd.DataFrame() # Avoid crash in example\n",
    "if 'df_train_ready' not in locals() or not isinstance(df_train_ready, pd.DataFrame):\n",
    "    print(f\"[ERROR] DataFrame 'df_train_ready' not found or not a DataFrame. Needed for embeddings.\")\n",
    "    df_train_ready = pd.DataFrame() # Avoid crash in example\n",
    "\n",
    "X_train = None\n",
    "y_train = None\n",
    "\n",
    "# --- Start Processing ---\n",
    "# Check required DataFrames exist and are not empty\n",
    "if isinstance(df_train_raw, pd.DataFrame) and not df_train_raw.empty and \\\n",
    "   isinstance(df_train_ready, pd.DataFrame) and not df_train_ready.empty:\n",
    "    try:\n",
    "        # Create a copy to work on\n",
    "        print(\"[INFO] Creating copy of df_train_raw...\")\n",
    "        X_train = df_train_raw.copy()\n",
    "        del df_train_raw\n",
    "        gc.collect()\n",
    "        print(\"[INFO] Copy created.\")\n",
    "\n",
    "        # --- Separate Target Variable ---\n",
    "        print(f\"[INFO] Separating target variable '{TARGET_COLUMN}'...\")\n",
    "        if TARGET_COLUMN in X_train.columns:\n",
    "            y_train = X_train[TARGET_COLUMN].copy()\n",
    "            X_train = X_train.drop(columns=[TARGET_COLUMN])\n",
    "            print(f\"[SUCCESS] Separated '{TARGET_COLUMN}'.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Target column '{TARGET_COLUMN}' not found!\")\n",
    "\n",
    "        # --- Initial Column Drop ---\n",
    "        # Keep 'user_id', 'app_id' in X_train for merging embeddings\n",
    "        merge_keys = ['user_id', 'app_id']\n",
    "        if not all(key in X_train.columns for key in merge_keys):\n",
    "             raise ValueError(f\"Merge keys {merge_keys} not found in df_train_raw.\")\n",
    "\n",
    "        cols_to_drop = [ # As defined before\n",
    "             'game_name', 'user_has_coordinates', 'user_latitude', 'user_longitude',\n",
    "             'game_tba', 'game_metacritic_rating', 'game_RAWG_reviews_with_text_count',\n",
    "             'game_RAWG_system_suggest_count', 'game_RAWG_reviews_count',\n",
    "             'game_released_month', 'game_released_day',\n",
    "             'game_RAWG_rating_5_percent', 'game_RAWG_rating_4_percent',\n",
    "             'game_RAWG_rating_3_percent', 'game_RAWG_rating_1_percent',\n",
    "             'game_RAWG_bookmark_type_yet_count','game_RAWG_bookmark_type_owned_count',\n",
    "             'game_RAWG_bookmark_type_beaten_count', 'game_RAWG_bookmark_type_toplay_count',\n",
    "             'game_RAWG_bookmark_type_dropped_count','game_RAWG_bookmark_type_playing_count',\n",
    "             'game_available_parent_platforms', 'game_avg_user_score',\n",
    "             'game_avg_playtime_last_2weeks', 'game_median_last_2weeks',\n",
    "             'game_current_discount',\n",
    "        ]\n",
    "        print(\"[INFO] Dropping initial set of unused/redundant columns (keeping merge keys)...\")\n",
    "        X_train.drop(columns=[col for col in cols_to_drop if col in X_train.columns], inplace=True, errors='ignore')\n",
    "        gc.collect()\n",
    "        print(f\"[INFO] Columns remaining after initial drop: {len(X_train.columns)}\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 0] Borrowing & Merging Embeddings from df_train_ready...\")\n",
    "        # ==============================\n",
    "        try:\n",
    "            emb_cols_to_borrow = ['user_id', 'app_id', 'user_emb', 'game_emb']\n",
    "            if not all(col in df_train_ready.columns for col in emb_cols_to_borrow):\n",
    "                raise ValueError(f\"df_train_ready must contain columns: {emb_cols_to_borrow}\")\n",
    "\n",
    "            print(f\"  Extracting embedding columns from df_train_ready...\")\n",
    "            # Select only necessary columns and rows if index doesn't match X_train (though likely it does)\n",
    "            # Using .loc ensures alignment if indices differ but user_id/app_id match\n",
    "            # If indices ARE guaranteed to match, simple selection is faster:\n",
    "            # emb_df = df_train_ready[emb_cols_to_borrow].copy()\n",
    "            # Let's assume we need to ensure correct rows via merge keys\n",
    "            emb_df = df_train_ready[emb_cols_to_borrow].drop_duplicates(subset=['user_id', 'app_id'], keep='first').copy()\n",
    "            print(f\"  Extracted {len(emb_df)} unique user/app embedding rows.\")\n",
    "            del df_train_ready # Free memory\n",
    "            gc.collect()\n",
    "\n",
    "            # --- Determine Embedding Dimension & Fill Value ---\n",
    "            emb_dim = None\n",
    "            for col in ['user_emb', 'game_emb']:\n",
    "                 # Check the first 100 non-NA values for a list to find dimension\n",
    "                 sample_embs = emb_df[col].dropna()\n",
    "                 if not sample_embs.empty:\n",
    "                     for emb in sample_embs.head(100):\n",
    "                         if isinstance(emb, (list, np.ndarray)) and len(emb) > 0:\n",
    "                             emb_dim = len(emb)\n",
    "                             break\n",
    "                 if emb_dim is not None: break # Stop searching once found\n",
    "\n",
    "            if emb_dim is None or emb_dim == 0:\n",
    "                 raise ValueError(\"Could not determine embedding dimension from df_train_ready columns.\")\n",
    "\n",
    "            print(f\"    Determined embedding dimension: {emb_dim}\")\n",
    "            fitted_transformers['embedding_dim'] = emb_dim\n",
    "            zero_emb_fill = [0.0] * emb_dim\n",
    "            fitted_transformers['embedding_fill_value'] = zero_emb_fill\n",
    "            print(f\"    Using fill value for missing embeddings: {zero_emb_fill}\")\n",
    "\n",
    "            # --- Merge ---\n",
    "            print(\"  Merging embeddings onto X_train...\")\n",
    "            # Check key types before merge\n",
    "            if X_train['user_id'].dtype != emb_df['user_id'].dtype:\n",
    "                print(f\"  [WARN] Mismatch user_id dtype: X_train({X_train['user_id'].dtype}), EmbDF({emb_df['user_id'].dtype}). Attempting cast.\")\n",
    "                try: X_train['user_id'] = X_train['user_id'].astype(emb_df['user_id'].dtype)\n",
    "                except Exception: raise TypeError(\"Could not cast user_id for merge.\")\n",
    "            if X_train['app_id'].dtype != emb_df['app_id'].dtype:\n",
    "                 print(f\"  [WARN] Mismatch app_id dtype: X_train({X_train['app_id'].dtype}), EmbDF({emb_df['app_id'].dtype}). Attempting cast.\")\n",
    "                 try: X_train['app_id'] = X_train['app_id'].astype(emb_df['app_id'].dtype)\n",
    "                 except Exception: raise TypeError(\"Could not cast app_id for merge.\")\n",
    "\n",
    "            X_train = pd.merge(X_train, emb_df, on=['user_id', 'app_id'], how='left')\n",
    "\n",
    "            # --- Handle NaNs from Merge ---\n",
    "            missing_user_embs = X_train['user_emb'].isnull().sum()\n",
    "            if missing_user_embs > 0:\n",
    "                 print(f\"  [WARN] Found {missing_user_embs} rows with missing user embeddings post-merge. Filling with zeros.\")\n",
    "                 # Ensure filling creates new list objects for each row\n",
    "                 X_train.loc[X_train['user_emb'].isnull(), 'user_emb'] = pd.Series([list(zero_emb_fill)] * missing_user_embs, index=X_train.index[X_train['user_emb'].isnull()])\n",
    "\n",
    "\n",
    "            missing_item_embs = X_train['game_emb'].isnull().sum()\n",
    "            if missing_item_embs > 0:\n",
    "                 print(f\"  [WARN] Found {missing_item_embs} rows with missing game embeddings post-merge. Filling with zeros.\")\n",
    "                 X_train.loc[X_train['game_emb'].isnull(), 'game_emb'] = pd.Series([list(zero_emb_fill)] * missing_item_embs, index=X_train.index[X_train['game_emb'].isnull()])\n",
    "\n",
    "\n",
    "            # --- Drop merge keys ---\n",
    "            X_train.drop(columns=['user_id', 'app_id'], inplace=True, errors='ignore')\n",
    "\n",
    "            print(\"  [SUCCESS] Embeddings borrowed and merged.\")\n",
    "            del emb_df # Cleanup\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed to borrow/merge embeddings from df_train_ready: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "            print(\"  [WARN] Proceeding WITHOUT ALS embeddings due to error.\")\n",
    "            embedding_cols = [] # Skip Phase 1\n",
    "        print(\"[PHASE 0] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 1] Flattening Embeddings (if available)...\")\n",
    "        # ==============================\n",
    "        # ... (This code remains the same, it operates on the merged 'user_emb', 'game_emb') ...\n",
    "        try:\n",
    "            processed_embeddings = []\n",
    "            if not embedding_cols: # Check if list is empty due to Phase 0 error\n",
    "                 print(\"  [SKIP] Skipping Phase 1 as embeddings were not successfully borrowed/merged.\")\n",
    "            else:\n",
    "                for col in embedding_cols:\n",
    "                    if col in X_train.columns:\n",
    "                        print(f\"  [INFO] Processing column: {col}...\")\n",
    "                        # Ensure data are lists before stacking\n",
    "                        is_list_like = X_train[col].apply(lambda x: isinstance(x, (list, np.ndarray)))\n",
    "                        if not is_list_like.all():\n",
    "                            print(f\"  [ERROR] Column '{col}' contains non-list/array elements before flattening. Check merge/fill logic.\")\n",
    "                            # Attempt to coerce non-list items to the zero vector\n",
    "                            emb_dim_check = fitted_transformers['embedding_dim']\n",
    "                            zero_fill_check = fitted_transformers['embedding_fill_value']\n",
    "                            if emb_dim_check and zero_fill_check:\n",
    "                                print(f\"  [WARN] Attempting to coerce non-list items in '{col}' to {zero_fill_check}.\")\n",
    "                                X_train[col] = X_train[col].apply(lambda x: x if isinstance(x, (list, np.ndarray)) and len(x) == emb_dim_check else list(zero_fill_check))\n",
    "                            else:\n",
    "                                print(f\"  [ERROR] Cannot coerce non-list items without valid emb_dim/fill_value. Skipping '{col}'.\")\n",
    "                                continue # Skip this column if coercion isn't possible\n",
    "\n",
    "                        emb_dim = fitted_transformers['embedding_dim']\n",
    "                        if emb_dim is None or emb_dim <= 0:\n",
    "                             print(f\"  [ERROR] Invalid embedding dimension ({emb_dim}). Cannot flatten '{col}'.\")\n",
    "                             continue\n",
    "\n",
    "                        emb_cols_names = [f'{col}_{i}' for i in range(emb_dim)]\n",
    "                        # Use np.array(X_train[col].tolist()) for robustness\n",
    "                        emb_data = np.array(X_train[col].tolist())\n",
    "                        if emb_data.ndim != 2 or emb_data.shape[1] != emb_dim:\n",
    "                             raise ValueError(f\"Shape mismatch after converting '{col}' to array. Expected N x {emb_dim}, got {emb_data.shape}. Check for inconsistent list lengths.\")\n",
    "\n",
    "                        emb_df = pd.DataFrame(emb_data, columns=emb_cols_names, index=X_train.index).astype(float)\n",
    "                        X_train = X_train.join(emb_df)\n",
    "                        X_train = X_train.drop(columns=[col])\n",
    "                        print(f\"  [SUCCESS] Flattened '{col}' into {emb_cols_names}.\")\n",
    "                        processed_embeddings.extend(emb_cols_names)\n",
    "                    else:\n",
    "                         print(f\"  [WARN] Embedding column '{col}' not found (should have been merged). Skipping.\")\n",
    "                gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed during embedding flattening: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "        print(\"[PHASE 1] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        # Phases 2 through 9 remain exactly the same as the previous code block\n",
    "        # They operate on the columns derived from df_train_raw (now including flattened embeddings)\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 2] Processing Game Tags (Top N)...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        if game_tags_col in X_train.columns:\n",
    "            try:\n",
    "                print(f\"  Calculating tag frequencies for Top {N_TOP_TAGS}...\")\n",
    "                tag_lists = X_train[game_tags_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                tag_counts = Counter(tag for sublist in tag_lists for tag in sublist)\n",
    "                top_n_tags = [tag for tag, count in tag_counts.most_common(N_TOP_TAGS)]\n",
    "                fitted_transformers['top_n_tags'] = top_n_tags\n",
    "                top_n_tags_set = set(top_n_tags)\n",
    "                print(f\"  Found {len(tag_counts)} unique tags. Keeping top {len(top_n_tags)}.\")\n",
    "\n",
    "                print(f\"  Applying Binarizer for Top {len(top_n_tags)} tags...\")\n",
    "                filtered_tag_lists = tag_lists.apply(lambda lst: [tag for tag in lst if tag in top_n_tags_set])\n",
    "                mlb_top_tags = MultiLabelBinarizer(classes=top_n_tags)\n",
    "                top_tag_features = mlb_top_tags.fit_transform(filtered_tag_lists)\n",
    "                top_tag_df = pd.DataFrame(\n",
    "                    top_tag_features, columns=mlb_top_tags.classes_, index=X_train.index\n",
    "                ).add_prefix('tag_').astype(bool)\n",
    "\n",
    "                X_train = X_train.join(top_tag_df)\n",
    "                X_train = X_train.drop(columns=[game_tags_col])\n",
    "                print(f\"  [SUCCESS] Processed '{game_tags_col}'. Added {top_tag_df.shape[1]} boolean features.\")\n",
    "                del tag_lists, tag_counts, top_n_tags_set, filtered_tag_lists, top_tag_features, top_tag_df\n",
    "                gc.collect()\n",
    "            except Exception as e:\n",
    "                 print(f\"  [ERROR] Failed processing '{game_tags_col}': {e}\")\n",
    "                 print(traceback.format_exc())\n",
    "        else:\n",
    "            print(f\"  [WARN] Tags column '{game_tags_col}' not found.\")\n",
    "        print(\"[PHASE 2] Completed.\")\n",
    "\n",
    "        print(\"\\n[PHASE 3] Processing Game Genres (Binarize)...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        if game_genres_col in X_train.columns:\n",
    "             try:\n",
    "                  print(f\"  Applying Binarizer for '{game_genres_col}'...\")\n",
    "                  genre_lists = X_train[game_genres_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                  mlb_genres = MultiLabelBinarizer()\n",
    "                  genre_features = mlb_genres.fit_transform(genre_lists)\n",
    "                  genre_df = pd.DataFrame(\n",
    "                      genre_features, columns=mlb_genres.classes_, index=X_train.index\n",
    "                  ).add_prefix('genre_').astype(bool)\n",
    "                  X_train = X_train.join(genre_df)\n",
    "                  X_train = X_train.drop(columns=[game_genres_col])\n",
    "                  fitted_transformers['mlb_genres'] = mlb_genres\n",
    "                  print(f\"  [SUCCESS] Processed '{game_genres_col}'. Added {genre_df.shape[1]} boolean features.\")\n",
    "                  del genre_lists, genre_features, genre_df\n",
    "                  gc.collect()\n",
    "             except Exception as e:\n",
    "                 print(f\"  [ERROR] Failed processing '{game_genres_col}': {e}\")\n",
    "                 print(traceback.format_exc())\n",
    "        else:\n",
    "             print(f\"  [WARN] Genres column '{game_genres_col}' not found.\")\n",
    "        print(\"[PHASE 3] Completed.\")\n",
    "\n",
    "        print(\"\\n[PHASE 4] Processing Platforms (Binarize)...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        if platform_col in X_train.columns:\n",
    "             try:\n",
    "                  print(f\"  Applying Binarizer for '{platform_col}'...\")\n",
    "                  platform_lists = X_train[platform_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                  mlb_platform = MultiLabelBinarizer()\n",
    "                  platform_features = mlb_platform.fit_transform(platform_lists)\n",
    "                  platform_df = pd.DataFrame(\n",
    "                      platform_features, columns=mlb_platform.classes_, index=X_train.index\n",
    "                  ).add_prefix('platform_').astype(bool)\n",
    "                  X_train = X_train.join(platform_df)\n",
    "                  X_train = X_train.drop(columns=[platform_col])\n",
    "                  fitted_transformers['mlb_platform'] = mlb_platform\n",
    "                  print(f\"  [SUCCESS] Processed '{platform_col}'. Added {platform_df.shape[1]} boolean features.\")\n",
    "                  del platform_lists, platform_features, platform_df\n",
    "                  gc.collect()\n",
    "             except Exception as e:\n",
    "                 print(f\"  [ERROR] Failed processing '{platform_col}': {e}\")\n",
    "                 print(traceback.format_exc())\n",
    "        else:\n",
    "             print(f\"  [WARN] Platform column '{platform_col}' not found.\")\n",
    "        print(\"[PHASE 4] Completed.\")\n",
    "\n",
    "        print(\"\\n[PHASE 5] Extracting Strings & Processing Dev/Publisher (Top N + Category)...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        try:\n",
    "            # 5a. Extract strings\n",
    "            for col in single_item_list_cols:\n",
    "                 if col in X_train.columns:\n",
    "                     print(f\"  [INFO] Extracting string from '{col}'...\")\n",
    "                     X_train[col] = X_train[col].apply(lambda x: str(x[0]) if isinstance(x, list) and len(x) > 0 else 'Unknown')\n",
    "                     print(f\"  [SUCCESS] Extracted strings for '{col}'.\")\n",
    "                 else:\n",
    "                      print(f\"  [WARN] Column '{col}' not found for string extraction.\")\n",
    "\n",
    "            # 5b. Apply Top N + 'Other' for Dev/Pub\n",
    "            for col in single_item_list_cols:\n",
    "                 if col in X_train.columns:\n",
    "                     print(f\"  [INFO] Applying Top {N_TOP_DEV_PUB} / Other to '{col}'...\")\n",
    "                     counts = X_train[col].value_counts()\n",
    "                     top_n = counts.nlargest(N_TOP_DEV_PUB).index.tolist()\n",
    "                     if 'Unknown' in counts.index and 'Unknown' not in top_n:\n",
    "                          if len(top_n) >= N_TOP_DEV_PUB and N_TOP_DEV_PUB > 0: top_n.pop()\n",
    "                          if 'Unknown' not in top_n: top_n.append('Unknown')\n",
    "\n",
    "                     transformer_key = f'top_n_{col}s'\n",
    "                     fitted_transformers[transformer_key] = top_n\n",
    "                     top_n_set = set(top_n)\n",
    "                     X_train[col] = X_train[col].apply(lambda x: x if x in top_n_set else 'Other')\n",
    "                     print(f\"  [SUCCESS] Applied Top {N_TOP_DEV_PUB} / Other to '{col}'. Now has {X_train[col].nunique()} unique values.\")\n",
    "                 else:\n",
    "                      print(f\"  [WARN] Column '{col}' not found for Top N processing.\")\n",
    "\n",
    "            # 5c. Convert Dev/Pub to category\n",
    "            for col in single_item_list_cols:\n",
    "                if col in X_train.columns:\n",
    "                     print(f\"  [INFO] Converting '{col}' to category dtype...\")\n",
    "                     X_train[col] = X_train[col].astype('category')\n",
    "                     print(f\"  [SUCCESS] Converted '{col}' to category.\")\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed during Dev/Publisher processing: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "        print(\"[PHASE 5] Completed.\")\n",
    "\n",
    "        print(\"\\n[PHASE 6] Processing Other Categoricals (Category)...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        try:\n",
    "            for col in low_card_categorical_cols:\n",
    "                 if col in X_train.columns:\n",
    "                     print(f\"  [INFO] Processing '{col}'...\")\n",
    "                     fill_val = 'Missing'\n",
    "                     if X_train[col].isnull().any():\n",
    "                          print(f\"  [INFO] Filling NaNs in '{col}' with '{fill_val}'.\")\n",
    "                          X_train[col].fillna(fill_val, inplace=True)\n",
    "                     X_train[col] = X_train[col].astype(str)\n",
    "                     X_train[col] = X_train[col].astype('category')\n",
    "                     print(f\"  [SUCCESS] Converted '{col}' to category.\")\n",
    "                 else:\n",
    "                     print(f\"  [WARN] Column '{col}' not found.\")\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "             print(f\"  [ERROR] Failed processing other categoricals: {e}\")\n",
    "             print(traceback.format_exc())\n",
    "        print(\"[PHASE 6] Completed.\")\n",
    "\n",
    "        print(\"\\n[PHASE 7] Processing Numerical Features (Imputation)...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        try:\n",
    "            print(f\"  [INFO] Imputing selected numerical columns...\")\n",
    "            cols_actually_imputed = []\n",
    "            numerical_cols_present = [col for col in numerical_cols_to_keep if col in X_train.columns]\n",
    "\n",
    "            for col in numerical_cols_present:\n",
    "                 X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "                 if X_train[col].isnull().any():\n",
    "                     median_val = X_train[col].median()\n",
    "                     if pd.isna(median_val): median_val = 0.0\n",
    "                     fitted_transformers['numerical_medians'][col] = median_val\n",
    "                     X_train[col].fillna(median_val, inplace=True)\n",
    "                     cols_actually_imputed.append(col)\n",
    "                 X_train[col] = X_train[col].astype(float)\n",
    "\n",
    "            if cols_actually_imputed:\n",
    "                 print(f\"    Imputed NaNs in: {cols_actually_imputed}\")\n",
    "            else:\n",
    "                 print(\"    No NaNs found or needing imputation in selected numerical columns.\")\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "             print(f\"  [ERROR] Failed processing numerical features: {e}\")\n",
    "             print(traceback.format_exc())\n",
    "        print(\"[PHASE 7] Completed.\")\n",
    "\n",
    "        print(\"\\n[PHASE 8] Processing Date Feature...\")\n",
    "        # ...(Identical code from previous answer)...\n",
    "        try:\n",
    "            if date_col in X_train.columns:\n",
    "                 print(f\"  [INFO] Processing '{date_col}'...\")\n",
    "                 X_train[date_col] = pd.to_numeric(X_train[date_col], errors='coerce')\n",
    "                 if X_train[date_col].isnull().any():\n",
    "                     median_year = X_train[date_col].median()\n",
    "                     if pd.isna(median_year): median_year = float(REF_YEAR)\n",
    "                     fitted_transformers['numerical_medians'][date_col] = median_year\n",
    "                     X_train[date_col].fillna(median_year, inplace=True)\n",
    "                     print(f\"    Imputed NaNs in '{date_col}' with median ({median_year:.0f}).\")\n",
    "                 new_date_col_name = f'{date_col}_since_{REF_YEAR}'\n",
    "                 X_train[new_date_col_name] = X_train[date_col] - REF_YEAR\n",
    "                 X_train[new_date_col_name] = X_train[new_date_col_name].astype(float)\n",
    "                 X_train.drop(columns=[date_col], inplace=True)\n",
    "                 print(f\"  [SUCCESS] Created '{new_date_col_name}' and dropped original.\")\n",
    "            else:\n",
    "                 print(f\"  [WARN] Date column '{date_col}' not found.\")\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed processing date feature: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "        print(\"[PHASE 8] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 9] Final Check & Info...\")\n",
    "        # ==============================\n",
    "        # ... (Code for Phase 9 remains the same) ...\n",
    "        print(\"  [INFO] Checking final columns and types...\")\n",
    "        X_train.info(verbose=True, show_counts=True)\n",
    "        final_dtypes = X_train.dtypes\n",
    "        non_supported_types = final_dtypes[~final_dtypes.apply(lambda x: pd.api.types.is_numeric_dtype(x) or pd.api.types.is_categorical_dtype(x) or pd.api.types.is_bool_dtype(x))]\n",
    "        if not non_supported_types.empty:\n",
    "             print(\"\\n[CRITICAL WARNING] Found columns with non-numeric/bool/category types AFTER processing:\")\n",
    "             print(non_supported_types)\n",
    "             print(\"These WILL likely cause XGBoost to fail. Review processing steps for these columns.\")\n",
    "        else:\n",
    "             print(\"\\n[INFO] All final columns appear to be numeric, boolean, or category dtype.\")\n",
    "        print(\"\\n[INFO] Final X_train shape:\", X_train.shape)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"[INFO] Leaner preprocessing pipeline finished.\")\n",
    "        print(\"[INFO] `X_train` and `y_train` should be ready.\")\n",
    "        print(\"[INFO] `fitted_transformers` dictionary contains objects needed for X_test.\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\n[FATAL ERROR] An unexpected error occurred during the NEW preprocessing pipeline.\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "else:\n",
    "      print(\"[INFO] df_train_raw or df_train_ready DataFrame is empty or not loaded. No preprocessing performed.\")\n",
    "\n",
    "# --- Reminder (Update X_test instructions slightly) ---\n",
    "print(\"\\n[NEXT STEPS]\")\n",
    "print(\"1. Inspect the final `X_train.info()` and shape. Ensure no unexpected object columns remain.\")\n",
    "print(\"2. Use the `fitted_transformers` dictionary to apply IDENTICAL transformations to `X_test` (starting from `df_test_raw`).\")\n",
    "print(\"   - **Borrow/Merge Embeddings:** Get `user_emb`, `game_emb` for test users/items (e.g., from `df_test_ready` or `df_test`). Merge onto `X_test` based on `user_id`/`app_id`. Fill any missing with `fitted_transformers['embedding_fill_value']`.\")\n",
    "print(\"   - Flatten test embeddings using `fitted_transformers['embedding_dim']`.\")\n",
    "print(\"   - Impute numerical NaNs using `fitted_transformers['numerical_medians'][col_name]`.\")\n",
    "print(\"   - Filter test tags using `fitted_transformers['top_n_tags']`, then use `MultiLabelBinarizer(classes=fitted_transformers['top_n_tags']).fit_transform(...)`.\")\n",
    "print(\"   - Transform test genres using `fitted_transformers['mlb_genres'].transform(...)`.\")\n",
    "print(\"   - Transform test platforms using `fitted_transformers['mlb_platform'].transform(...)`.\")\n",
    "print(\"   - Apply Top N / Other logic for Dev/Pub using `fitted_transformers['top_n_developers']`/`['top_n_publishers']` lists, then convert to category (handle values not seen in train, map to 'Other').\")\n",
    "print(\"   - Convert other categoricals (`user_country_code`, `game_esrb_rating`) to category dtype (handle new values by mapping to 'Missing'/'Other').\")\n",
    "print(\"   - Create date feature using the same REF_YEAR and imputation value if needed.\")\n",
    "print(\"   - **CRITICAL:** Ensure `X_test` has the exact same columns in the same order as the final `X_train`. Use `X_test = X_test.reindex(columns=X_train.columns, fill_value=0)` (or appropriate fill like False for bools) after all transformations.\")\n",
    "print(\"3. Train XGBoost model using `enable_categorical=True`:\")\n",
    "print(\"   import xgboost as xgb\")\n",
    "print(\"   model = xgb.XGBRegressor(objective='reg:squarederror', tree_method='hist', enable_categorical=True, random_state=42)\")\n",
    "print(\"   # model.fit(X_train, y_train)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8016e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Saving processed X_train and y_train to disk using pickle...\n",
      "  Saving X_train (shape: (2643279, 588)) to X_train_processed.pkl...\n",
      "  [SUCCESS] Saved X_train.\n",
      "  Saving y_train (length: 2643279) to y_train.pkl...\n",
      "  [SUCCESS] Saved y_train.\n",
      "[INFO] Data saving complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle # Make sure pickle is imported\n",
    "\n",
    "print(\"\\n[INFO] Saving processed X_train and y_train to disk using pickle...\")\n",
    "\n",
    "try:\n",
    "    # --- Save X_train ---\n",
    "    x_train_filename = 'X_train_processed.pkl'\n",
    "    print(f\"  Saving X_train (shape: {X_train.shape}) to {x_train_filename}...\")\n",
    "    X_train.to_pickle(x_train_filename)\n",
    "    print(f\"  [SUCCESS] Saved X_train.\")\n",
    "\n",
    "    # --- Save y_train ---\n",
    "    y_train_filename = 'y_train.pkl'\n",
    "    print(f\"  Saving y_train (length: {len(y_train)}) to {y_train_filename}...\")\n",
    "    y_train.to_pickle(y_train_filename)\n",
    "    print(f\"  [SUCCESS] Saved y_train.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  [ERROR] Failed to save data: {e}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "print(\"[INFO] Data saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45402041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Saving fitted_transformers dictionary to disk...\n",
      "  [SUCCESS] Saved fitted_transformers to fitted_transformers.pkl.\n",
      "[INFO] Transformers saving complete.\n"
     ]
    }
   ],
   "source": [
    "import pickle # Make sure pickle is imported\n",
    "\n",
    "print(\"\\n[INFO] Saving fitted_transformers dictionary to disk...\")\n",
    "\n",
    "transformers_filename = 'fitted_transformers.pkl'\n",
    "try:\n",
    "    with open(transformers_filename, 'wb') as f:\n",
    "        pickle.dump(fitted_transformers, f)\n",
    "    print(f\"  [SUCCESS] Saved fitted_transformers to {transformers_filename}.\")\n",
    "except Exception as e:\n",
    "    print(f\"  [ERROR] Failed to save fitted_transformers: {e}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "print(\"[INFO] Transformers saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1758bb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting preprocessing of test data...\n",
      "----------------------------------------------------------------------\n",
      "[INFO] Initial test data shape: (694638, 50)\n",
      "[INFO] Columns remaining after initial drop: 23\n",
      "\n",
      "[PHASE 0] Merging Test Embeddings...\n",
      "  Extracting required columns from embedding source...\n",
      "    Using embedding dimension: 2, Fill value: [0.0, 0.0]\n",
      "  Merging embeddings onto X_test...\n",
      "  [WARN] Found 518 rows with missing user embeddings post-merge. Filling with [0.0, 0.0].\n",
      "  [WARN] Found 518 rows with missing game embeddings post-merge. Filling with [0.0, 0.0].\n",
      "  [SUCCESS] Embeddings merged.\n",
      "[PHASE 0] Completed.\n",
      "\n",
      "[PHASE 1] Flattening Embeddings...\n",
      "  [INFO] Flattening column: user_emb...\n",
      "  [SUCCESS] Flattened 'user_emb'.\n",
      "  [INFO] Flattening column: game_emb...\n",
      "  [SUCCESS] Flattened 'game_emb'.\n",
      "[PHASE 1] Completed.\n",
      "\n",
      "[PHASE 2] Processing Game Tags (Top N)...\n",
      "  Applying Binarizer using Top 500 tags from training...\n",
      "  [SUCCESS] Processed 'game_tags'. Added/Aligned 500 tag features.\n",
      "[PHASE 2] Completed.\n",
      "\n",
      "[PHASE 3] Processing Game Genres (Binarize)...\n",
      "  Applying fitted genres MLB...\n",
      "  [SUCCESS] Processed 'game_genres'. Added/Aligned 19 genre features.\n",
      "[PHASE 3] Completed.\n",
      "\n",
      "[PHASE 4] Processing Platforms (Binarize)...\n",
      "  Applying fitted platform MLB...\n",
      "  [SUCCESS] Processed 'game_available_platform'. Added/Aligned 47 platform features.\n",
      "[PHASE 4] Completed.\n",
      "\n",
      "[PHASE 5] Processing Dev/Publisher (Top N + Category)...\n",
      "  [INFO] Extracting string from 'game_developer'...\n",
      "  [SUCCESS] Extracted strings for 'game_developer'.\n",
      "  [INFO] Extracting string from 'game_publisher'...\n",
      "  [SUCCESS] Extracted strings for 'game_publisher'.\n",
      "  [INFO] Applying Top 150 / Other to 'game_developer' using stored list...\n",
      "  [SUCCESS] Applied Top N / Other to 'game_developer'.\n",
      "  [INFO] Applying Top 150 / Other to 'game_publisher' using stored list...\n",
      "  [SUCCESS] Applied Top N / Other to 'game_publisher'.\n",
      "[ERROR] X_train (loaded from pickle) is required to get categories for test set conversion.\n",
      "[PHASE 5] Completed.\n",
      "\n",
      "[PHASE 6] Processing Other Categoricals (Category)...\n",
      "  [INFO] Processing 'user_country_code'...\n",
      "[ERROR] X_train (loaded from pickle) is required to get categories for test set conversion.\n",
      "[PHASE 6] Completed.\n",
      "\n",
      "[PHASE 7] Processing Numerical Features (Imputation)...\n",
      "  [INFO] Imputing selected numerical columns using stored medians...\n",
      "    Imputed NaNs in test set: ['game_current_price', 'game_initial_price']\n",
      "[PHASE 7] Completed.\n",
      "\n",
      "[PHASE 8] Processing Date Feature...\n",
      "  [INFO] Processing 'game_released_year'...\n",
      "    Imputed NaNs in 'game_released_year' with median (2015).\n",
      "  [SUCCESS] Created 'game_released_year_since_1984' and dropped original.\n",
      "[PHASE 8] Completed.\n",
      "\n",
      "[PHASE 9] Final Alignment (Reindex)...\n",
      "  [INFO] Aligning test columns to training columns order and presence (588 columns)...\n",
      "  Test columns BEFORE reindex: 588\n",
      "  Test columns AFTER reindex: 588\n",
      "  [INFO] No NaNs found in the final processed test set.\n",
      "[PHASE 9] Completed.\n",
      "\n",
      "[INFO] Test data preprocessing finished.\n",
      "[INFO] Final X_test shape: (694638, 588)\n"
     ]
    }
   ],
   "source": [
    "X_test_processed = preprocess_test_data(\n",
    "    df_test_raw,\n",
    "    df_test_ready[['user_id', 'app_id', 'user_emb', 'game_emb']], # Pass only needed columns\n",
    "    fitted_transformers,\n",
    "    X_train.columns # Pass the column index from the processed X_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af48b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading saved processed data and transformers...\n",
      "  Loading X_train from X_train_processed.pkl...\n",
      "  [SUCCESS] Loaded X_train (shape: (2643279, 588)).\n",
      "  Loading y_train from y_train.pkl...\n",
      "  [SUCCESS] Loaded y_train (length: 2643279).\n",
      "  Loading fitted_transformers from fitted_transformers.pkl...\n",
      "  [SUCCESS] Loaded fitted_transformers.\n",
      "\n",
      "[INFO] All saved objects loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "print(\"[INFO] Loading saved processed data and transformers...\")\n",
    "\n",
    "try:\n",
    "    # --- Load X_train ---\n",
    "    x_train_filename = 'X_train_processed.pkl'\n",
    "    print(f\"  Loading X_train from {x_train_filename}...\")\n",
    "    X_train = pd.read_pickle(x_train_filename)\n",
    "    print(f\"  [SUCCESS] Loaded X_train (shape: {X_train.shape}).\")\n",
    "\n",
    "    # --- Load y_train ---\n",
    "    y_train_filename = 'y_train.pkl'\n",
    "    print(f\"  Loading y_train from {y_train_filename}...\")\n",
    "    y_train = pd.read_pickle(y_train_filename)\n",
    "    print(f\"  [SUCCESS] Loaded y_train (length: {len(y_train)}).\")\n",
    "\n",
    "    # --- Load fitted_transformers ---\n",
    "    transformers_filename = 'fitted_transformers.pkl'\n",
    "    print(f\"  Loading fitted_transformers from {transformers_filename}...\")\n",
    "    with open(transformers_filename, 'rb') as f:\n",
    "        fitted_transformers = pickle.load(f)\n",
    "    print(f\"  [SUCCESS] Loaded fitted_transformers.\")\n",
    "\n",
    "    print(\"\\n[INFO] All saved objects loaded successfully!\")\n",
    "    # You can now proceed with processing X_test and training the model.\n",
    "    # Example: print(X_train.info()) to verify\n",
    "\n",
    "except FileNotFoundError as e_fnf:\n",
    "     print(f\"  [ERROR] Could not find saved file: {e_fnf}\")\n",
    "     print(\"  Please ensure the .pkl files are in the correct directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"  [ERROR] Failed to load data/transformers: {e}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5207d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from collections import Counter\n",
    "import traceback\n",
    "import gc\n",
    "\n",
    "# Make sure TARGET_COLUMN is defined (same as used in training script)\n",
    "# Example: TARGET_COLUMN = 'relevance_score'\n",
    "# Ensure numerical_cols_to_keep, single_item_list_cols, low_card_categorical_cols,\n",
    "# embedding_cols, game_tags_col, game_genres_col, platform_col, date_col, REF_YEAR\n",
    "# are defined or replace them with the actual values used in the training script if needed.\n",
    "# It's better practice to pass these lists as arguments if they might change.\n",
    "\n",
    "def preprocess_test_data(df_raw, df_ready_for_emb, fitted_transformers, x_train_columns):\n",
    "    \"\"\"\n",
    "    Applies preprocessing steps to the test data using fitted transformers.\n",
    "    Includes fixes for category handling errors.\n",
    "\n",
    "    Args:\n",
    "        df_raw (pd.DataFrame): Raw test data (like df_test_raw).\n",
    "        df_ready_for_emb (pd.DataFrame): DataFrame containing test embeddings\n",
    "                                         (like df_test_ready[['user_id', 'app_id', 'user_emb', 'game_emb']]).\n",
    "        fitted_transformers (dict): Dictionary containing fitted objects and values from training.\n",
    "        x_train_columns (pd.Index): The columns from the processed X_train dataset for final reindexing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed X_test DataFrame, ready for prediction.\n",
    "        None: If a critical error occurs.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Starting preprocessing of test data...\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    if not isinstance(df_raw, pd.DataFrame) or df_raw.empty:\n",
    "        print(\"[ERROR] Input df_raw is invalid or empty.\")\n",
    "        return None\n",
    "    if not isinstance(df_ready_for_emb, pd.DataFrame) or df_ready_for_emb.empty:\n",
    "        print(\"[ERROR] Input df_ready_for_emb is invalid or empty.\")\n",
    "        return None\n",
    "\n",
    "    # Define column lists (redundant if defined globally, but safer here)\n",
    "    embedding_cols = ['user_emb', 'game_emb']\n",
    "    game_tags_col = 'game_tags'\n",
    "    game_genres_col = 'game_genres'\n",
    "    platform_col = 'game_available_platform'\n",
    "    single_item_list_cols = ['game_developer', 'game_publisher']\n",
    "    low_card_categorical_cols = ['user_country_code', 'game_esrb_rating']\n",
    "    numerical_cols_to_keep = [\n",
    "        'user_account_age_months', 'game_RAWG_weighted_avg_rating',\n",
    "        'game_RAWG_ratings_count', 'game_RAWG_bookmark_count',\n",
    "        'game_positive_review_count', 'game_negative_review_count',\n",
    "        'game_avg_playtime_forever', 'game_median_playtime_forever',\n",
    "        'game_current_price', 'game_initial_price', 'game_concurrent_user',\n",
    "        'game_estimate_owners_lower', 'game_estimate_owners_upper',\n",
    "    ]\n",
    "    date_col = 'game_released_year'\n",
    "    REF_YEAR = 1984\n",
    "    TARGET_COLUMN = 'relevance_score' # Needed for dropping\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create a copy\n",
    "        X_test = df_raw.copy()\n",
    "        print(f\"[INFO] Initial test data shape: {X_test.shape}\")\n",
    "\n",
    "        # --- Initial Column Drop (Keep merge keys temporarily) ---\n",
    "        merge_keys = ['user_id', 'app_id']\n",
    "        if not all(key in X_test.columns for key in merge_keys):\n",
    "             raise ValueError(f\"Merge keys {merge_keys} not found in df_test_raw.\")\n",
    "\n",
    "        cols_to_drop = [\n",
    "             'game_name', 'user_has_coordinates', 'user_latitude', 'user_longitude',\n",
    "             'game_tba', 'game_metacritic_rating', 'game_RAWG_reviews_with_text_count',\n",
    "             'game_RAWG_system_suggest_count', 'game_RAWG_reviews_count',\n",
    "             'game_released_month', 'game_released_day',\n",
    "             'game_RAWG_rating_5_percent', 'game_RAWG_rating_4_percent',\n",
    "             'game_RAWG_rating_3_percent', 'game_RAWG_rating_1_percent',\n",
    "             'game_RAWG_bookmark_type_yet_count','game_RAWG_bookmark_type_owned_count',\n",
    "             'game_RAWG_bookmark_type_beaten_count', 'game_RAWG_bookmark_type_toplay_count',\n",
    "             'game_RAWG_bookmark_type_dropped_count','game_RAWG_bookmark_type_playing_count',\n",
    "             'game_available_parent_platforms', 'game_avg_user_score',\n",
    "             'game_avg_playtime_last_2weeks', 'game_median_last_2weeks',\n",
    "             'game_current_discount', TARGET_COLUMN\n",
    "        ]\n",
    "        temp_keys_to_keep = [key for key in merge_keys if key in cols_to_drop]\n",
    "        cols_to_drop_now = [col for col in cols_to_drop if col not in temp_keys_to_keep]\n",
    "        X_test.drop(columns=[col for col in cols_to_drop_now if col in X_test.columns], inplace=True, errors='ignore')\n",
    "        print(f\"[INFO] Columns remaining after initial drop: {len(X_test.columns)}\")\n",
    "        gc.collect()\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 0] Merging Test Embeddings...\")\n",
    "        # ==============================\n",
    "        emb_cols_to_borrow = ['user_id', 'app_id', 'user_emb', 'game_emb']\n",
    "        if not all(col in df_ready_for_emb.columns for col in emb_cols_to_borrow):\n",
    "            raise ValueError(f\"df_ready_for_emb must contain columns: {emb_cols_to_borrow}\")\n",
    "\n",
    "        print(f\"  Extracting required columns from embedding source...\")\n",
    "        emb_df_test = df_ready_for_emb[emb_cols_to_borrow].drop_duplicates(subset=['user_id', 'app_id'], keep='first').copy()\n",
    "\n",
    "        # --- Get Embedding Dim & Fill Value ---\n",
    "        zero_emb_fill = fitted_transformers['embedding_fill_value']\n",
    "        if zero_emb_fill is None:\n",
    "             raise ValueError(\"Embedding fill value not found in fitted_transformers.\")\n",
    "        emb_dim = fitted_transformers['embedding_dim']\n",
    "        if emb_dim is None or emb_dim <=0:\n",
    "             raise ValueError(\"Embedding dimension not found or invalid in fitted_transformers.\")\n",
    "        print(f\"    Using embedding dimension: {emb_dim}, Fill value: {zero_emb_fill}\")\n",
    "\n",
    "        # --- Merge ---\n",
    "        print(\"  Merging embeddings onto X_test...\")\n",
    "        if X_test['user_id'].dtype != emb_df_test['user_id'].dtype:\n",
    "            try: X_test['user_id'] = X_test['user_id'].astype(emb_df_test['user_id'].dtype)\n",
    "            except Exception: raise TypeError(\"Could not cast user_id for merge.\")\n",
    "        if X_test['app_id'].dtype != emb_df_test['app_id'].dtype:\n",
    "             try: X_test['app_id'] = X_test['app_id'].astype(emb_df_test['app_id'].dtype)\n",
    "             except Exception: raise TypeError(\"Could not cast app_id for merge.\")\n",
    "\n",
    "        X_test = pd.merge(X_test, emb_df_test, on=['user_id', 'app_id'], how='left')\n",
    "\n",
    "        # --- Handle NaNs from Merge ---\n",
    "        missing_user_embs = X_test['user_emb'].isnull().sum()\n",
    "        if missing_user_embs > 0:\n",
    "             print(f\"  [WARN] Found {missing_user_embs} rows with missing user embeddings post-merge. Filling with {zero_emb_fill}.\")\n",
    "             # Use .loc for safer assignment\n",
    "             nan_user_indices = X_test.index[X_test['user_emb'].isnull()]\n",
    "             X_test.loc[nan_user_indices, 'user_emb'] = pd.Series([list(zero_emb_fill)] * len(nan_user_indices), index=nan_user_indices)\n",
    "\n",
    "\n",
    "        missing_item_embs = X_test['game_emb'].isnull().sum()\n",
    "        if missing_item_embs > 0:\n",
    "             print(f\"  [WARN] Found {missing_item_embs} rows with missing game embeddings post-merge. Filling with {zero_emb_fill}.\")\n",
    "             nan_item_indices = X_test.index[X_test['game_emb'].isnull()]\n",
    "             X_test.loc[nan_item_indices, 'game_emb'] = pd.Series([list(zero_emb_fill)] * len(nan_item_indices), index=nan_item_indices)\n",
    "\n",
    "\n",
    "        X_test.drop(columns=['user_id', 'app_id'], inplace=True, errors='ignore')\n",
    "        print(\"  [SUCCESS] Embeddings merged.\")\n",
    "        del emb_df_test\n",
    "        gc.collect()\n",
    "        print(\"[PHASE 0] Completed.\")\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 1] Flattening Embeddings...\")\n",
    "        # ==============================\n",
    "        emb_dim = fitted_transformers['embedding_dim']\n",
    "        if emb_dim is None or emb_dim <= 0:\n",
    "             print(\"  [WARN] Invalid embedding dimension found in transformers. Skipping flattening.\")\n",
    "             X_test.drop(columns=embedding_cols, inplace=True, errors='ignore')\n",
    "        else:\n",
    "            zero_emb_fill = fitted_transformers['embedding_fill_value'] # Get fill value again\n",
    "            for col in embedding_cols:\n",
    "                 if col in X_test.columns:\n",
    "                     print(f\"  [INFO] Flattening column: {col}...\")\n",
    "                     # Ensure all elements are lists of correct dim before stacking\n",
    "                     def check_and_coerce(item):\n",
    "                         if isinstance(item, (list, np.ndarray)) and len(item) == emb_dim:\n",
    "                             return item\n",
    "                         else:\n",
    "                             # Log unexpected type if needed\n",
    "                             return list(zero_emb_fill) # Coerce to zero vector\n",
    "                     X_test[col] = X_test[col].apply(check_and_coerce)\n",
    "\n",
    "                     emb_cols_names = [f'{col}_{i}' for i in range(emb_dim)]\n",
    "                     emb_data = np.array(X_test[col].tolist())\n",
    "                     if emb_data.ndim != 2 or emb_data.shape[1] != emb_dim:\n",
    "                          raise ValueError(f\"Shape mismatch after converting '{col}' to array in test set.\")\n",
    "\n",
    "                     emb_df = pd.DataFrame(emb_data, columns=emb_cols_names, index=X_test.index).astype(float)\n",
    "                     X_test = X_test.join(emb_df)\n",
    "                     X_test = X_test.drop(columns=[col])\n",
    "                     print(f\"  [SUCCESS] Flattened '{col}'.\")\n",
    "                 else:\n",
    "                     print(f\"  [WARN] Embedding column '{col}' not found for flattening.\")\n",
    "            gc.collect()\n",
    "        print(\"[PHASE 1] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 2] Processing Game Tags (Top N)...\")\n",
    "        # ==============================\n",
    "        top_n_tags = fitted_transformers['top_n_tags']\n",
    "        if top_n_tags is None:\n",
    "             print(\"  [WARN] Top N tags list not found in transformers. Skipping tag processing.\")\n",
    "        elif game_tags_col not in X_test.columns:\n",
    "             print(f\"  [WARN] Tags column '{game_tags_col}' not found in test set.\")\n",
    "        else:\n",
    "             try:\n",
    "                 print(f\"  Applying Binarizer using Top {len(top_n_tags)} tags from training...\")\n",
    "                 tag_lists_test = X_test[game_tags_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                 top_n_tags_set = set(top_n_tags) # Use set for efficient filtering\n",
    "                 filtered_tag_lists_test = tag_lists_test.apply(lambda lst: [tag for tag in lst if tag in top_n_tags_set])\n",
    "\n",
    "                 mlb_top_tags = MultiLabelBinarizer(classes=top_n_tags)\n",
    "                 top_tag_features_test = mlb_top_tags.fit_transform(filtered_tag_lists_test)\n",
    "                 top_tag_df_test = pd.DataFrame(\n",
    "                     top_tag_features_test, columns=mlb_top_tags.classes_, index=X_test.index\n",
    "                 ).add_prefix('tag_').astype(bool)\n",
    "\n",
    "                 X_test = X_test.join(top_tag_df_test)\n",
    "                 X_test = X_test.drop(columns=[game_tags_col])\n",
    "                 print(f\"  [SUCCESS] Processed '{game_tags_col}'. Added/Aligned {top_tag_df_test.shape[1]} tag features.\")\n",
    "                 del tag_lists_test, filtered_tag_lists_test, top_tag_features_test, top_tag_df_test\n",
    "                 gc.collect()\n",
    "             except Exception as e:\n",
    "                 print(f\"  [ERROR] Failed processing '{game_tags_col}' in test set: {e}\")\n",
    "                 print(traceback.format_exc())\n",
    "        print(\"[PHASE 2] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 3] Processing Game Genres (Binarize)...\")\n",
    "        # ==============================\n",
    "        mlb_genres = fitted_transformers['mlb_genres']\n",
    "        if mlb_genres is None:\n",
    "             print(\"  [WARN] Genres MLB not found in transformers. Skipping genres.\")\n",
    "        elif game_genres_col not in X_test.columns:\n",
    "             print(f\"  [WARN] Genres column '{game_genres_col}' not found in test set.\")\n",
    "        else:\n",
    "             try:\n",
    "                 print(f\"  Applying fitted genres MLB...\")\n",
    "                 genre_lists_test = X_test[game_genres_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                 genre_features_test = mlb_genres.transform(genre_lists_test) # Use TRANSFORM\n",
    "                 genre_df_test = pd.DataFrame(\n",
    "                     genre_features_test, columns=mlb_genres.classes_, index=X_test.index\n",
    "                 ).add_prefix('genre_').astype(bool)\n",
    "                 X_test = X_test.join(genre_df_test)\n",
    "                 X_test = X_test.drop(columns=[game_genres_col])\n",
    "                 print(f\"  [SUCCESS] Processed '{game_genres_col}'. Added/Aligned {genre_df_test.shape[1]} genre features.\")\n",
    "                 del genre_lists_test, genre_features_test, genre_df_test\n",
    "                 gc.collect()\n",
    "             except Exception as e:\n",
    "                 print(f\"  [ERROR] Failed processing '{game_genres_col}' in test set: {e}\")\n",
    "                 print(traceback.format_exc())\n",
    "        print(\"[PHASE 3] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 4] Processing Platforms (Binarize)...\")\n",
    "        # ==============================\n",
    "        mlb_platform = fitted_transformers['mlb_platform']\n",
    "        if mlb_platform is None:\n",
    "             print(\"  [WARN] Platform MLB not found in transformers. Skipping platforms.\")\n",
    "        elif platform_col not in X_test.columns:\n",
    "              print(f\"  [WARN] Platform column '{platform_col}' not found in test set.\")\n",
    "        else:\n",
    "             try:\n",
    "                 print(f\"  Applying fitted platform MLB...\")\n",
    "                 platform_lists_test = X_test[platform_col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "                 platform_features_test = mlb_platform.transform(platform_lists_test) # Use TRANSFORM\n",
    "                 platform_df_test = pd.DataFrame(\n",
    "                     platform_features_test, columns=mlb_platform.classes_, index=X_test.index\n",
    "                 ).add_prefix('platform_').astype(bool)\n",
    "                 X_test = X_test.join(platform_df_test)\n",
    "                 X_test = X_test.drop(columns=[platform_col])\n",
    "                 print(f\"  [SUCCESS] Processed '{platform_col}'. Added/Aligned {platform_df_test.shape[1]} platform features.\")\n",
    "                 del platform_lists_test, platform_features_test, platform_df_test\n",
    "                 gc.collect()\n",
    "             except Exception as e:\n",
    "                 print(f\"  [ERROR] Failed processing '{platform_col}' in test set: {e}\")\n",
    "                 print(traceback.format_exc())\n",
    "        print(\"[PHASE 4] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 5] Processing Dev/Publisher (Top N + Category)...\")\n",
    "        # ==============================\n",
    "        try:\n",
    "            # 5a. Extract strings\n",
    "            for col in single_item_list_cols:\n",
    "                 if col in X_test.columns:\n",
    "                     print(f\"  [INFO] Extracting string from '{col}'...\")\n",
    "                     X_test[col] = X_test[col].apply(lambda x: str(x[0]) if isinstance(x, list) and len(x) > 0 else 'Unknown')\n",
    "                     print(f\"  [SUCCESS] Extracted strings for '{col}'.\")\n",
    "                 else:\n",
    "                      print(f\"  [WARN] Column '{col}' not found in test set for string extraction.\")\n",
    "\n",
    "            # 5b. Apply Top N + 'Other' using stored lists\n",
    "            for col in single_item_list_cols:\n",
    "                 if col in X_test.columns:\n",
    "                     transformer_key = f'top_n_{col}s'\n",
    "                     top_n = fitted_transformers.get(transformer_key)\n",
    "                     if top_n is None:\n",
    "                          print(f\"  [WARN] Top N list '{transformer_key}' not found. Skipping Top N for '{col}'.\")\n",
    "                          continue\n",
    "                     print(f\"  [INFO] Applying Top {len(top_n)} / Other to '{col}' using stored list...\")\n",
    "                     top_n_set = set(top_n)\n",
    "                     # Define 'Other' category explicitly in case it wasn't in top N but is needed\n",
    "                     fill_other_cat = 'Other'\n",
    "                     X_test[col] = X_test[col].apply(lambda x: x if x in top_n_set else fill_other_cat)\n",
    "                     print(f\"  [SUCCESS] Applied Top N / Other to '{col}'.\")\n",
    "                 else:\n",
    "                      print(f\"  [WARN] Column '{col}' not found for Top N processing.\")\n",
    "\n",
    "            # 5c. Convert Dev/Pub to category - Use categories from X_train for consistency\n",
    "            for col in single_item_list_cols:\n",
    "                 # We need X_train's categories here. If X_train isn't available, this won't work perfectly.\n",
    "                 # Assuming X_train *is* available from the loaded data.\n",
    "                 if 'X_train' not in locals():\n",
    "                     print(\"[ERROR] X_train (loaded from pickle) is required to get categories for test set conversion.\")\n",
    "                     break\n",
    "\n",
    "                 if col in X_train.columns and isinstance(X_train[col].dtype, pd.CategoricalDtype) and col in X_test.columns:\n",
    "                     print(f\"  [INFO] Converting '{col}' to category dtype using training categories...\")\n",
    "                     train_categories = X_train[col].cat.categories\n",
    "                     # Make sure 'Other' is included if we used it as a fill value\n",
    "                     if 'Other' not in train_categories and (X_test[col] == 'Other').any():\n",
    "                         train_categories = train_categories.tolist() + ['Other']\n",
    "\n",
    "                     X_test[col] = pd.Categorical(X_test[col], categories=train_categories, ordered=False)\n",
    "                     # Fill any NaNs created by values not in train_categories (should only be 'Other' now)\n",
    "                     if X_test[col].isnull().any():\n",
    "                          fill_cat = 'Other' if 'Other' in train_categories else 'Unknown' if 'Unknown' in train_categories else None\n",
    "                          if fill_cat:\n",
    "                              print(f\"  [WARN] Filling NaNs in '{col}' post-categorization with '{fill_cat}'.\")\n",
    "                              # No need to add category if it's already in train_categories\n",
    "                              X_test.loc[X_test[col].isnull(), col] = fill_cat\n",
    "                          else:\n",
    "                              print(f\"  [WARN] Cannot fill NaNs for unknown categories in '{col}'.\")\n",
    "                     print(f\"  [SUCCESS] Converted '{col}' to category.\")\n",
    "                 elif col in X_test.columns:\n",
    "                    print(f\"  [WARN] Cannot convert '{col}' to category - either missing in X_train or not category in X_train.\")\n",
    "                    # Fallback: Convert to generic category, but XGBoost needs consistency\n",
    "                    X_test[col] = X_test[col].astype('category')\n",
    "\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed during Dev/Publisher processing in test set: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "        print(\"[PHASE 5] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 6] Processing Other Categoricals (Category)...\")\n",
    "        # ==============================\n",
    "        try:\n",
    "            for col in low_card_categorical_cols:\n",
    "                 if col in X_test.columns:\n",
    "                     print(f\"  [INFO] Processing '{col}'...\")\n",
    "                     fill_val = 'Missing' # Consistent fill value\n",
    "                     if X_test[col].isnull().any():\n",
    "                          # Use .loc for assignment\n",
    "                          X_test.loc[X_test[col].isnull(), col] = fill_val\n",
    "                          print(f\"  [INFO] Filled NaNs in '{col}' with '{fill_val}'.\")\n",
    "\n",
    "                     # Ensure string type before category conversion\n",
    "                     X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "                     # Use categories from X_train\n",
    "                     if 'X_train' not in locals():\n",
    "                         print(\"[ERROR] X_train (loaded from pickle) is required to get categories for test set conversion.\")\n",
    "                         break\n",
    "                     if col in X_train.columns and isinstance(X_train[col].dtype, pd.CategoricalDtype):\n",
    "                          train_categories = X_train[col].cat.categories\n",
    "                          # Check if fill_val ('Missing') is a known category\n",
    "                          if fill_val not in train_categories:\n",
    "                               print(f\"  [WARN] Fill value '{fill_val}' for column '{col}' not found in training categories. This might cause issues or introduce NaNs.\")\n",
    "                               # Optionally add it IF it makes sense, otherwise map unknowns to it\n",
    "                               # train_categories = train_categories.tolist() + [fill_val] # Example: add if needed\n",
    "\n",
    "                          X_test[col] = pd.Categorical(X_test[col], categories=train_categories, ordered=False)\n",
    "\n",
    "                          # Handle values present in test but not train -> these become NaN here\n",
    "                          if X_test[col].isnull().any():\n",
    "                              # Determine fill category again based on what's actually in train_categories\n",
    "                              fill_cat = fill_val if fill_val in train_categories else None\n",
    "                              if fill_cat:\n",
    "                                   print(f\"  [WARN] Filling NaNs introduced by unknown categories in '{col}' with '{fill_cat}'.\")\n",
    "                                   # ---- FIX: Check if category exists before adding ----\n",
    "                                   # This check is redundant if fill_cat was confirmed in train_categories above\n",
    "                                   # We just need to fill\n",
    "                                   X_test.loc[X_test[col].isnull(), col] = fill_cat\n",
    "                              else:\n",
    "                                   # This case means 'Missing' wasn't even in train cats, problematic\n",
    "                                   print(f\"  [ERROR] Cannot fill NaNs for unknown categories in '{col}' as '{fill_val}' not in training categories.\")\n",
    "                          print(f\"  [SUCCESS] Converted '{col}' to category using training categories.\")\n",
    "                     else:\n",
    "                          print(f\"  [WARN] Cannot find training categories for '{col}'. Converting to category directly.\")\n",
    "                          X_test[col] = X_test[col].astype('category')\n",
    "                 else:\n",
    "                     print(f\"  [WARN] Column '{col}' not found in test set.\")\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "             print(f\"  [ERROR] Failed processing other categoricals in test set: {e}\")\n",
    "             print(traceback.format_exc())\n",
    "        print(\"[PHASE 6] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 7] Processing Numerical Features (Imputation)...\")\n",
    "        # ==============================\n",
    "        try:\n",
    "            print(f\"  [INFO] Imputing selected numerical columns using stored medians...\")\n",
    "            numerical_cols_present_test = [col for col in numerical_cols_to_keep if col in X_test.columns]\n",
    "            cols_actually_imputed_test = []\n",
    "\n",
    "            for col in numerical_cols_present_test:\n",
    "                 X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
    "                 if X_test[col].isnull().any():\n",
    "                     median_val = fitted_transformers['numerical_medians'].get(col)\n",
    "                     if median_val is None:\n",
    "                          print(f\"  [WARN] Median for '{col}' not found in transformers. Filling with 0.\")\n",
    "                          median_val = 0.0\n",
    "                     # Use .loc for assignment\n",
    "                     X_test.loc[X_test[col].isnull(), col] = median_val\n",
    "                     #X_test[col].fillna(median_val, inplace=True)\n",
    "                     cols_actually_imputed_test.append(col)\n",
    "                 X_test[col] = X_test[col].astype(float)\n",
    "\n",
    "            if cols_actually_imputed_test:\n",
    "                 print(f\"    Imputed NaNs in test set: {cols_actually_imputed_test}\")\n",
    "            else:\n",
    "                 print(\"    No NaNs found or needing imputation in selected numerical columns in test set.\")\n",
    "\n",
    "            # Optional Scaling\n",
    "            # ... (scaler logic using .transform()) ...\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "             print(f\"  [ERROR] Failed processing numerical features in test set: {e}\")\n",
    "             print(traceback.format_exc())\n",
    "        print(\"[PHASE 7] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 8] Processing Date Feature...\")\n",
    "        # ==============================\n",
    "        try:\n",
    "            if date_col in X_test.columns:\n",
    "                 print(f\"  [INFO] Processing '{date_col}'...\")\n",
    "                 X_test[date_col] = pd.to_numeric(X_test[date_col], errors='coerce')\n",
    "                 if X_test[date_col].isnull().any():\n",
    "                     median_year = fitted_transformers['numerical_medians'].get(date_col)\n",
    "                     if median_year is None:\n",
    "                          print(f\"  [WARN] Median year for '{date_col}' not found. Filling with {REF_YEAR}.\")\n",
    "                          median_year = float(REF_YEAR)\n",
    "                     # Use .loc for assignment\n",
    "                     X_test.loc[X_test[date_col].isnull(), date_col] = median_year\n",
    "                     # X_test[date_col].fillna(median_year, inplace=True)\n",
    "                     print(f\"    Imputed NaNs in '{date_col}' with median ({median_year:.0f}).\")\n",
    "\n",
    "                 new_date_col_name = f'{date_col}_since_{REF_YEAR}'\n",
    "                 X_test[new_date_col_name] = X_test[date_col] - REF_YEAR\n",
    "                 X_test[new_date_col_name] = X_test[new_date_col_name].astype(float)\n",
    "                 X_test.drop(columns=[date_col], inplace=True)\n",
    "                 print(f\"  [SUCCESS] Created '{new_date_col_name}' and dropped original.\")\n",
    "            else:\n",
    "                 print(f\"  [WARN] Date column '{date_col}' not found in test set.\")\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Failed processing date feature in test set: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "        print(\"[PHASE 8] Completed.\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        print(\"\\n[PHASE 9] Final Alignment (Reindex)...\")\n",
    "        # ==============================\n",
    "        print(f\"  [INFO] Aligning test columns to training columns order and presence ({len(x_train_columns)} columns)...\")\n",
    "        print(f\"  Test columns BEFORE reindex: {len(X_test.columns)}\")\n",
    "\n",
    "        missing_cols = x_train_columns.difference(X_test.columns)\n",
    "        extra_cols = X_test.columns.difference(x_train_columns)\n",
    "\n",
    "        if not missing_cols.empty:\n",
    "            print(f\"  [INFO] Columns missing in test set (will be added and filled): {missing_cols.tolist()}\")\n",
    "        if not extra_cols.empty:\n",
    "            print(f\"  [INFO] Columns present in test but not train (will be removed): {extra_cols.tolist()}\")\n",
    "\n",
    "        # Reindex to match training columns exactly\n",
    "        X_test = X_test.reindex(columns=x_train_columns)\n",
    "\n",
    "        # Fill NaNs possibly introduced by reindexing missing columns\n",
    "        # Primarily for numeric/bool types, categoricals should handle unknowns earlier\n",
    "        cols_after_reindex_with_nan = X_test.columns[X_test.isnull().any()].tolist()\n",
    "        if cols_after_reindex_with_nan:\n",
    "             print(f\"  [WARN] Found NaNs after reindex in columns: {cols_after_reindex_with_nan}. Attempting fill...\")\n",
    "             for col in cols_after_reindex_with_nan:\n",
    "                 # Check original X_train dtype to decide fill value\n",
    "                 if col in X_train.columns: # Check if col exists in X_train\n",
    "                     if pd.api.types.is_bool_dtype(X_train[col]):\n",
    "                         fill_val = False\n",
    "                         print(f\"    Filling NaNs in bool column '{col}' with {fill_val}.\")\n",
    "                         X_test[col].fillna(fill_val, inplace=True) # inplace should be okay here after reindex\n",
    "                     elif pd.api.types.is_numeric_dtype(X_train[col]):\n",
    "                         fill_val = 0.0\n",
    "                         print(f\"    Filling NaNs in numeric column '{col}' with {fill_val}.\")\n",
    "                         X_test[col].fillna(fill_val, inplace=True)\n",
    "                     elif pd.api.types.is_categorical_dtype(X_train[col]):\n",
    "                          # This case should ideally be handled by Phase 5/6, but as a fallback:\n",
    "                          known_cats = X_train[col].cat.categories\n",
    "                          fill_cat = 'Other' if 'Other' in known_cats else 'Missing' if 'Missing' in known_cats else None\n",
    "                          if fill_cat:\n",
    "                              print(f\"    Filling NaNs in category column '{col}' with '{fill_cat}'.\")\n",
    "                              # Ensure category exists before filling\n",
    "                              if fill_cat not in X_test[col].cat.categories:\n",
    "                                   X_test[col] = X_test[col].cat.add_categories([fill_cat])\n",
    "                              X_test[col].fillna(fill_cat, inplace=True)\n",
    "                          else:\n",
    "                               print(f\"    [WARN] Could not determine fill category for '{col}'. NaNs may remain.\")\n",
    "                     else:\n",
    "                         print(f\"    [WARN] Unknown dtype for column '{col}' in X_train. Filling NaNs with 0.\")\n",
    "                         X_test[col].fillna(0, inplace=True)\n",
    "                 else:\n",
    "                      print(f\"   [WARN] Column '{col}' not found in original X_train. Cannot determine fill type. Filling NaNs with 0.\")\n",
    "                      X_test[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        print(f\"  Test columns AFTER reindex: {len(X_test.columns)}\")\n",
    "        if len(X_test.columns) != len(x_train_columns):\n",
    "             print(\"  [ERROR] Column count mismatch after reindex!\")\n",
    "        final_nan_check = X_test.isnull().sum().sum()\n",
    "        if final_nan_check > 0:\n",
    "            print(f\"  [WARN] {final_nan_check} NaNs remain in the processed test set!\")\n",
    "        else:\n",
    "            print(\"  [INFO] No NaNs found in the final processed test set.\")\n",
    "        print(\"[PHASE 9] Completed.\")\n",
    "\n",
    "\n",
    "        print(\"\\n[INFO] Test data preprocessing finished.\")\n",
    "        print(f\"[INFO] Final X_test shape: {X_test.shape}\")\n",
    "        return X_test\n",
    "\n",
    "    except Exception as e_main:\n",
    "        print(f\"\\n[FATAL ERROR] An unexpected error occurred during test data preprocessing.\")\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "# --- How to Use ---\n",
    "# 1. Make sure df_test_raw is loaded\n",
    "# 2. Make sure df_test_ready is loaded (containing test user/item embeddings)\n",
    "# 3. Make sure X_train (DataFrame, loaded from pickle), y_train (Series, loaded),\n",
    "#    and fitted_transformers (dict, loaded) are available in your environment.\n",
    "\n",
    "# Example Call:\n",
    "# print(\"\\n--- Processing Test Data ---\")\n",
    "#\n",
    "# # Check if necessary variables exist\n",
    "# required_vars = ['df_test_raw', 'df_test_ready', 'X_train', 'fitted_transformers']\n",
    "# if all(var in locals() or var in globals() for var in required_vars):\n",
    "#\n",
    "#     # Ensure df_test_ready has the necessary columns\n",
    "#     if all(c in df_test_ready.columns for c in ['user_id', 'app_id', 'user_emb', 'game_emb']):\n",
    "#\n",
    "#         X_test_processed = preprocess_test_data(\n",
    "#             df_test_raw,\n",
    "#             df_test_ready[['user_id', 'app_id', 'user_emb', 'game_emb']], # Pass only needed columns\n",
    "#             fitted_transformers,\n",
    "#             X_train.columns # Pass the column index from the processed X_train\n",
    "#         )\n",
    "#\n",
    "#         if X_test_processed is not None:\n",
    "#             print(\"\\n[SUCCESS] X_test_processed DataFrame is ready.\")\n",
    "#             # Now you can proceed to train the model\n",
    "#             # import xgboost as xgb\n",
    "#             # model = xgb.XGBRegressor(...)\n",
    "#             # model.fit(X_train, y_train)\n",
    "#             # predictions = model.predict(X_test_processed)\n",
    "#             # ... evaluation ...\n",
    "#         else:\n",
    "#             print(\"\\n[FAILURE] Test data preprocessing failed.\")\n",
    "#     else:\n",
    "#          print(\"[ERROR] df_test_ready does not contain the required embedding columns ('user_id', 'app_id', 'user_emb', 'game_emb').\")\n",
    "# else:\n",
    "#     print(\"[ERROR] One or more required variables (df_test_raw, df_test_ready, X_train, fitted_transformers) are not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "256fc2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Test Data ---\n",
      "[INFO] Starting preprocessing of test data...\n",
      "----------------------------------------------------------------------\n",
      "[INFO] Initial test data shape: (694638, 50)\n",
      "[INFO] Columns remaining after initial drop: 23\n",
      "\n",
      "[PHASE 0] Merging Test Embeddings...\n",
      "  Extracting required columns from embedding source...\n",
      "    Using embedding dimension: 2, Fill value: [0.0, 0.0]\n",
      "  Merging embeddings onto X_test...\n",
      "  [WARN] Found 518 rows with missing user embeddings post-merge. Filling with [0.0, 0.0].\n",
      "  [WARN] Found 518 rows with missing game embeddings post-merge. Filling with [0.0, 0.0].\n",
      "  [SUCCESS] Embeddings merged.\n",
      "[PHASE 0] Completed.\n",
      "\n",
      "[PHASE 1] Flattening Embeddings...\n",
      "  [INFO] Flattening column: user_emb...\n",
      "  [SUCCESS] Flattened 'user_emb'.\n",
      "  [INFO] Flattening column: game_emb...\n",
      "  [SUCCESS] Flattened 'game_emb'.\n",
      "[PHASE 1] Completed.\n",
      "\n",
      "[PHASE 2] Processing Game Tags (Top N)...\n",
      "  Applying Binarizer using Top 500 tags from training...\n",
      "  [SUCCESS] Processed 'game_tags'. Added/Aligned 500 tag features.\n",
      "[PHASE 2] Completed.\n",
      "\n",
      "[PHASE 3] Processing Game Genres (Binarize)...\n",
      "  Applying fitted genres MLB...\n",
      "  [SUCCESS] Processed 'game_genres'. Added/Aligned 19 genre features.\n",
      "[PHASE 3] Completed.\n",
      "\n",
      "[PHASE 4] Processing Platforms (Binarize)...\n",
      "  Applying fitted platform MLB...\n",
      "  [SUCCESS] Processed 'game_available_platform'. Added/Aligned 47 platform features.\n",
      "[PHASE 4] Completed.\n",
      "\n",
      "[PHASE 5] Processing Dev/Publisher (Top N + Category)...\n",
      "  [INFO] Extracting string from 'game_developer'...\n",
      "  [SUCCESS] Extracted strings for 'game_developer'.\n",
      "  [INFO] Extracting string from 'game_publisher'...\n",
      "  [SUCCESS] Extracted strings for 'game_publisher'.\n",
      "  [INFO] Applying Top 150 / Other to 'game_developer' using stored list...\n",
      "  [SUCCESS] Applied Top N / Other to 'game_developer'.\n",
      "  [INFO] Applying Top 150 / Other to 'game_publisher' using stored list...\n",
      "  [SUCCESS] Applied Top N / Other to 'game_publisher'.\n",
      "[ERROR] X_train (loaded from pickle) is required to get categories for test set conversion.\n",
      "[PHASE 5] Completed.\n",
      "\n",
      "[PHASE 6] Processing Other Categoricals (Category)...\n",
      "  [INFO] Processing 'user_country_code'...\n",
      "[ERROR] X_train (loaded from pickle) is required to get categories for test set conversion.\n",
      "[PHASE 6] Completed.\n",
      "\n",
      "[PHASE 7] Processing Numerical Features (Imputation)...\n",
      "  [INFO] Imputing selected numerical columns using stored medians...\n",
      "    Imputed NaNs in test set: ['game_current_price', 'game_initial_price']\n",
      "[PHASE 7] Completed.\n",
      "\n",
      "[PHASE 8] Processing Date Feature...\n",
      "  [INFO] Processing 'game_released_year'...\n",
      "    Imputed NaNs in 'game_released_year' with median (2015).\n",
      "  [SUCCESS] Created 'game_released_year_since_1984' and dropped original.\n",
      "[PHASE 8] Completed.\n",
      "\n",
      "[PHASE 9] Final Alignment (Reindex)...\n",
      "  [INFO] Aligning test columns to training columns order and presence (588 columns)...\n",
      "  Test columns BEFORE reindex: 588\n",
      "  Test columns AFTER reindex: 588\n",
      "  [INFO] No NaNs found in the final processed test set.\n",
      "[PHASE 9] Completed.\n",
      "\n",
      "[INFO] Test data preprocessing finished.\n",
      "[INFO] Final X_test shape: (694638, 588)\n",
      "\n",
      "[SUCCESS] X_test_processed DataFrame is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "print(\"\\n--- Processing Test Data ---\")\n",
    "\n",
    "# Load your actual test data here\n",
    "# df_test_raw = pd.read_csv('path/to/your/test_raw_data.csv')\n",
    "# df_test_ready = pd.read_csv('path/to/your/test_ready_data.csv') # Or load the part with test embeddings\n",
    "\n",
    "# Make sure they are loaded correctly before calling the function\n",
    "if 'df_test_raw' in locals() and 'df_test_ready' in locals() and 'X_train' in locals() and 'fitted_transformers' in locals():\n",
    "    # Assuming df_test_ready contains the necessary embeddings for test data\n",
    "    X_test_processed = preprocess_test_data(df_test_raw, df_test_ready, fitted_transformers, X_train.columns)\n",
    "\n",
    "    if X_test_processed is not None:\n",
    "        print(\"\\n[SUCCESS] X_test_processed DataFrame is ready.\")\n",
    "        # You can now proceed to train your model with X_train, y_train\n",
    "        # and make predictions using X_test_processed.\n",
    "    else:\n",
    "        print(\"\\n[FAILURE] Test data preprocessing failed.\")\n",
    "else:\n",
    "    print(\"[ERROR] Ensure df_test_raw, df_test_ready, X_train, and fitted_transformers are loaded before calling preprocess_test_data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "398cb6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training XGBoost Model ---\n",
      "Starting model training...\n",
      "[SUCCESS] Model training completed in 40.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import time # To time the training\n",
    "\n",
    "print(\"\\n--- Training XGBoost Model ---\")\n",
    "\n",
    "# Instantiate the XGBoost Regressor\n",
    "# Key parameters:\n",
    "#  - objective='reg:squarederror': For regression tasks.\n",
    "#  - tree_method='hist': Generally fast and memory-efficient.\n",
    "#  - enable_categorical=True: CRITICAL - allows XGBoost to use your 'category' dtype columns directly.\n",
    "#  - random_state=42: For reproducibility.\n",
    "# You might want to adjust n_estimators, learning_rate, max_depth later for tuning.\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    enable_categorical=True,\n",
    "    random_state=42,\n",
    "    n_estimators=100,      # Number of trees (start with 100-500, tune later)\n",
    "    learning_rate=0.1,     # Step size shrinkage (start with 0.1 or 0.05)\n",
    "    max_depth=7,           # Max depth of trees (start with 5-10)\n",
    "    subsample=0.8,         # Fraction of samples used per tree\n",
    "    colsample_bytree=0.8,  # Fraction of features used per tree\n",
    "    n_jobs=-1              # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"[SUCCESS] Model training completed in {(end_time - start_time):.2f} seconds.\")\n",
    "\n",
    "# Optional: Save the trained model\n",
    "# import joblib # Or use pickle\n",
    "# model_filename = 'xgboost_recommender_model.joblib'\n",
    "# joblib.dump(model, model_filename)\n",
    "# print(f\"Trained model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c9b5c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Making Predictions on Test Set ---\n",
      "[ERROR] Failed to make predictions: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:user_country_code: object, game_esrb_rating: object, game_developer: object, game_publisher: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Making Predictions on Test Set ---\")\n",
    "\n",
    "if 'X_test_processed' in locals() and X_test_processed is not None:\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        predictions = model.predict(X_test_processed)\n",
    "        end_time = time.time()\n",
    "        print(f\"[SUCCESS] Predictions made in {(end_time - start_time):.2f} seconds.\")\n",
    "        print(f\"Sample predictions: {predictions[:10]}\") # Show first few predictions\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to make predictions: {e}\")\n",
    "        predictions = None # Set to None if prediction failed\n",
    "else:\n",
    "    print(\"[ERROR] Processed test data 'X_test_processed' not found or is None. Cannot make predictions.\")\n",
    "    predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f4fffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying Dtypes of X_test_processed BEFORE prediction ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 694638 entries, 0 to 694637\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   user_country_code  694638 non-null  object\n",
      " 1   game_esrb_rating   694638 non-null  object\n",
      " 2   game_developer     694638 non-null  object\n",
      " 3   game_publisher     694638 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 21.2+ MB\n",
      "None\n",
      "\n",
      "--- Dtypes of X_train for comparison ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2643279 entries, 0 to 2643278\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   user_country_code  category\n",
      " 1   game_esrb_rating   category\n",
      " 2   game_developer     category\n",
      " 3   game_publisher     category\n",
      "dtypes: category(4)\n",
      "memory usage: 17.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Verifying Dtypes of X_test_processed BEFORE prediction ---\")\n",
    "cols_to_check = ['user_country_code', 'game_esrb_rating', 'game_developer', 'game_publisher']\n",
    "if 'X_test_processed' in locals() and X_test_processed is not None:\n",
    "    cols_present = [col for col in cols_to_check if col in X_test_processed.columns]\n",
    "    if cols_present:\n",
    "        print(X_test_processed[cols_present].info())\n",
    "        print(\"\\n--- Dtypes of X_train for comparison ---\")\n",
    "        print(X_train[cols_present].info()) # Assumes X_train is loaded\n",
    "    else:\n",
    "         print(\"Columns to check not found in X_test_processed.\")\n",
    "else:\n",
    "    print(\"X_test_processed not found or is None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "463c1611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying final category dtype enforcement on X_test_processed ---\n",
      "  Enforcing category dtype for: user_country_code\n",
      "    Filling unknown/NaN values in 'user_country_code' with category: 'Missing'\n",
      "  Enforcing category dtype for: game_esrb_rating\n",
      "  Enforcing category dtype for: game_developer\n",
      "  Enforcing category dtype for: game_publisher\n",
      "\n",
      "--- Verifying Dtypes of X_test_processed AFTER enforcement ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 694638 entries, 0 to 694637\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   user_country_code  694638 non-null  category\n",
      " 1   game_esrb_rating   694638 non-null  category\n",
      " 2   game_developer     694638 non-null  category\n",
      " 3   game_publisher     694638 non-null  category\n",
      "dtypes: category(4)\n",
      "memory usage: 4.7 MB\n",
      "None\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Ensure pandas is imported\n",
    "import numpy as np  # Ensure numpy is imported\n",
    "\n",
    "print(\"\\n--- Applying final category dtype enforcement on X_test_processed ---\")\n",
    "\n",
    "# Assumes X_train and X_test_processed are loaded DataFrames\n",
    "cols_to_enforce = ['user_country_code', 'game_esrb_rating', 'game_developer', 'game_publisher']\n",
    "\n",
    "if 'X_test_processed' in locals() and X_test_processed is not None and 'X_train' in locals():\n",
    "    for col in cols_to_enforce:\n",
    "        if col in X_test_processed.columns and col in X_train.columns:\n",
    "            # Check if the corresponding column in X_train is indeed categorical\n",
    "            if isinstance(X_train[col].dtype, pd.CategoricalDtype):\n",
    "                print(f\"  Enforcing category dtype for: {col}\")\n",
    "                # Get the exact categories from the processed training data\n",
    "                train_categories = X_train[col].cat.categories\n",
    "\n",
    "                # Convert the test column using these specific categories\n",
    "                # This will turn any value in test not in train_categories into NaN\n",
    "                X_test_processed[col] = pd.Categorical(X_test_processed[col], categories=train_categories)\n",
    "\n",
    "                # Handle any NaNs created (values not in train categories) by filling\n",
    "                # with a known category ('Other' or 'Missing' preferred)\n",
    "                if X_test_processed[col].isnull().any():\n",
    "                    fill_cat = 'Other' if 'Other' in train_categories else 'Missing' if 'Missing' in train_categories else None\n",
    "                    if fill_cat:\n",
    "                        print(f\"    Filling unknown/NaN values in '{col}' with category: '{fill_cat}'\")\n",
    "                        # Ensure the fill category exists in the dtype before filling\n",
    "                        if fill_cat not in X_test_processed[col].cat.categories:\n",
    "                             print(f\"    Adding missing category '{fill_cat}' before filling.\")\n",
    "                             X_test_processed[col] = X_test_processed[col].cat.add_categories([fill_cat])\n",
    "                        # Use fillna (using .loc is safer practice for chained assignment)\n",
    "                        X_test_processed.loc[X_test_processed[col].isnull(), col] = fill_cat\n",
    "                        # Verify no NaNs remain\n",
    "                        if X_test_processed[col].isnull().any():\n",
    "                            print(f\"    [WARN] NaNs still remain in '{col}' after attempting fill.\")\n",
    "                    else:\n",
    "                        print(f\"    [WARN] Could not determine appropriate fill category ('Other' or 'Missing') for NaNs in '{col}'. NaNs may remain.\")\n",
    "            else:\n",
    "                 print(f\"  [WARN] Cannot enforce category for '{col}' as it's not categorical in X_train.\")\n",
    "        else:\n",
    "             print(f\"  [WARN] Column '{col}' not found in X_test_processed or X_train for final dtype enforcement.\")\n",
    "\n",
    "    # Final verification after enforcement\n",
    "    print(\"\\n--- Verifying Dtypes of X_test_processed AFTER enforcement ---\")\n",
    "    cols_present = [col for col in cols_to_enforce if col in X_test_processed.columns]\n",
    "    if cols_present:\n",
    "        print(X_test_processed[cols_present].info())\n",
    "    else:\n",
    "         print(\"Columns to check not found in X_test_processed.\")\n",
    "\n",
    "else:\n",
    "     print(\"[ERROR] X_test_processed or X_train not found. Cannot enforce dtypes.\")\n",
    "\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c79d2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Making Predictions on Test Set (Attempt 2) ---\n",
      "[SUCCESS] Predictions made in 0.98 seconds.\n",
      "Sample predictions: [0.38354272 0.20945464 0.19145061 0.16514194 0.27555335 0.26256698\n",
      " 0.38142455 0.25643748 0.2552675  0.25188658]\n"
     ]
    }
   ],
   "source": [
    "# --- Now call predict AFTER running the enforcement code above ---\n",
    "print(\"\\n--- Making Predictions on Test Set (Attempt 2) ---\")\n",
    "if 'X_test_processed' in locals() and X_test_processed is not None and 'model' in locals():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        predictions = model.predict(X_test_processed)\n",
    "        end_time = time.time()\n",
    "        print(f\"[SUCCESS] Predictions made in {(end_time - start_time):.2f} seconds.\")\n",
    "        print(f\"Sample predictions: {predictions[:10]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to make predictions even after dtype enforcement: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        predictions = None\n",
    "else:\n",
    "    print(\"[ERROR] X_test_processed or model not found. Cannot make predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9008b6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Defining y_test from df_test_raw...\n",
      "[SUCCESS] Created y_test (length: 694638) from 'relevance_score' column.\n",
      "[INFO] y_test length matches predictions length.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Make sure pandas is imported\n",
    "\n",
    "print(\"[INFO] Defining y_test from df_test_raw...\")\n",
    "\n",
    "# --- !!! Ensure df_test_raw is loaded correctly !!! ---\n",
    "# Example: df_test_raw = pd.read_csv('path/to/your/test_raw_data.csv') # Or however you load it\n",
    "\n",
    "target_column_name = 'relevance_score'\n",
    "\n",
    "if 'df_test_raw' in locals() or 'df_test_raw' in globals():\n",
    "    if isinstance(df_test_raw, pd.DataFrame) and not df_test_raw.empty:\n",
    "        if target_column_name in df_test_raw.columns:\n",
    "            # Create y_test - make sure its index aligns with X_test_processed\n",
    "            # If X_test_processed was created from a copy of df_test_raw and rows weren't dropped, the index should align.\n",
    "            y_test = df_test_raw[target_column_name].copy()\n",
    "            print(f\"[SUCCESS] Created y_test (length: {len(y_test)}) from '{target_column_name}' column.\")\n",
    "\n",
    "            # Optional: Quick check if length matches predictions (if predictions exist)\n",
    "            if 'predictions' in locals() and predictions is not None:\n",
    "                if len(y_test) != len(predictions):\n",
    "                     print(f\"[WARNING] Length mismatch! y_test has {len(y_test)} samples, predictions have {len(predictions)}. Evaluation might fail.\")\n",
    "                else:\n",
    "                     print(\"[INFO] y_test length matches predictions length.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"[ERROR] Target column '{target_column_name}' not found in df_test_raw. Cannot create y_test.\")\n",
    "    else:\n",
    "         print(\"[ERROR] df_test_raw is not a valid or non-empty DataFrame.\")\n",
    "else:\n",
    "    print(\"[ERROR] DataFrame 'df_test_raw' not found. Please load your raw test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41256b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcfa7936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model Performance ---\n",
      "Evaluating performance on 694638 test samples.\n",
      "\n",
      "Evaluation Metrics:\n",
      "  Mean Squared Error (MSE):      0.0778\n",
      "  Root Mean Squared Error (RMSE): 0.2789\n",
      "  Mean Absolute Error (MAE):     0.2138\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# import matplotlib.pyplot as plt # Uncomment if you want the plot and have matplotlib installed\n",
    "\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "\n",
    "# --- !!! IMPORTANT !!! ---\n",
    "# Ensure 'y_test' (your true test relevance scores) is loaded and available HERE.\n",
    "# It MUST correspond row-by-row to the 'X_test_processed' data used for predictions.\n",
    "\n",
    "# Example: If you separated it from df_test_raw earlier:\n",
    "# y_test = df_test_raw['relevance_score'].copy() # Make sure df_test_raw indices match X_test_processed if using this\n",
    "\n",
    "# Check if both y_test and predictions are available\n",
    "if 'y_test' in locals() or 'y_test' in globals():\n",
    "    if 'predictions' in locals() and predictions is not None:\n",
    "        try:\n",
    "            # Verify lengths match before calculating metrics\n",
    "            if len(y_test) == len(predictions):\n",
    "                print(f\"Evaluating performance on {len(y_test)} test samples.\")\n",
    "\n",
    "                # Calculate metrics\n",
    "                mse = mean_squared_error(y_test, predictions)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "                print(f\"\\nEvaluation Metrics:\")\n",
    "                print(f\"  Mean Squared Error (MSE):      {mse:.4f}\")\n",
    "                print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "                print(f\"  Mean Absolute Error (MAE):     {mae:.4f}\")\n",
    "\n",
    "                # --- Optional: Scatter plot of True vs Predicted ---\n",
    "                # print(\"\\nGenerating True vs Predicted plot (optional)...\")\n",
    "                # try:\n",
    "                #     import matplotlib.pyplot as plt\n",
    "                #     plt.figure(figsize=(8, 8))\n",
    "                #     # Sample data if the test set is very large to avoid overplotting\n",
    "                #     sample_size = min(len(y_test), 50000) # Adjust sample size if needed\n",
    "                #     indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "                #\n",
    "                #     # Handle y_test being Series or numpy array\n",
    "                #     y_test_sample = y_test.iloc[indices] if hasattr(y_test, 'iloc') else y_test[indices]\n",
    "                #     predictions_sample = predictions[indices]\n",
    "                #\n",
    "                #     plt.scatter(y_test_sample, predictions_sample, alpha=0.1)\n",
    "                #     # Add y=x line for reference\n",
    "                #     min_val = min(y_test_sample.min(), predictions_sample.min())\n",
    "                #     max_val = max(y_test_sample.max(), predictions_sample.max())\n",
    "                #     plt.plot([min_val, max_val], [min_val, max_val], '--', color='red', label='Perfect Prediction (y=x)')\n",
    "                #\n",
    "                #     plt.xlabel(\"True Relevance Score\")\n",
    "                #     plt.ylabel(\"Predicted Relevance Score\")\n",
    "                #     plt.title(\"True vs. Predicted Relevance Score (Sample)\")\n",
    "                #     plt.grid(True)\n",
    "                #     plt.legend()\n",
    "                #     plt.show()\n",
    "                # except ImportError:\n",
    "                #     print(\"  (Plotting skipped: matplotlib not found. Install: pip install matplotlib)\")\n",
    "                # except Exception as plot_err:\n",
    "                #      print(f\"  (Plotting failed: {plot_err})\")\n",
    "\n",
    "            else:\n",
    "                print(f\"[ERROR] Length mismatch! y_test has {len(y_test)} samples, predictions have {len(predictions)}. Cannot evaluate.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed during evaluation calculation: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "    elif 'predictions' not in locals() or predictions is None:\n",
    "        print(\"[ERROR] `predictions` variable not found or is None. Cannot evaluate.\")\n",
    "else:\n",
    "     print(\"[ERROR] `y_test` variable not found. Please load or define the true test labels corresponding to X_test_processed.\")\n",
    "\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b295e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Making Predictions on Test Set ---\n",
      "[SUCCESS] Predictions made in 0.78 seconds.\n",
      "Sample predictions: [0.38354272 0.20945464 0.19145061 0.16514194 0.27555335 0.26256698\n",
      " 0.38142455 0.25643748 0.2552675  0.25188658]\n"
     ]
    }
   ],
   "source": [
    "import time # To time the prediction\n",
    "import traceback # For error details\n",
    "\n",
    "print(\"\\n--- Making Predictions on Test Set ---\")\n",
    "\n",
    "# Ensure model and X_test_processed are loaded and valid\n",
    "if 'model' in locals() and 'X_test_processed' in locals() and X_test_processed is not None:\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        # THE ACTUAL PREDICTION STEP:\n",
    "        predictions = model.predict(X_test_processed)\n",
    "        end_time = time.time()\n",
    "        print(f\"[SUCCESS] Predictions made in {(end_time - start_time):.2f} seconds.\")\n",
    "        print(f\"Sample predictions: {predictions[:10]}\") # Verify it outputs numbers\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to make predictions: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        predictions = None # Set to None if prediction failed\n",
    "else:\n",
    "    # Provide more specific feedback if possible\n",
    "    if 'model' not in locals():\n",
    "         print(\"[ERROR] Trained 'model' not found. Please load or train the model.\")\n",
    "    if 'X_test_processed' not in locals() or X_test_processed is None:\n",
    "         print(\"[ERROR] Processed test data 'X_test_processed' not found or is None.\")\n",
    "    predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149cd1e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372698ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06bc585f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a289cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
