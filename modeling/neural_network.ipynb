{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, Sampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import ndcg_score\n",
    "import optuna\n",
    "import itertools\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2079135a2f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix randomness for reproducibility, but may still have slight variation\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    # Get a unique seed for each worker based on torch's initial seed\n",
    "    worker_seed = (RANDOM_SEED + worker_id) % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2595694, 130) (694120, 130)\n"
     ]
    }
   ],
   "source": [
    "train_df = joblib.load(r'..\\assets\\combined\\train_ready.pkl')\n",
    "test_df = joblib.load(r'..\\assets\\combined\\test_ready.pkl')\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2595694 entries, 0 to 2595693\n",
      "Data columns (total 130 columns):\n",
      " #    Column                                             Non-Null Count    Dtype  \n",
      "---   ------                                             --------------    -----  \n",
      " 0    user_id                                            2595694 non-null  object \n",
      " 1    app_id                                             2595694 non-null  int64  \n",
      " 2    relevance_score                                    2595694 non-null  float64\n",
      " 3    user_country_code                                  2595694 non-null  object \n",
      " 4    user_has_coordinates                               2595694 non-null  bool   \n",
      " 5    user_latitude                                      2595694 non-null  float64\n",
      " 6    user_longitude                                     2595694 non-null  float64\n",
      " 7    user_account_age_months                            2595694 non-null  float64\n",
      " 8    game_name                                          2595694 non-null  string \n",
      " 9    game_tba                                           2595694 non-null  bool   \n",
      " 10   game_RAWG_weighted_avg_rating                      2595694 non-null  float64\n",
      " 11   game_RAWG_ratings_count                            2595694 non-null  float64\n",
      " 12   game_RAWG_reviews_with_text_count                  2595694 non-null  float64\n",
      " 13   game_RAWG_bookmark_count                           2595694 non-null  float64\n",
      " 14   game_metacritic_rating                             2595694 non-null  float64\n",
      " 15   game_RAWG_system_suggest_count                     2595694 non-null  float64\n",
      " 16   game_RAWG_reviews_count                            2595694 non-null  float64\n",
      " 17   game_tags                                          2595694 non-null  object \n",
      " 18   game_released_month                                2595694 non-null  float64\n",
      " 19   game_released_day                                  2595694 non-null  float64\n",
      " 20   game_RAWG_rating_5_percent                         2595694 non-null  float64\n",
      " 21   game_RAWG_rating_4_percent                         2595694 non-null  float64\n",
      " 22   game_RAWG_rating_3_percent                         2595694 non-null  float64\n",
      " 23   game_RAWG_rating_1_percent                         2595694 non-null  float64\n",
      " 24   game_RAWG_bookmark_type_yet_count                  2595694 non-null  float64\n",
      " 25   game_RAWG_bookmark_type_owned_count                2595694 non-null  float64\n",
      " 26   game_RAWG_bookmark_type_beaten_count               2595694 non-null  float64\n",
      " 27   game_RAWG_bookmark_type_toplay_count               2595694 non-null  float64\n",
      " 28   game_RAWG_bookmark_type_dropped_count              2595694 non-null  float64\n",
      " 29   game_RAWG_bookmark_type_playing_count              2595694 non-null  float64\n",
      " 30   game_available_platform                            2595694 non-null  object \n",
      " 31   game_developer                                     2595694 non-null  object \n",
      " 32   game_publisher                                     2595694 non-null  object \n",
      " 33   game_positive_review_count                         2595694 non-null  float64\n",
      " 34   game_negative_review_count                         2595694 non-null  float64\n",
      " 35   game_avg_playtime_forever                          2595694 non-null  float64\n",
      " 36   game_median_playtime_forever                       2595694 non-null  float64\n",
      " 37   game_current_price                                 2595694 non-null  float64\n",
      " 38   game_initial_price                                 2595694 non-null  float64\n",
      " 39   game_current_discount                              2595694 non-null  bool   \n",
      " 40   game_concurrent_user                               2595694 non-null  float64\n",
      " 41   game_estimate_owners_lower                         2595694 non-null  float64\n",
      " 42   game_estimate_owners_upper                         2595694 non-null  float64\n",
      " 43   game_esrb_rating_Rating Pending                    2595694 non-null  bool   \n",
      " 44   game_esrb_rating_Missing                           2595694 non-null  bool   \n",
      " 45   game_esrb_rating_Mature                            2595694 non-null  bool   \n",
      " 46   game_esrb_rating_Everyone 10+                      2595694 non-null  bool   \n",
      " 47   game_esrb_rating_Teen                              2595694 non-null  bool   \n",
      " 48   game_esrb_rating_Everyone                          2595694 non-null  bool   \n",
      " 49   game_esrb_rating_Adults Only                       2595694 non-null  bool   \n",
      " 50   game_genres_Action                                 2595694 non-null  bool   \n",
      " 51   game_genres_Adventure                              2595694 non-null  bool   \n",
      " 52   game_genres_Arcade                                 2595694 non-null  bool   \n",
      " 53   game_genres_Board Games                            2595694 non-null  bool   \n",
      " 54   game_genres_Card                                   2595694 non-null  bool   \n",
      " 55   game_genres_Casual                                 2595694 non-null  bool   \n",
      " 56   game_genres_Educational                            2595694 non-null  bool   \n",
      " 57   game_genres_Family                                 2595694 non-null  bool   \n",
      " 58   game_genres_Fighting                               2595694 non-null  bool   \n",
      " 59   game_genres_Indie                                  2595694 non-null  bool   \n",
      " 60   game_genres_Massively Multiplayer                  2595694 non-null  bool   \n",
      " 61   game_genres_Platformer                             2595694 non-null  bool   \n",
      " 62   game_genres_Puzzle                                 2595694 non-null  bool   \n",
      " 63   game_genres_RPG                                    2595694 non-null  bool   \n",
      " 64   game_genres_Racing                                 2595694 non-null  bool   \n",
      " 65   game_genres_Shooter                                2595694 non-null  bool   \n",
      " 66   game_genres_Simulation                             2595694 non-null  bool   \n",
      " 67   game_genres_Sports                                 2595694 non-null  bool   \n",
      " 68   game_genres_Strategy                               2595694 non-null  bool   \n",
      " 69   game_platforms_3DO                                 2595694 non-null  bool   \n",
      " 70   game_platforms_Android                             2595694 non-null  bool   \n",
      " 71   game_platforms_Apple Macintosh                     2595694 non-null  bool   \n",
      " 72   game_platforms_Atari                               2595694 non-null  bool   \n",
      " 73   game_platforms_Commodore / Amiga                   2595694 non-null  bool   \n",
      " 74   game_platforms_Linux                               2595694 non-null  bool   \n",
      " 75   game_platforms_Neo Geo                             2595694 non-null  bool   \n",
      " 76   game_platforms_Nintendo                            2595694 non-null  bool   \n",
      " 77   game_platforms_PC                                  2595694 non-null  bool   \n",
      " 78   game_platforms_PlayStation                         2595694 non-null  bool   \n",
      " 79   game_platforms_SEGA                                2595694 non-null  bool   \n",
      " 80   game_platforms_Web                                 2595694 non-null  bool   \n",
      " 81   game_platforms_Xbox                                2595694 non-null  bool   \n",
      " 82   game_platforms_iOS                                 2595694 non-null  bool   \n",
      " 83   game_popularity                                    2595694 non-null  float64\n",
      " 84   user_preference_game_popularity                    2595694 non-null  float64\n",
      " 85   user_preference_game_duration                      2595694 non-null  float64\n",
      " 86   user_preference_new_game                           2595694 non-null  float64\n",
      " 87   user_preference_avg_spent                          2595694 non-null  float64\n",
      " 88   user_preference_game_esrb_rating_Rating Pending    2595694 non-null  float64\n",
      " 89   user_preference_game_esrb_rating_Missing           2595694 non-null  float64\n",
      " 90   user_preference_game_esrb_rating_Mature            2595694 non-null  float64\n",
      " 91   user_preference_game_esrb_rating_Everyone 10+      2595694 non-null  float64\n",
      " 92   user_preference_game_esrb_rating_Teen              2595694 non-null  float64\n",
      " 93   user_preference_game_esrb_rating_Everyone          2595694 non-null  float64\n",
      " 94   user_preference_game_esrb_rating_Adults Only       2595694 non-null  float64\n",
      " 95   user_preference_game_genres_Action                 2595694 non-null  float64\n",
      " 96   user_preference_game_genres_Adventure              2595694 non-null  float64\n",
      " 97   user_preference_game_genres_Arcade                 2595694 non-null  float64\n",
      " 98   user_preference_game_genres_Board Games            2595694 non-null  float64\n",
      " 99   user_preference_game_genres_Card                   2595694 non-null  float64\n",
      " 100  user_preference_game_genres_Casual                 2595694 non-null  float64\n",
      " 101  user_preference_game_genres_Educational            2595694 non-null  float64\n",
      " 102  user_preference_game_genres_Family                 2595694 non-null  float64\n",
      " 103  user_preference_game_genres_Fighting               2595694 non-null  float64\n",
      " 104  user_preference_game_genres_Indie                  2595694 non-null  float64\n",
      " 105  user_preference_game_genres_Massively Multiplayer  2595694 non-null  float64\n",
      " 106  user_preference_game_genres_Platformer             2595694 non-null  float64\n",
      " 107  user_preference_game_genres_Puzzle                 2595694 non-null  float64\n",
      " 108  user_preference_game_genres_RPG                    2595694 non-null  float64\n",
      " 109  user_preference_game_genres_Racing                 2595694 non-null  float64\n",
      " 110  user_preference_game_genres_Shooter                2595694 non-null  float64\n",
      " 111  user_preference_game_genres_Simulation             2595694 non-null  float64\n",
      " 112  user_preference_game_genres_Sports                 2595694 non-null  float64\n",
      " 113  user_preference_game_genres_Strategy               2595694 non-null  float64\n",
      " 114  user_preference_game_platforms_3DO                 2595694 non-null  float64\n",
      " 115  user_preference_game_platforms_Android             2595694 non-null  float64\n",
      " 116  user_preference_game_platforms_Apple Macintosh     2595694 non-null  float64\n",
      " 117  user_preference_game_platforms_Atari               2595694 non-null  float64\n",
      " 118  user_preference_game_platforms_Commodore / Amiga   2595694 non-null  float64\n",
      " 119  user_preference_game_platforms_Linux               2595694 non-null  float64\n",
      " 120  user_preference_game_platforms_Neo Geo             2595694 non-null  float64\n",
      " 121  user_preference_game_platforms_Nintendo            2595694 non-null  float64\n",
      " 122  user_preference_game_platforms_PlayStation         2595694 non-null  float64\n",
      " 123  user_preference_game_platforms_SEGA                2595694 non-null  float64\n",
      " 124  user_preference_game_platforms_Web                 2595694 non-null  float64\n",
      " 125  user_preference_game_platforms_Xbox                2595694 non-null  float64\n",
      " 126  user_preference_game_platforms_iOS                 2595694 non-null  float64\n",
      " 127  game_released_year_since_1984.0                    2595694 non-null  float64\n",
      " 128  user_emb                                           2595694 non-null  object \n",
      " 129  game_emb                                           2595694 non-null  object \n",
      "dtypes: bool(43), float64(77), int64(1), object(8), string(1)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing categorical columns before passing them to embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_country_code'] \n",
      " ['game_tags', 'game_available_platform', 'game_developer', 'game_publisher'] \n",
      " ['user_latitude', 'user_longitude', 'user_account_age_months', 'game_RAWG_weighted_avg_rating', 'game_RAWG_ratings_count', 'game_RAWG_reviews_with_text_count', 'game_RAWG_bookmark_count', 'game_metacritic_rating', 'game_RAWG_system_suggest_count', 'game_RAWG_reviews_count', 'game_released_month', 'game_released_day', 'game_RAWG_rating_5_percent', 'game_RAWG_rating_4_percent', 'game_RAWG_rating_3_percent', 'game_RAWG_rating_1_percent', 'game_RAWG_bookmark_type_yet_count', 'game_RAWG_bookmark_type_owned_count', 'game_RAWG_bookmark_type_beaten_count', 'game_RAWG_bookmark_type_toplay_count', 'game_RAWG_bookmark_type_dropped_count', 'game_RAWG_bookmark_type_playing_count', 'game_positive_review_count', 'game_negative_review_count', 'game_avg_playtime_forever', 'game_median_playtime_forever', 'game_current_price', 'game_initial_price', 'game_concurrent_user', 'game_estimate_owners_lower', 'game_estimate_owners_upper', 'game_popularity', 'user_preference_game_popularity', 'user_preference_game_duration', 'user_preference_new_game', 'user_preference_avg_spent', 'user_preference_game_esrb_rating_Rating Pending', 'user_preference_game_esrb_rating_Missing', 'user_preference_game_esrb_rating_Mature', 'user_preference_game_esrb_rating_Everyone 10+', 'user_preference_game_esrb_rating_Teen', 'user_preference_game_esrb_rating_Everyone', 'user_preference_game_esrb_rating_Adults Only', 'user_preference_game_genres_Action', 'user_preference_game_genres_Adventure', 'user_preference_game_genres_Arcade', 'user_preference_game_genres_Board Games', 'user_preference_game_genres_Card', 'user_preference_game_genres_Casual', 'user_preference_game_genres_Educational', 'user_preference_game_genres_Family', 'user_preference_game_genres_Fighting', 'user_preference_game_genres_Indie', 'user_preference_game_genres_Massively Multiplayer', 'user_preference_game_genres_Platformer', 'user_preference_game_genres_Puzzle', 'user_preference_game_genres_RPG', 'user_preference_game_genres_Racing', 'user_preference_game_genres_Shooter', 'user_preference_game_genres_Simulation', 'user_preference_game_genres_Sports', 'user_preference_game_genres_Strategy', 'user_preference_game_platforms_3DO', 'user_preference_game_platforms_Android', 'user_preference_game_platforms_Apple Macintosh', 'user_preference_game_platforms_Atari', 'user_preference_game_platforms_Commodore / Amiga', 'user_preference_game_platforms_Linux', 'user_preference_game_platforms_Neo Geo', 'user_preference_game_platforms_Nintendo', 'user_preference_game_platforms_PlayStation', 'user_preference_game_platforms_SEGA', 'user_preference_game_platforms_Web', 'user_preference_game_platforms_Xbox', 'user_preference_game_platforms_iOS', 'game_released_year_since_1984.0'] \n",
      " ['user_has_coordinates', 'game_tba', 'game_current_discount', 'game_esrb_rating_Rating Pending', 'game_esrb_rating_Missing', 'game_esrb_rating_Mature', 'game_esrb_rating_Everyone 10+', 'game_esrb_rating_Teen', 'game_esrb_rating_Everyone', 'game_esrb_rating_Adults Only', 'game_genres_Action', 'game_genres_Adventure', 'game_genres_Arcade', 'game_genres_Board Games', 'game_genres_Card', 'game_genres_Casual', 'game_genres_Educational', 'game_genres_Family', 'game_genres_Fighting', 'game_genres_Indie', 'game_genres_Massively Multiplayer', 'game_genres_Platformer', 'game_genres_Puzzle', 'game_genres_RPG', 'game_genres_Racing', 'game_genres_Shooter', 'game_genres_Simulation', 'game_genres_Sports', 'game_genres_Strategy', 'game_platforms_3DO', 'game_platforms_Android', 'game_platforms_Apple Macintosh', 'game_platforms_Atari', 'game_platforms_Commodore / Amiga', 'game_platforms_Linux', 'game_platforms_Neo Geo', 'game_platforms_Nintendo', 'game_platforms_PC', 'game_platforms_PlayStation', 'game_platforms_SEGA', 'game_platforms_Web', 'game_platforms_Xbox', 'game_platforms_iOS']\n"
     ]
    }
   ],
   "source": [
    "# Note that categorical columns with less than 20 unique values are already one-hot encoded\n",
    "# Here will only handle the rest\n",
    "\n",
    "single_cat_cols = []\n",
    "multi_cat_cols = []\n",
    "\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    if not col in ['user_id', 'user_emb', 'game_emb']:\n",
    "        if isinstance(train_df[col].iloc[0], list):\n",
    "            multi_cat_cols.append(col)\n",
    "        else:\n",
    "            single_cat_cols.append(col)\n",
    "\n",
    "num_cols = [col for col in train_df.select_dtypes(include=['number']).columns if not col in ['app_id', 'relevance_score']]\n",
    "# bool_cols also includes one-hot columns\n",
    "bool_cols = [col for col in train_df.select_dtypes(include=['bool']).columns]\n",
    "cf_emb_cols = ['user_emb', 'game_emb']\n",
    "\n",
    "print(single_cat_cols, '\\n', multi_cat_cols, '\\n', num_cols, '\\n', bool_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode categorical columns in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_country_code: 222\n",
      "game_tags: 2460\n",
      "game_available_platform: 47\n",
      "game_developer: 15183\n",
      "game_publisher: 10723\n"
     ]
    }
   ],
   "source": [
    "for col in single_cat_cols:\n",
    "    print(f\"{col}: {train_df[col].nunique()}\")\n",
    "for col in multi_cat_cols:\n",
    "    print(f\"{col}: {train_df[col].explode().nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since game_tags, game_developer, and game_publisher have extremely high-cardinality, we first group infrequent categories into \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_threshold = 0.80\n",
    "cat_to_other_mapper = {}  # Save for mapping cat to other in test set\n",
    "\n",
    "for col in ['game_tags', 'game_developer', 'game_publisher']:\n",
    "    all_categories = list(itertools.chain.from_iterable(train_df[col]))  # Flatten\n",
    "\n",
    "    freq_counts = pd.Series(all_categories).value_counts()\n",
    "    cumulative_fraction = freq_counts.cumsum() / freq_counts.sum()\n",
    "    \n",
    "    # 80% coverage cutoff\n",
    "    cutoff_index = np.searchsorted(cumulative_fraction, coverage_threshold)\n",
    "    \n",
    "    # Keep only about 80%\n",
    "    top_cats = set(freq_counts.index[:cutoff_index])\n",
    "\n",
    "    # Save mapper for test set\n",
    "    mapper = {cat: (cat if cat in top_cats else \"Other\") for cat in freq_counts.index}\n",
    "    cat_to_other_mapper[col] = mapper\n",
    "\n",
    "    def map_cat_list_to_top(cat_list):\n",
    "        return list({cat if cat in top_cats else \"Other\" for cat in cat_list})  # Only keep single \"Other\" label\n",
    "\n",
    "    train_df[col] = train_df[col].apply(map_cat_list_to_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_country_code: 222\n",
      "game_tags: 111\n",
      "game_available_platform: 47\n",
      "game_developer: 3278\n",
      "game_publisher: 1503\n"
     ]
    }
   ],
   "source": [
    "for col in single_cat_cols:\n",
    "    print(f\"{col}: {train_df[col].nunique()}\")\n",
    "for col in multi_cat_cols:\n",
    "    print(f\"{col}: {train_df[col].explode().nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn label encoder is too damn slow, use dict instead\n",
    "\n",
    "single_cat_label_encoders = {}\n",
    "multi_cat_label_encoders = {}\n",
    "max_seq_len_per_column = {}\n",
    "\n",
    "new_columns_single = {}\n",
    "new_columns_multi_padded = {}\n",
    "\n",
    "# Label Encode Single Categorical Columns\n",
    "for col in single_cat_cols:\n",
    "    all_categories = train_df[col].unique().tolist()\n",
    "\n",
    "    mapping = {cat: i for i, cat in enumerate(all_categories)}\n",
    "    single_cat_label_encoders[col] = mapping  # Store mapper for later use on test set\n",
    "\n",
    "    new_columns_single[col + '_encoded'] = train_df[col].map(mapping)\n",
    "\n",
    "# Label Encode and Pad Multi-Categorical\n",
    "for col in multi_cat_cols:\n",
    "    all_categories = set(itertools.chain.from_iterable(train_df[col]))\n",
    "    \n",
    "    mapping = {cat: i + 1 for i, cat in enumerate(all_categories)}\n",
    "    multi_cat_label_encoders[col] = mapping  # Store mapper for later use on test set\n",
    "    \n",
    "    # Label encode each category\n",
    "    encoded_lists = [[mapping[item] for item in row] for row in train_df[col]]\n",
    "    \n",
    "    # Compute the max sequence length for the current column\n",
    "    max_seq_len_per_column[col] = max(len(seq) for seq in encoded_lists)\n",
    "    \n",
    "    # Pad sequences with 0 (padding index)\n",
    "    PADDING_VALUE = 0\n",
    "    padded_sequences = pad_sequence(\n",
    "        [torch.tensor(seq, dtype=torch.int64) for seq in encoded_lists],\n",
    "        batch_first=True, padding_value=PADDING_VALUE\n",
    "    )\n",
    "    \n",
    "    new_columns_multi_padded[col + '_encoded_padded'] = padded_sequences.numpy().tolist()\n",
    "\n",
    "df_single = pd.DataFrame(new_columns_single, index=train_df.index)\n",
    "df_multi_padded = pd.DataFrame(new_columns_multi_padded, index=train_df.index)\n",
    "train_df = pd.concat([train_df, df_single, df_multi_padded], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_tags</th>\n",
       "      <th>game_tags_encoded_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1512276</th>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389635</th>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307380</th>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197667</th>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368763</th>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        game_tags                           game_tags_encoded_padded\n",
       "1512276        []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2389635        []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2307380        []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1197667        []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1368763        []  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The missing in multi-cat columns is encoded as all 0 list\n",
    "train_df[train_df['game_tags'].apply(lambda x: len(x)==0)][['game_tags', 'game_tags_encoded_padded']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "13\n",
      "10\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Padded size\n",
    "for col in multi_cat_cols:\n",
    "    print(len(train_df[col + '_encoded_padded'].sample(1).values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(train_df, r'..\\assets\\combined\\train_NN_processed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply same transformation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single categorical columns\n",
    "for col in single_cat_cols:\n",
    "    mapping = single_cat_label_encoders[col]\n",
    "    unknown_label = len(mapping)\n",
    "\n",
    "    test_df[col + '_encoded'] = test_df[col].apply(\n",
    "        lambda x: mapping.get(x, unknown_label)  # Use largest label to encode Unknown\n",
    "    )\n",
    "\n",
    "# Multi categorical columns\n",
    "for col in multi_cat_cols:\n",
    "    mapping = multi_cat_label_encoders[col]\n",
    "    unknown_label = len(mapping) + 1  # Use +1 since label start from 1 (0 is used for padding)\n",
    "\n",
    "    test_df[col + '_encoded'] = test_df[col].apply(\n",
    "        lambda x: [mapping.get(item, unknown_label) for item in x]  # Use largest label + 1 to encode Unknown\n",
    "    )\n",
    "    \n",
    "    # Pad sequences with 0 (padding index)\n",
    "    max_seq_len = max_seq_len_per_column[col]\n",
    "    PADDING_VALUE = 0\n",
    "    padded_sequences = pad_sequence(\n",
    "        [torch.tensor(row, dtype=torch.int64) for row in test_df[col + '_encoded']],\n",
    "        batch_first=True, padding_value=PADDING_VALUE\n",
    "    )\n",
    "\n",
    "    test_df[col + '_encoded_padded'] = list(padded_sequences.numpy())\n",
    "    test_df.drop(columns=[col + '_encoded'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(train_df, r'..\\assets\\combined\\test_NN_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = joblib.load(r'..\\assets\\combined\\train_NN_processed.pkl')\n",
    "test_df = joblib.load(r'..\\assets\\combined\\test_NN_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cat_cols = []\n",
    "multi_cat_cols = []\n",
    "\n",
    "for col in train_df.select_dtypes(include=['object']).columns:\n",
    "    if not col in ['user_id', 'user_emb', 'game_emb']:\n",
    "        if isinstance(train_df[col].iloc[0], list):\n",
    "            multi_cat_cols.append(col)\n",
    "        else:\n",
    "            single_cat_cols.append(col)\n",
    "\n",
    "num_cols = [col for col in train_df.select_dtypes(include=['number']).columns if not col in ['app_id', 'relevance_score']]\n",
    "# bool_cols also includes one-hot columns\n",
    "bool_cols = [col for col in train_df.select_dtypes(include=['bool']).columns]\n",
    "cf_emb_cols = ['user_emb', 'game_emb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserGameDataset(Dataset):\n",
    "    def __init__(self, single_cat_inputs, multi_cat_inputs, num_inputs, bool_inputs, CF_inputs, relevance_score, user_ids):\n",
    "        self.single_cat_inputs = single_cat_inputs\n",
    "        self.multi_cat_inputs = multi_cat_inputs\n",
    "        self.num_inputs = num_inputs\n",
    "        self.bool_inputs = bool_inputs\n",
    "        self.CF_inputs = CF_inputs\n",
    "        self.relevance_score = relevance_score\n",
    "        self.user_ids = user_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.relevance_score)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # For each sample, return the inputs and the corresponding target (score)\n",
    "        single_cat_input = self.single_cat_inputs[idx]\n",
    "        multi_cat_input = [multi_cat[idx] for multi_cat in self.multi_cat_inputs]  # Extract each multi-cat feature\n",
    "        numeric_input = self.num_inputs[idx]\n",
    "        boolean_input = self.bool_inputs[idx]\n",
    "        CF_input = self.CF_inputs[idx]\n",
    "\n",
    "        # Combine input into single tensor\n",
    "        all_input = torch.cat([single_cat_input, *multi_cat_input, numeric_input, boolean_input, *CF_input])\n",
    "\n",
    "        target = self.relevance_score[idx]\n",
    "\n",
    "        user_id = self.user_ids[idx]\n",
    "        \n",
    "        return all_input, target, user_id\n",
    "    \n",
    "# Convert into a tensor\n",
    "train_relevance_score = torch.tensor(train_df['relevance_score'].values, dtype=torch.float32)\n",
    "train_single_cat_inputs = torch.tensor(train_df[[col + '_encoded' for col in single_cat_cols]].values)\n",
    "train_multi_cat_inputs = [\n",
    "    torch.tensor(np.stack(train_df[col + '_encoded_padded'].values), dtype=torch.float32)\n",
    "    for col in multi_cat_cols\n",
    "]\n",
    "train_num_inputs = torch.tensor(train_df[num_cols].values, dtype=torch.float32)\n",
    "train_bool_inputs = torch.tensor(train_df[bool_cols].values)\n",
    "train_CF_inputs = [\n",
    "    torch.tensor(np.stack(train_df[col].values), dtype=torch.float32)\n",
    "    for col in cf_emb_cols\n",
    "]\n",
    "train_user_ids = torch.tensor(train_df['user_id'].astype(np.int64).values)\n",
    "\n",
    "train_dataset = UserGameDataset(train_single_cat_inputs, train_multi_cat_inputs, train_num_inputs, train_bool_inputs, train_CF_inputs, train_relevance_score, train_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [41, 13, 10, 4] 76 43 [2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Number of columns for each type of inputs\n",
    "single_cat_n_columns = train_single_cat_inputs.shape[1]\n",
    "multi_cat_n_columns = [tensor.shape[1] for tensor in train_multi_cat_inputs]\n",
    "num_n_columns = train_num_inputs.shape[1]\n",
    "bool_n_columns = train_bool_inputs.shape[1]\n",
    "CF_n_columns = [tensor.shape[1] for tensor in train_CF_inputs]\n",
    "\n",
    "print(single_cat_n_columns, multi_cat_n_columns, num_n_columns, bool_n_columns, CF_n_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into a tensor\n",
    "test_relevance_scores = torch.tensor(test_df['relevance_score'].values, dtype=torch.float32)\n",
    "test_single_cat_inputs = torch.tensor(test_df[[col + '_encoded' for col in single_cat_cols]].values)\n",
    "test_multi_cat_inputs = [\n",
    "    torch.tensor(np.stack(test_df[col + '_encoded_padded'].values), dtype=torch.int64)\n",
    "    for col in multi_cat_cols\n",
    "]\n",
    "test_num_inputs = torch.tensor(test_df[num_cols].values, dtype=torch.float32)\n",
    "test_bool_inputs = torch.tensor(test_df[bool_cols].values)\n",
    "test_CF_inputs = [\n",
    "    torch.tensor(np.stack(test_df[col].values), dtype=torch.float32)\n",
    "    for col in cf_emb_cols\n",
    "]\n",
    "test_user_ids = torch.tensor(test_df['user_id'].astype(np.int64).values)\n",
    "\n",
    "test_dataset = UserGameDataset(test_single_cat_inputs, test_multi_cat_inputs, test_num_inputs, test_bool_inputs, test_CF_inputs, test_relevance_scores, test_user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_model(nn.Module):\n",
    "    def __init__(self, single_cat_dims, multi_cat_dims, emb_dim, num_dim, bool_dim, hidden_sizes, dropout_rate):\n",
    "        super(NN_model, self).__init__()\n",
    "\n",
    "        # Embedding layers for single categorical columns\n",
    "        self.single_cat_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim) for cat_dim in single_cat_dims\n",
    "        ])\n",
    "\n",
    "        # Embedding layers for multi-categorical columns with padding\n",
    "        self.multi_cat_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, emb_dim, padding_idx=PADDING_VALUE) for cat_dim in multi_cat_dims\n",
    "        ])\n",
    "\n",
    "        # Layer normalization for each single categorical embedding\n",
    "        self.single_cat_layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(emb_dim) for _ in single_cat_dims\n",
    "        ])\n",
    "\n",
    "        # Layer normalization for each multi-categorical embedding\n",
    "        self.multi_cat_layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(emb_dim) for _ in multi_cat_dims\n",
    "        ])\n",
    "\n",
    "        # Dense layer for numeric and boolean inputs\n",
    "        self.num_dense = nn.Linear(num_dim, emb_dim)\n",
    "        self.bool_dense = nn.Linear(bool_dim, emb_dim)\n",
    "\n",
    "        # Fully connected layers setup\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "\n",
    "        # Batch normalization setup\n",
    "        self.batch_norm_layers = nn.ModuleList()\n",
    "\n",
    "        # Drop out\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        input_size = emb_dim * (len(single_cat_dims) + len(multi_cat_dims) + 2)\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.fc_layers.append(nn.Linear(input_size, hidden_size)) # Fully connected layers\n",
    "            self.batch_norm_layers.append(nn.BatchNorm1d(hidden_size)) # Batch normalization\n",
    "            input_size = hidden_size\n",
    "        self.output = nn.Linear(input_size, 1)  # Output for regression\n",
    "\n",
    "    def forward(self, all_inputs):\n",
    "        # Extract single categorical columns\n",
    "        single_cat_inputs = all_inputs[:, :single_cat_n_columns]\n",
    "\n",
    "        # Extract multi-categorical columns\n",
    "        i = 0\n",
    "        multi_cat_inputs = []\n",
    "        for n_col in multi_cat_n_columns:\n",
    "            multi_cat_inputs.append(all_inputs[:, single_cat_n_columns + i:single_cat_n_columns + i + n_col])\n",
    "            i += n_col\n",
    "\n",
    "        # Extract numerical columns\n",
    "        num_inputs = all_inputs[:, single_cat_n_columns + sum(multi_cat_n_columns):single_cat_n_columns + sum(multi_cat_n_columns) + num_n_columns]\n",
    "\n",
    "        # Extract Boolean columns\n",
    "        bool_inputs = all_inputs[:, single_cat_n_columns + sum(multi_cat_n_columns) + num_n_columns:single_cat_n_columns + sum(multi_cat_n_columns) + num_n_columns + bool_n_columns]\n",
    "\n",
    "        # Process single categorical columns through embeddings and normalize\n",
    "        single_cat_emb = [\n",
    "            self.single_cat_layer_norms[i](embed(single_cat_inputs[:, i].type(torch.long))) \n",
    "            for i, embed in enumerate(self.single_cat_embeddings)\n",
    "        ]\n",
    "\n",
    "        # Process multi-categorical columns through embeddings with max pooling the most representative category for each feature and then normalize\n",
    "        multi_cat_emb = [\n",
    "            self.multi_cat_layer_norms[i](torch.max(embed(multi_cat_inputs[i].type(torch.long)), dim=1)[0])\n",
    "            for i, embed in enumerate(self.multi_cat_embeddings)\n",
    "        ]\n",
    "\n",
    "        # Process numeric and boolean features through dense layers\n",
    "        num_out = torch.relu(self.num_dense(num_inputs))\n",
    "        bool_out = torch.relu(self.bool_dense(bool_inputs.float()))\n",
    "\n",
    "        # Concatenate all features together\n",
    "        combined = torch.cat(single_cat_emb + multi_cat_emb + [num_out, bool_out], dim=1)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        x = combined\n",
    "        for fc_layer, batch_norm_layer in zip(self.fc_layers, self.batch_norm_layers):\n",
    "            x = torch.relu(fc_layer(x))\n",
    "            x = batch_norm_layer(x)\n",
    "            x = self.dropout(x)\n",
    "        output = self.output(x)  # Regression output\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Dimensions for category embedding layers\n",
    "# Add 1 dimension for the additional \"Unknown\" category in test set\n",
    "single_cat_dims = [train_df[col + '_encoded'].nunique() + 1 for col in single_cat_cols]\n",
    "# max() + 2 because it starts from 0 and the additional \"Unknown\" category\n",
    "multi_cat_dims = [train_df[col + '_encoded_padded'].apply(lambda x: max(x)).max() + 2 for col in multi_cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since NDCG is not differentiable, we use RankNet Loss to approximate NDCG during training, then use NDCG to evaluate during validation\n",
    "\n",
    "def ranknet_loss(scores, targets):\n",
    "    # Compute pairwise differences for scores and targets.\n",
    "    pairwise_diff = scores - scores.t()  # shape: (batch_size, batch_size)\n",
    "    target_diff = targets - targets.t()    # shape: (batch_size, batch_size)\n",
    "    \n",
    "    # Only consider pairs with a non-zero difference in ground truth.\n",
    "    valid_pairs = (target_diff != 0).float()\n",
    "    \n",
    "    # Sij is +1 if target[i] > target[j] and -1 if target[i] < target[j].\n",
    "    Sij = torch.sign(target_diff)\n",
    "    \n",
    "    # Compute the probability that item i is ranked higher than j.\n",
    "    P_ij = torch.sigmoid(pairwise_diff)\n",
    "    \n",
    "    # Convert Sij to binary targets: 1 for Sij == 1, 0 for Sij == -1.\n",
    "    target_prob = (Sij + 1) / 2.0\n",
    "    \n",
    "    # Compute the binary cross entropy loss for the pairwise differences.\n",
    "    loss = F.binary_cross_entropy(P_ij, target_prob, reduction='none')\n",
    "    \n",
    "    # Only count valid pairs.\n",
    "    loss = (loss * valid_pairs).sum() / valid_pairs.sum().clamp(min=1)\n",
    "    return loss\n",
    "\n",
    "def grouped_ranknet_loss(outputs, targets, user_ids):\n",
    "    if not torch.is_tensor(user_ids):\n",
    "        user_ids = torch.tensor(user_ids)\n",
    "    unique_users = torch.unique(user_ids)\n",
    "    group_loss_sum = 0.0\n",
    "    group_count = 0\n",
    "    for uid in unique_users:\n",
    "        indices = (user_ids == uid).nonzero(as_tuple=True)[0]\n",
    "        if indices.numel() < 2:\n",
    "            continue\n",
    "        group_output = outputs[indices]\n",
    "        group_targets = targets[indices]\n",
    "        group_loss = ranknet_loss(group_output, group_targets)\n",
    "        group_loss_sum += group_loss\n",
    "        group_count += 1\n",
    "    if group_count > 0:\n",
    "        return group_loss_sum / group_count\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=outputs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserGroupBatchSampler(Sampler):\n",
    "    def __init__(self, user_ids, min_samples=2):\n",
    "        \"\"\"\n",
    "        Custom batch sampler for dataloader to implement user-based batching\n",
    "        Args:\n",
    "            user_ids (list or tensor): List or tensor of user IDs for each example.\n",
    "            min_samples (int): Minimum number of samples required from a user to form a batch.\n",
    "        \"\"\"\n",
    "        if hasattr(user_ids, \"tolist\"):\n",
    "            user_ids = user_ids.tolist()\n",
    "        user_ids = [int(uid) for uid in user_ids]\n",
    "        \n",
    "        user_series = pd.Series(user_ids)\n",
    "        self.user_to_indices = user_series.groupby(user_series).apply(list).to_dict()\n",
    "        \n",
    "        # Filter out users with fewer than min_samples.\n",
    "        self.user_to_indices = {uid: indices for uid, indices in self.user_to_indices.items() if len(indices) >= min_samples}\n",
    "        self.user_ids = list(self.user_to_indices.keys())\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Shuffle the user order to randomize batches\n",
    "        random.shuffle(self.user_ids)\n",
    "        for uid in self.user_ids:\n",
    "            # Yield the indices for this user as a single batch\n",
    "            yield self.user_to_indices[uid]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-11 18:10:42,500] A new study created in memory with name: no-name-fb7d9a6e-eb79-4a9a-876e-23897dbb46f5\n"
     ]
    }
   ],
   "source": [
    "K_FOLDS = 5\n",
    "NUM_EPOCHS = 5\n",
    "PATIENCE = 3\n",
    "N_TRIALS = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up Optuna's logging system\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions by Optuna\n",
    "    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    hidden_sizes = [trial.suggest_int(f'hidden_size_{i}', 16, 128) for i in range(num_layers)]\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "\n",
    "    # K-Fold Cross Validation splitting by user\n",
    "    groups = train_df['user_id'].values\n",
    "    kf = GroupKFold(n_splits=K_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    trial_training_loss = []\n",
    "    trial_validation_ndcg = []\n",
    "    trial_best_val_ndcg = -float('inf')  # Initialize global best validation loss\n",
    "    trial_best_model_state = None  # Initialize global best model state\n",
    "    fold_ndcg_scores = []\n",
    "\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df, train_df['relevance_score'].values, groups)):\n",
    "        # Create Subsets and DataLoader for the current fold\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "        train_fold_user_ids = [train_dataset.user_ids[i] for i in train_subset.indices]\n",
    "        train_user_batch_sampler = UserGroupBatchSampler(train_fold_user_ids, min_samples=2)\n",
    "\n",
    "        val_fold_user_ids = [train_dataset.user_ids[i] for i in val_subset.indices]\n",
    "        val_train_user_batch_sampler = UserGroupBatchSampler(val_fold_user_ids, min_samples=2)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_sampler=train_user_batch_sampler, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "        val_loader = DataLoader(val_subset, batch_sampler=val_train_user_batch_sampler, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "\n",
    "        # Initialize model for each fold\n",
    "        model = NN_model(\n",
    "            single_cat_dims=single_cat_dims,\n",
    "            multi_cat_dims=multi_cat_dims,\n",
    "            emb_dim=embedding_dim,\n",
    "            num_dim=len(num_cols),\n",
    "            bool_dim=len(bool_cols),\n",
    "            hidden_sizes=hidden_sizes,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Initialization for each fold\n",
    "        fold_best_val_ndcg = -float('inf')\n",
    "        fold_train_losses = []\n",
    "        fold_val_ndcgs = []\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # Training loop with early stopping\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            model.train()\n",
    "            epoch_train_loss = 0\n",
    "\n",
    "            # ------------- Training -------------\n",
    "            for batch in train_loader:\n",
    "                input_batch, target_batch, user_ids = batch\n",
    "                input_batch = input_batch.to(device)\n",
    "                target_batch = target_batch.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(input_batch)\n",
    "\n",
    "                loss = grouped_ranknet_loss(output, target_batch, user_ids)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "            epoch_train_loss /= len(train_loader) # Average train loss for this fold\n",
    "            fold_train_losses.append(epoch_train_loss)\n",
    "\n",
    "            # ------------- Validation -------------\n",
    "            model.eval()\n",
    "            preds_by_user = defaultdict(list)\n",
    "            truths_by_user = defaultdict(list)\n",
    "            epoch_val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_batch, target_batch, user_ids = batch\n",
    "                    input_batch = input_batch.to(device)\n",
    "                    target_batch = target_batch.to(device)\n",
    "\n",
    "                    output = model(input_batch)\n",
    "                    loss = grouped_ranknet_loss(output, target_batch, user_ids)\n",
    "                    epoch_val_loss += loss.item() # Accumulate validation loss\n",
    "\n",
    "                    # Accumulate predictions and targets according to user ids\n",
    "                    for pred, truth, uid in zip(output.squeeze().cpu().numpy(),\n",
    "                                                  target_batch.cpu().numpy(), user_ids):\n",
    "                        preds_by_user[int(uid)].append(pred)\n",
    "                        truths_by_user[int(uid)].append(truth)\n",
    "\n",
    "            epoch_val_loss /= len(val_loader) # Average validation loss for this fold\n",
    "\n",
    "            # Compute NDCG per user group and average across groups\n",
    "            user_ndcgs = []\n",
    "            for uid in preds_by_user:\n",
    "                # Reshape for ndcg_score to 2D arrays\n",
    "                y_true = np.array(truths_by_user[uid]).reshape(1, -1)\n",
    "                y_pred = np.array(preds_by_user[uid]).reshape(1, -1)\n",
    "                ndcg = ndcg_score(y_true, y_pred)\n",
    "                user_ndcgs.append(ndcg)\n",
    "            epoch_val_ndcg = np.mean(user_ndcgs) if user_ndcgs else 0.0\n",
    "            fold_val_ndcgs.append(epoch_val_ndcg)\n",
    "\n",
    "            # Early stopping check\n",
    "            if epoch_val_ndcg > fold_best_val_ndcg:\n",
    "                fold_best_val_ndcg = epoch_val_ndcg\n",
    "                epochs_no_improve = 0\n",
    "                \n",
    "                if epoch_val_ndcg > trial_best_val_ndcg:\n",
    "                    trial_best_val_ndcg = epoch_val_ndcg\n",
    "                    trial_best_model_state = model.state_dict()  # Save trail best model state\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                break\n",
    "\n",
    "        fold_ndcg_scores.append(fold_best_val_ndcg)\n",
    "        trial_training_loss.append(fold_train_losses)\n",
    "        trial_validation_ndcg.append(fold_val_ndcgs)\n",
    "\n",
    "    # Record fold metrics in the trial attributes\n",
    "    trial.set_user_attr('fold_ndcg_scores', fold_ndcg_scores)\n",
    "    trial.set_user_attr('training_loss', trial_training_loss)\n",
    "    trial.set_user_attr('validation_ndcg', trial_validation_ndcg)\n",
    "    \n",
    "    average_ndcg = np.mean(fold_ndcg_scores)\n",
    "    trial.set_user_attr(\"best_model_state\", trial_best_model_state)\n",
    "    return average_ndcg\n",
    "\n",
    "# Create a study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# Reconstruct the best model\n",
    "best_trial = study.best_trial\n",
    "best_model_state = best_trial.user_attrs[\"best_model_state\"]\n",
    "embedding_dim = best_trial.params['embedding_dim']\n",
    "num_layers = best_trial.params['num_layers']\n",
    "hidden_sizes = [best_trial.params[f'hidden_size_{i}'] for i in range(num_layers)]\n",
    "dropout_rate = best_trial.params['dropout_rate']\n",
    "\n",
    "best_model = NN_model(\n",
    "    single_cat_dims=single_cat_dims,\n",
    "    multi_cat_dims=multi_cat_dims,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_numeric=len(num_cols),\n",
    "    num_boolean=len(bool_cols),\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    dropout_rate=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "best_model.load_state_dict(best_model_state)\n",
    "# Save trained model\n",
    "torch.save(best_model, r'..\\assets\\model\\PyTorch_trained_model.pth')\n",
    "\n",
    "# Compute standard deviations\n",
    "best_trial_fold_ndcgs = best_trial.user_attrs['fold_ndcg_scores']\n",
    "ndcg_std = np.std(best_trial_fold_ndcgs)\n",
    "\n",
    "# Print the best result\n",
    "print('Best trial:')\n",
    "print(f'  Average Validation NDCG: {best_trial.value}')\n",
    "print(f'  NDCG Std: {ndcg_std}')\n",
    "print('  Params: ')\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env699",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
